{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training using darts library\n",
    "\n",
    "TL using the same number of IDs is possible\n",
    "\n",
    "Reshaping does not seem possible.\n",
    "\n",
    "when the target dataset has more IDs than the source set, we use the same model to predict multiple ids \n",
    "\n",
    "the models are trained on the same amount of IDs as the target test set contains \n",
    "\n",
    "residuals of the target test set are not considered \n",
    "\n",
    "TODO: Fine tuning and saving outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.utils.losses import *\n",
    "from darts.models import *\n",
    "from darts.metrics.metrics import mse, mae, mape\n",
    "\n",
    "from utils import data_handling, helpers\n",
    "import torch\n",
    "import numpy\n",
    "\n",
    "four_weeks = 24*7*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"4_weeks_train\"] = electricity_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "electricity_dict[\"4_weeks_train\"], _ = helpers.custom_standardizer(electricity_dict[\"4_weeks_train\"], train_standardize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/IPython/core/completerlib.py:120: UserWarning: using rootmodules_cache requires you to install the `pickleshare` library.\n",
      "  rootmodules_cache = ip.db.get('rootmodules_cache', {})\n"
     ]
    }
   ],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "bavaria_dict[\"4_weeks_train\"] = bavaria_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "gp_dict[\"4_weeks_train\"] = gp_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED FOR EXPERIMENTS\n",
    "# euro dataset\n",
    "#data_tensor = data_handling.eu_electricity_to_tensor()\n",
    "#euro_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(source_data_train, source_data_val, epochs=1):\n",
    "    \"\"\"\n",
    "    -Convert train/val data into Darts TimeSeries format\n",
    "    -Instantiate different models\n",
    "    -Fit models to dataset\n",
    "\n",
    "    Return: fitted models\n",
    "    \"\"\"\n",
    "    ts_train_source = TimeSeries.from_values(source_data_train)\n",
    "    ts_val_source = TimeSeries.from_values(source_data_val)\n",
    "   \n",
    "   \n",
    "    # model specific parameters\n",
    "    # nhits/nbeats\n",
    "    NUM_STACKS = 4\n",
    "    NUM_BLOCKS = 2\n",
    "    NUM_LAYERS = 2\n",
    "    LAYER_WIDTH = 256\n",
    "    COEFFS_DIM = 5\n",
    "\n",
    "    # Training settings:\n",
    "    LR = 0.0005\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    # shared parameters\n",
    "    LAYER_NORM = 'LayerNorm'\n",
    "    USE_REVIN = True\n",
    "    LOSS_FN = torch.nn.MSELoss()\n",
    "    IN_LEN = 96\n",
    "    OUT_LEN = 96\n",
    "    DROPOUT = 0.2  # slightly higher than \"generic\" because we want more robustnes for TL\n",
    "    VERBOSE = False\n",
    "\n",
    "    # reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    nhits_model = NHiTSModel(\n",
    "    input_chunk_length=IN_LEN,\n",
    "    output_chunk_length=OUT_LEN,\n",
    "    activation='ReLU',\n",
    "    num_stacks=NUM_STACKS, \n",
    "    num_blocks=NUM_BLOCKS, \n",
    "    num_layers=NUM_LAYERS, \n",
    "    layer_widths=LAYER_WIDTH, \n",
    "    expansion_coefficient_dim=COEFFS_DIM, \n",
    "    trend_polynomial_degree=2, \n",
    "    dropout=DROPOUT, \n",
    "    loss_fn=LOSS_FN,\n",
    "    use_reversible_instance_norm=USE_REVIN,\n",
    "    pl_trainer_kwargs={\n",
    "            \"enable_progress_bar\": True,\n",
    "            # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "            \"accelerator\": \"gpu\",},\n",
    ")\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "        activation='ReLU',\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs={\n",
    "            \"enable_progress_bar\": True,\n",
    "            # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "            \"accelerator\": \"gpu\",},\n",
    "    )\n",
    "\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        output_chunk_shift=0, \n",
    "        d_model=LAYER_WIDTH, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=LAYER_WIDTH, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=None, \n",
    "        custom_encoder=None, \n",
    "        custom_decoder=None,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "    )\n",
    "\n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        output_chunk_shift=0,\n",
    "        hidden_size=LAYER_WIDTH, \n",
    "        ff_size=LAYER_WIDTH, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=LAYER_NORM, \n",
    "        normalize_before=False, \n",
    "        use_static_covariates=False,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "\n",
    "    )\n",
    "\n",
    "    nhits_model.fit(        \n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,)\n",
    "\n",
    "    nbeats_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    transformer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    return transformer_model, nbeats_model, tsmixer_model, nhits_model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(transformer, nbeats, nhits, tsnmix, target_test):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    \n",
    "\n",
    "    Input:  -trained models\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: [transformer, nhits, tsnmix]-Losses\n",
    "    \"\"\"\n",
    "\n",
    "    forecasting_endpoint = int(len(target_test)) - 96*2\n",
    "    target_test = TimeSeries.from_values(target_test)\n",
    "    window = [target_test[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "    target = [target_test[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    preds_transformer = transformer.predict(n=96, series=window)\n",
    "    preds_nhits = nhits.predict(n=96, series=window)\n",
    "    preds_tsnmix = tsnmix.predict(n=96, series=window)\n",
    "    preds_nbeats = nbeats.predict(n=96, series=window)\n",
    "\n",
    "\n",
    "    mse_transformer = mse(preds_transformer, target)\n",
    "    mse_nhits = mse(preds_nhits, target)\n",
    "    mse_tsmix = mse(preds_tsnmix, target)\n",
    "    mse_nbeats = mse(preds_nbeats, target)\n",
    "\n",
    "    length_loss = len(mse_transformer)\n",
    "\n",
    "    mae_transformer = mae(preds_transformer, target)\n",
    "    mae_nhits = mae(preds_nhits, target)\n",
    "    mae_tsmix = mae(preds_tsnmix, target)\n",
    "    mae_nbeats = mae(preds_nbeats, target)\n",
    "\n",
    "\n",
    "    #mape_transformer = mape(preds_transformer, target)\n",
    "    #mape_nhits = mape(preds_nhits, target)\n",
    "    #mape_tsmix = mape(preds_tsnmix, target)\n",
    "    #mape_nbeats = mape(preds_nbeats, target)\n",
    "\n",
    "\n",
    "\n",
    "    mse_mae_mape_transformer = sum(mse_transformer) / length_loss, sum(mae_transformer) / length_loss#, sum(mape_transformer) / length_loss\n",
    "    mse_mae_mape_nhits = sum(mse_nhits) / length_loss, sum(mae_nhits) / length_loss#, sum(mape_nhits) / length_loss\n",
    "    mse_mae_mape_tsmix = sum(mse_tsmix) / length_loss, sum(mae_tsmix) / length_loss#, sum(mape_tsmix) / length_loss\n",
    "    mse_mae_mape_nbeats = sum(mse_nbeats) / length_loss, sum(mae_nbeats) / length_loss#, sum(mape_nbeats) / length_loss\n",
    "\n",
    "    return mse_mae_mape_transformer, mse_mae_mape_nhits, mse_mae_mape_nbeats, mse_mae_mape_tsmix\n",
    "\n",
    "def extend_source_to_target_id_count(source, target):\n",
    "    source_id_count = source[\"train\"].shape[1]\n",
    "    target_id_count = target[\"train\"].shape[1]\n",
    "    full_repeats = target_id_count // source_id_count\n",
    "    remainder = target_id_count % source_id_count\n",
    "\n",
    "    repeated_tensor = source[\"train\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"train\"][:, :remainder]\n",
    "    source_train = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    assert target[\"train\"].size(1) == source[\"train\"].size(1), \"Reshaping was incorrect.\"\n",
    "\n",
    "    repeated_tensor = source[\"validation\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"validation\"][:, :remainder]\n",
    "    source_validation = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    assert target[\"validation\"].size(1) == source[\"validation\"].size(1), \"Reshaping was incorrect.\"\n",
    "\n",
    "    return source_train, source_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_zero_shot(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    fine_tune_horizon = -24*7*4\n",
    "    target_test = target_data[\"test\"]\n",
    "    target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,:]\n",
    "\n",
    "    # remove IDs if source is bigger than target or\n",
    "    # repeat IDs if target is bigger than source\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_validation = source_data[\"validation\"][:,:target_ids]\n",
    "    else:\n",
    "        source_train, source_validation = extend_source_to_target_id_count(source_data, target_data)\n",
    "\n",
    "    transformer, nbeats, tsmix, nhits = train_models(source_train, source_validation, epochs=5)\n",
    "    return transformer, nbeats, nhits, tsmix, target_test, target_fine_tuning\n",
    "\n",
    "\n",
    "\n",
    "def fine_tune_models(model, target_fine_tuning, epochs=5):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    ts_fine_tuning = TimeSeries.from_values(target_fine_tuning) \n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    model.fit(\n",
    "            ts_fine_tuning,\n",
    "            num_loader_workers=4,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            max_samples_per_ts=None,\n",
    "        )\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "loss_transformer = {}\n",
    "loss_nhits = {}\n",
    "loss_tsnmix = {}\n",
    "loss_nbeats = {}\n",
    "\n",
    "\n",
    "transformer, nbeats, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, bavaria_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:  12%|█▏        | 2/17 [00:00<00:00, 28.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 23.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 25.27it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 38.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 118   \n",
      "4 | encoder             | Linear              | 3.8 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 368 K \n",
      "------------------------------------------------------------\n",
      "920 K     Trainable params\n",
      "0         Non-trainable params\n",
      "920 K     Total params\n",
      "3.683     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 10.04it/s, train_loss=0.000663]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00,  9.98it/s, train_loss=0.000663]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 118   \n",
      "4 | stacks        | ModuleList       | 7.0 M \n",
      "---------------------------------------------------\n",
      "7.0 M     Trainable params\n",
      "69.4 K    Non-trainable params\n",
      "7.0 M     Total params\n",
      "28.173    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00,  8.71it/s, train_loss=0.0006]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 3/3 [00:00<00:00,  8.64it/s, train_loss=0.0006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 24.1 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 3.8 K \n",
      "---------------------------------------------------------\n",
      "121 K     Trainable params\n",
      "0         Non-trainable params\n",
      "121 K     Total params\n",
      "0.487     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 14.64it/s, train_loss=0.0142]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 5/5 [00:00<00:00, 14.51it/s, train_loss=0.0142]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 39.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 25.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((0.0008762322704018461, 0.019058848016853022, 0.7485992676493797),\n",
       " (0.0008602265230420568, 0.01827123355840079, 0.7163087949156761),\n",
       " (1.2296520091706153, 0.9392287497493353, 57.00679485003153))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# electricity as source\n",
    "loss_transformer[\"elec_to_bavaria\"], loss_nhits[\"elec_to_bavaria\"], loss_tsnmix[\"elec_to_bavaria\"]  = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer_tuned  = fine_tune_models(transformer, target_fine_tuning, epochs=5)\n",
    "nhits_tuned  = fine_tune_models(nhits, target_fine_tuning, epochs=5)\n",
    "tsmix_tuned  = fine_tune_models(tsmix, target_fine_tuning, epochs=5)\n",
    "\n",
    "metrics = evaluate(transformer_tuned, nhits_tuned, tsmix_tuned, target_test)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.54it/s, train_loss=0.277, val_loss=0.521]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.50it/s, train_loss=0.277, val_loss=0.521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.56it/s, train_loss=0.159, val_loss=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.53it/s, train_loss=0.159, val_loss=0.690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.80it/s, train_loss=0.364, val_loss=0.448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.76it/s, train_loss=0.364, val_loss=0.448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.88it/s, train_loss=0.131, val_loss=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.84it/s, train_loss=0.131, val_loss=0.550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.43it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.40it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.24it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.21it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 30.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.12it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.09it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.66it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.64it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 29.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.28it/s, train_loss=0.302, val_loss=1.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.26it/s, train_loss=0.302, val_loss=1.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.04it/s, train_loss=0.248, val_loss=2.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.03it/s, train_loss=0.248, val_loss=2.050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 23.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.18it/s, train_loss=0.375, val_loss=0.767]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.17it/s, train_loss=0.375, val_loss=0.767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.88it/s, train_loss=0.434, val_loss=0.728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.87it/s, train_loss=0.434, val_loss=0.728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.16it/s, train_loss=0.211, val_loss=1.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.15it/s, train_loss=0.211, val_loss=1.260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.11it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_transformer = {}\n",
    "loss_nhits = {}\n",
    "loss_tsnmix = {}\n",
    "\n",
    "# electricity as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, bavaria_dict)\n",
    "loss_transformer[\"elec_to_bavaria\"], loss_nhits[\"elec_to_bavaria\"], loss_tsnmix[\"elec_to_bavaria\"]  = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, gp_dict)\n",
    "loss_transformer[\"elec_to_gp\"], loss_nhits[\"elec_to_gp\"], loss_tsnmix[\"elec_to_gp\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "\n",
    "# bavaria as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(bavaria_dict, electricity_dict)\n",
    "loss_transformer[\"bavaria_to_elec\"], loss_nhits[\"bavaria_to_elec\"], loss_tsnmix[\"bavaria_to_elec\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(bavaria_dict, gp_dict)\n",
    "loss_transformer[\"bavaria_to_gp\"], loss_nhits[\"bavaria_to_gp\"], loss_tsnmix[\"bavaria_to_gp\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "\n",
    "# genome project as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(gp_dict, bavaria_dict)\n",
    "loss_transformer[\"gp_to_bavaria\"], loss_nhits[\"gp_to_bavaria\"], loss_tsnmix[\"gp_to_bavaria\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(gp_dict, electricity_dict)\n",
    "loss_transformer[\"gp_to_elec\"], loss_nhits[\"gp_to_elec\"], loss_tsnmix[\"gp_to_elec\"] = evaluate(transformer, nhits, tsmix, target_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
