{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import succesfull\n"
     ]
    }
   ],
   "source": [
    "# TODO which one?\n",
    "#git clone https://github.com/lucidrains/iTransformer.git\n",
    "#import iTransformer\n",
    "import sys\n",
    "sys.path.append('/vol/fob-vol7/nebenf21/reinbene/bene/MA/iTransformer') \n",
    "from iTransformer import iTransformer\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "window_size = 96\n",
    "pred_length = (96)\n",
    "\n",
    "from utils import data_handling, training_functions, helpers\n",
    "import config \n",
    "\n",
    "print(\"Import succesfull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark all datasets used for transfer learning on iTransformer on its own.\n",
    "\n",
    "After the sanity check, we will use 96h as the input and the prediction horizon. In the following we will use the RevIn normalization strategie to benchmark iTransformer on our transfer learning datasets to get an initial baseline. RevIn is used because if performed the best on our initial baseline. This baseline will be compared to an SARIMA implementation and an additional DL model.\n",
    "\n",
    "Those results will also be used to evaluate the transfer-learning capability of iTransformer.\n",
    "\n",
    "Because transfer-learning is a sensible solution for the cold-start problem, we also do benchmarks on iTransformer only trained on the first 10% of the train dataset. Beacuse all datasets are big enough for efficient training, using a small subset is a solutoin to get meaningfull insight in how much value can be created through transfer-learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use full train dataset for training or small 10% subset\n",
    "full_dataset = True  # change to True to use full train dataset for training\n",
    "\n",
    "\n",
    "# potentially take different horizons for training\n",
    "def create_data_subset(data_dict):\n",
    "    sum_timesteps = data_dict[\"train\"].size(0)\n",
    "\n",
    "    h_per_week = 7 * 24\n",
    "    weeks_dict = {\"2_weeks\" : 2*h_per_week, \n",
    "                \"4_weeks\" : 4*h_per_week, \n",
    "                \"6_weeks\" : 6*h_per_week, \n",
    "                \"8_weeks\" : 8*h_per_week }\n",
    "\n",
    "\n",
    "    for key, value in weeks_dict.items():\n",
    "        data_dict[f\"train_{key}\"][(sum_timesteps-value):,:]     \n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 348])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4993, 348])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "data_dict = data_handling.load_electricity()\n",
    "\n",
    "# create a smaller subset of the train dataset\n",
    "if full_dataset == False:\n",
    "    daat_dict = create_data_subset(data_dict)\n",
    "\n",
    "electricity = {}\n",
    "electricity[\"dataloader_train\"], electricity[\"dataloader_validation\"], electricity[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "data_dict[\"train\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 208])\n"
     ]
    }
   ],
   "source": [
    "# eu electricity data\n",
    "data_tensor = data_handling.eu_electricity_to_tensor()\n",
    "data_dict, standardize_values =  data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# create a smaller subset of the train dataset\n",
    "if full_dataset == False:\n",
    "    percentage = 0.1\n",
    "    ten_percent_length = int(percentage * data_dict[\"train\"].shape[0])\n",
    "    data_dict[\"train\"] = data_dict[\"train\"][:ten_percent_length, :]\n",
    "\n",
    "# convert to dataloader\n",
    "europe = {}\n",
    "europe[\"dataloader_train\"], europe[\"dataloader_validation\"], europe[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 67])\n"
     ]
    }
   ],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "data_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# create a smaller subset of the train dataset\n",
    "if full_dataset == False:\n",
    "    percentage = 0.1\n",
    "    ten_percent_length = int(percentage * data_dict[\"train\"].shape[0])\n",
    "    data_dict[\"train\"] = data_dict[\"train\"][:ten_percent_length, :]\n",
    "\n",
    "# convert to datalaoder\n",
    "bavaria = {}\n",
    "bavaria[\"dataloader_train\"], bavaria[\"dataloader_validation\"], bavaria[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 278])\n",
      "Feature batch shape: torch.Size([32, 96, 70])\n"
     ]
    }
   ],
   "source": [
    "full_dataset = True  # change to True to use full train dataset for training\n",
    "\n",
    "# use electricity dataset\n",
    "data_dict = data_handling.load_electricity()\n",
    "\n",
    "transfer_learning_split = True\n",
    "\n",
    "if transfer_learning_split == True:\n",
    "\n",
    "    id_split_point = int(data_dict[\"train\"].size(1) * 0.8)\n",
    "\n",
    "    data_dict_source = {}\n",
    "    data_dict_target = {}\n",
    "\n",
    "    for key, value in data_dict.items():\n",
    "        data_dict_source[key] = value[:,:id_split_point]\n",
    "        data_dict_target[key] = value[:,id_split_point:]\n",
    "\n",
    "\n",
    "    electricity = {}\n",
    "    electricity[\"dataloader_train\"], electricity[\"dataloader_validation\"], electricity[\"dataloader_test\"] = data_handling.convert_data(data_dict_source, window_size, pred_length)\n",
    "    dataloader_train_target, dataloader_validation_target, dataloader_test_target = data_handling.convert_data(data_dict_target, window_size, pred_length)\n",
    "\n",
    "else:\n",
    "    dataloader_train, dataloader_validation, dataloader_test = data_handling.convert_data(data_dict, window_size, pred_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {\"electricity\" : electricity,\n",
    "\t\t\t#\"europe\" : europe,\n",
    "\t\t\t#\"bavaria\" : bavaria\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 151/151 [00:24<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, MSE-Loss: 0.06950481870020463, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 81.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2617, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 151/151 [00:07<00:00, 20.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, MSE-Loss: 0.04911985351944601, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 82.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2371, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 151/151 [00:07<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, MSE-Loss: 0.04410922561852348, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 82.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2296, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4: 100%|██████████| 151/151 [00:07<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, MSE-Loss: 0.041530271461665234, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 83.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2311, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5: 100%|██████████| 151/151 [00:07<00:00, 20.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, MSE-Loss: 0.04003832659480588, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 84.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2316, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 6: 100%|██████████| 151/151 [00:07<00:00, 20.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, MSE-Loss: 0.03867426258049264, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 81.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2342, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 7: 100%|██████████| 151/151 [00:07<00:00, 20.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, MSE-Loss: 0.0381188832026049, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 79.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2326, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 8: 100%|██████████| 151/151 [00:07<00:00, 20.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8, MSE-Loss: 0.037131103915193225, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 85.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2359, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 9: 100%|██████████| 151/151 [00:07<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9, MSE-Loss: 0.03652111222560437, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 82.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2339, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 10: 100%|██████████| 151/151 [00:07<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, MSE-Loss: 0.03604539311090053, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 83.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2358, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 11: 100%|██████████| 151/151 [00:07<00:00, 21.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11, MSE-Loss: 0.034776946443398266, LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 83.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2355, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 12: 100%|██████████| 151/151 [00:07<00:00, 20.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12, MSE-Loss: 0.034424661911579946, LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 83.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2348, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 13: 100%|██████████| 151/151 [00:07<00:00, 20.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13, MSE-Loss: 0.03426811560396327, LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 82.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2364, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 14: 100%|██████████| 151/151 [00:07<00:00, 21.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14, MSE-Loss: 0.034228173386774315, LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 84.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2370, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 15: 100%|██████████| 151/151 [00:07<00:00, 20.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15, MSE-Loss: 0.034175754715966074, LR: 5e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:00<00:00, 82.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {96: {'mse': tensor(0.2369, device='cuda:1')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:01<00:00, 67.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{96: {'mse': 0.18652816116809845, 'mae': 0.2702822685241699, 'p10': 0.030281152576208115, 'p50': 0.1763065755367279, 'p90': 0.6134117841720581}, 192: {'mse': 0, 'mae': 0, 'p10': 0, 'p50': 0, 'p90': 0}, 336: {'mse': 0, 'mae': 0, 'p10': 0, 'p50': 0, 'p90': 0}, 720: {'mse': 0, 'mae': 0, 'p10': 0, 'p50': 0, 'p90': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run experiment for each normalizaiton strategie and save model and evaluation metrics\n",
    "\n",
    "for key, dataset_dict in datasets.items():\n",
    "    inputs, _ = next(iter(dataset_dict[\"dataloader_train\"]))\n",
    "    num_variates = inputs.size(2)\n",
    "    \n",
    "    # define parameters and create config \n",
    "    best_parameters = {'depth': 2, 'dim': 256, 'dim_head': 56, 'heads': 4, 'attn_dropout': 0.2, 'ff_mult': 4, 'ff_dropout': 0.1, \n",
    "                    'num_mem_tokens': 4, 'learning_rate': 0.0005}\n",
    "\n",
    "\n",
    "    model_config = {\n",
    "        'num_variates': num_variates,\n",
    "        'lookback_len': window_size,\n",
    "        'depth': best_parameters[\"depth\"],\n",
    "        'dim': best_parameters[\"dim\"],\n",
    "        'num_tokens_per_variate': 1,\n",
    "        'pred_length': pred_length,\n",
    "        'dim_head': best_parameters[\"dim_head\"],\n",
    "        'heads': best_parameters[\"heads\"],\n",
    "        'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "        'ff_mult': best_parameters[\"ff_mult\"],\n",
    "        'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "        'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "        'use_reversible_instance_norm': True,\n",
    "        'reversible_instance_norm_affine': True,\n",
    "        'flash_attn': True\n",
    "    }\n",
    "\n",
    "    # select available deviec\n",
    "#    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # defining all needed instances\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_parameters[\"learning_rate\"])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    writer = SummaryWriter(log_dir=config.CONFIG_LOGS_PATH[\"iTransformer_baseline\"])\n",
    "\n",
    "    # run model training as mentioned in the original paper\n",
    "    epoch = 15\n",
    "\n",
    "    for epoch in range(1, epoch + 1):\n",
    "        training_functions.train_one_epoch(epoch, model, device, dataset_dict[\"dataloader_train\"], dataset_dict[\"dataloader_validation\"], optimizer, scheduler, writer)\n",
    "\n",
    "\n",
    "    metrics = helpers.full_eval(model, dataset_dict[\"dataloader_test\"], device)\n",
    "\n",
    "    for eval_metric, value in metrics[96].items():\n",
    "        metrics[96][eval_metric] = value.item()\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics[96], orient='index')\n",
    "    metrics_df.rename(columns={0: key}, inplace=True)\n",
    "\n",
    "    if full_dataset == False:\n",
    "        metrics_df.to_csv(f\"{config.CONFIG_OUTPUT_PATH['iTransformer_baseline']}/metrics_{key}_epochs{epoch}_revin_10_percent_dataset.csv\")\n",
    "    else:\n",
    "        metrics_df.to_csv(f\"{config.CONFIG_OUTPUT_PATH['iTransformer_baseline']}/metrics_{key}_epochs{epoch}_revin_{num_variates}_channels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "\t\t'model_state_dict': model.state_dict(),\n",
    "\t\t'optimizer_state_dict': optimizer.state_dict(),\n",
    "\t\t'scheduler_state_dict' : scheduler.state_dict(),\n",
    "\t\t'epoch': epoch,\n",
    "\t\t'loss': 0.178,\n",
    "\t\t'global_step_writer' : 0,\n",
    "\t}\n",
    "\t# model, revin, affine, epoch, loss\n",
    "torch.save(checkpoint, f'{config.CONFIG_OUTPUT_PATH[\"iTransformer_baseline\"]}/electricity_tl_270_channels.pt') # "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
