{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import succesfull\n"
     ]
    }
   ],
   "source": [
    "# TODO which one?\n",
    "#git clone https://github.com/lucidrains/iTransformer.git\n",
    "#import iTransformer\n",
    "import sys\n",
    "sys.path.append('/vol/fob-vol7/nebenf21/reinbene/bene/MA/iTransformer') \n",
    "from iTransformer import iTransformer\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "from utils import data_handling, training_functions\n",
    "import config \n",
    "\n",
    "print(\"Import succesfull\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sanity checking our iTransformer implementation\n",
    "\n",
    "We use the same parameters as presented in the paper to do a first evaulation if our model is actually able\n",
    "to reproduce the results as shown in the original paper.\n",
    "\n",
    "We take a window size of 96 hours as input and predict different horizons from 96h to 720h. \n",
    "\n",
    "The parameters used are in the range of the optimal parameters evaluated in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 348])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "data_dict = data_handling.load_electricity()\n",
    "\n",
    "window_size = 96\n",
    "pred_length = (96, 192, 336, 720)\n",
    "\n",
    "dataloader_train, dataloader_validation, dataloader_test = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "len(dataloader_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model on electricity dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_strategies = {\"base\" : [False, False],\n",
    "\t\t\t\t\t\t\t\"revin\" : [True, True],\n",
    "\t\t\t\t\t\t\t\"stationary\" : [True, False]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 151/151 [02:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, MSE-Loss: 0.0684398826680436, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:18<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE is {96: {'mse': tensor(0.2269, device='cuda:0')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|██████████| 151/151 [02:24<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, MSE-Loss: 0.047383620471551716, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:15<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE is {96: {'mse': tensor(0.2194, device='cuda:0')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|██████████| 151/151 [02:23<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, MSE-Loss: 0.04356631458989832, LR: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 21/21 [00:18<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE is {96: {'mse': tensor(0.2076, device='cuda:0')}, 192: {'mse': 0}, 336: {'mse': 0}, 720: {'mse': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4:  83%|████████▎ | 125/151 [01:58<00:24,  1.06it/s]"
     ]
    }
   ],
   "source": [
    "# run experiment for each normalizaiton strategie and save model and evaluation metrics\n",
    "\n",
    "for key, value in normalization_strategies.items():\n",
    "\n",
    "    # define parameters and create config \n",
    "    best_parameters = {'depth': 2, 'dim': 256, 'dim_head': 56, 'heads': 4, 'attn_dropout': 0.2, 'ff_mult': 4, 'ff_dropout': 0.2, \n",
    "                    'num_mem_tokens': 4, 'learning_rate': 0.0005}\n",
    "\n",
    "\n",
    "    model_config = {\n",
    "        'num_variates': data_dict[\"train\"].size(1),\n",
    "        'lookback_len': window_size,\n",
    "        'depth': best_parameters[\"depth\"],\n",
    "        'dim': best_parameters[\"dim\"],\n",
    "        'num_tokens_per_variate': 1,\n",
    "        'pred_length': pred_length,\n",
    "        'dim_head': best_parameters[\"dim_head\"],\n",
    "        'heads': best_parameters[\"heads\"],\n",
    "        'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "        'ff_mult': best_parameters[\"ff_mult\"],\n",
    "        'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "        'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "        'use_reversible_instance_norm': value[0],\n",
    "        'reversible_instance_norm_affine': value[1],\n",
    "        'flash_attn': True\n",
    "    }\n",
    "\n",
    "    # select available deviec\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # defining all needed instances\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_parameters[\"learning_rate\"])\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    writer = SummaryWriter(log_dir=config.CONFIG_LOGS_PATH[key])\n",
    "\n",
    "    # run model training as mentioned in the original paper\n",
    "    epoch = 15\n",
    "\n",
    "    for epoch in range(1, epoch + 1):\n",
    "        metrics, best_model = training_functions.train_one_epoch(epoch, model, device, dataloader_train, dataloader_validation, optimizer, scheduler, writer)\n",
    "\n",
    "    model = best_model\n",
    "    metrics = training_functions.fast_eval(model, dataloader_test)\n",
    "\n",
    "\n",
    "    # save model\n",
    "    checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'scheduler_state_dict' : scheduler.state_dict(),\n",
    "            'epoch': epoch,\n",
    "            'loss': metrics[96][\"mse\"].item(),\n",
    "            'global_step_writer' : 0,\n",
    "        }\n",
    "\n",
    "    torch.save(checkpoint, f'{config.CONFIG_MODEL_LOCATION[key]}/electricity_{key}_epoch_{epoch}_loss_{checkpoint[\"loss\"]}.pt')  \n",
    "\n",
    "    print(f\"Checkpointing succesfull after epoch {epoch} for {key}\")\n",
    "\n",
    "    # convert metrics to dataframe and save as csv\n",
    "    for key_1, values_1 in metrics.items():\n",
    "        for key_2, values_2 in values_1.items():\n",
    "            metrics[key_1][key_2] = (values_2.item())\n",
    "\n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index')\n",
    "\n",
    "    metrics_df.to_csv(f\"{config.CONFIG_OUTPUT_PATH[key]}/metrics_{key}_epochs{epoch}.csv\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
