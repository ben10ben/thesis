{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook can be executed to run all experiments using the darts library.\n",
    "\n",
    "Training using the Transformer model is unreliable, sometimes returning nan with the same input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel, NHiTSModel, TransformerModel, TSMixerModel\n",
    "from darts.utils.losses import *\n",
    "from darts.metrics import metrics as darts_metrics\n",
    "from utils import data_handling, helpers\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import config\n",
    "import copy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "# Constants\n",
    "DEVICE = [1]\n",
    "IN_LEN = 96\n",
    "OUT_LEN = 96\n",
    "LOSS_FN = torch.nn.MSELoss()\n",
    "LAYER_WIDTH = 256\n",
    "NUM_STACKS = 4\n",
    "NUM_BLOCKS = 2\n",
    "NUM_LAYERS = 3\n",
    "COEFFS_DIM = 5\n",
    "DROPOUT = 0.25\n",
    "VERBOSE = True\n",
    "TRAIN_EPOCHS = 15\n",
    "TUNE_EPOCHS = 5\n",
    "four_weeks = -24*7*4\n",
    "LR = 0.005\n",
    "\n",
    "metrics_output_path = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"darts_metrics.csv\"\n",
    "\n",
    "model_path = config.CONFIG_MODEL_LOCATION[\"darts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_source_to_target_id_count(source, target):\n",
    "    source_id_count = source[\"train\"].shape[1]\n",
    "    target_id_count = target[\"train\"].shape[1]\n",
    "\n",
    "    full_repeats = target_id_count // source_id_count\n",
    "    remainder = target_id_count % source_id_count\n",
    "\n",
    "    repeated_tensor = source[\"train\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"train\"][:, :remainder]\n",
    "    source_train = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    \n",
    "    assert target_id_count == source_train.size(1), f\"Reshaping was incorrect. Target_train = {target_id_count}, source_train = {source_train.size(1)}.\"\n",
    "\n",
    "    repeated_tensor = source[\"validation\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"validation\"][:, :remainder]\n",
    "    source_validation = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    assert target_id_count == source_validation.size(1), f\"Reshaping was incorrect. Target_val = {target_id_count}, source_val = {source_validation.size(1)}.\"\n",
    "\n",
    "    return source_train, source_validation\n",
    "\n",
    "\n",
    "def process_tl_data(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    fine_tune_horizon = -24*7*4\n",
    "    target_test = target_data[\"test\"]\n",
    "    target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,:]\n",
    "\n",
    "    # remove IDs if source is bigger than target or\n",
    "    # repeat IDs if target is bigger than source\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_validation = source_data[\"validation\"][:,:target_ids]\n",
    "    else:\n",
    "        source_train, source_validation = extend_source_to_target_id_count(source_data, target_data)\n",
    "\n",
    "    # convert to TimeSeries dataframe\n",
    "    source_train = TimeSeries.from_values(source_train)\n",
    "    source_validation = TimeSeries.from_values(source_validation)\n",
    "    target_test = TimeSeries.from_values(target_test)\n",
    "    target_fine_tuning = TimeSeries.from_values(target_fine_tuning)\n",
    "    target_train = TimeSeries.from_values(target_data[\"train\"])\n",
    "    target_validation = TimeSeries.from_values(target_data[\"validation\"])\n",
    "\n",
    "    tl_dataset = {\n",
    "                    \"source_train\" : source_train,\n",
    "                    \"source_validation\" : source_validation,\n",
    "                    \"target_fine_tuning\" : target_fine_tuning,\n",
    "                    \"target_test\" : target_test,\n",
    "                    \"target_train\" : target_train,\n",
    "                    \"target_validation\" : target_validation\n",
    "                }\n",
    "\n",
    "    return tl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nhits(ts_train, ts_val, epochs=1):   \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    nhits_model = NHiTSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        activation='ReLU',\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        dropout=DROPOUT,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )\n",
    "\n",
    "    nhits_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nhits_model\n",
    "\n",
    "# Train NBEATS model\n",
    "def train_nbeats(ts_train, ts_val, epochs=1):   \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=32,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        activation='ReLU',\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )    \n",
    "\n",
    "    nbeats_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nbeats_model\n",
    "\n",
    "# Train Transformer model\n",
    "def train_transformer(ts_train, ts_val, epochs=1):    \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        d_model=LAYER_WIDTH, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=2, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=LAYER_WIDTH, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "        \n",
    "        )\n",
    "    \n",
    "    transformer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return transformer_model \n",
    "\n",
    "# Train TSMixer model\n",
    "def train_tsmixer(ts_train, ts_val, epochs=1):    \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "    \n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        hidden_size=LAYER_WIDTH, \n",
    "        ff_size=LAYER_WIDTH, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type='LayerNorm', \n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return tsmixer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, target_test):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    Input:  -trained model\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: Dict{MSE, MAE}\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # check for last input point and create input/target lists of 96 horizons\n",
    "    forecasting_endpoint = int(len(target_test)) - 96*2\n",
    "    window = [target_test[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "    target = [target_test[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    predictions = model.predict(n=96, series=window)\n",
    "\n",
    "    mse = darts_metrics.mse(predictions, target)\n",
    "    mae = darts_metrics.mae(predictions, target)\n",
    "\n",
    "    mse = sum(mse) / len(predictions)\n",
    "    mae = sum(mae) / len(predictions)\n",
    "\n",
    "    return {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "\n",
    "def fine_tune_model(model, target_fine_tuning, epochs=1):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    model.fit(\n",
    "            target_fine_tuning,\n",
    "            num_loader_workers=4,\n",
    "            epochs=epochs,\n",
    "            max_samples_per_ts=None,\n",
    "        )\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"4_weeks_train\"] = electricity_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "electricity_dict[\"4_weeks_train\"], _ = helpers.custom_standardizer(electricity_dict[\"4_weeks_train\"], train_standardize_dict)\n",
    "\n",
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "bavaria_dict[\"4_weeks_train\"] = bavaria_dict[\"train\"][four_weeks:,:]\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "gp_dict[\"4_weeks_train\"] = gp_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_setups = {\n",
    "    \"ELD_to_Bavaria\" : (electricity_dict, bavaria_dict), \n",
    "    \"ELD_to_GP2\" : (electricity_dict, gp_dict),\n",
    "    \"Bavaria_to_ELD\" : (bavaria_dict, electricity_dict), \n",
    "    \"Bavaria_to_GP2\" : (bavaria_dict, gp_dict), \n",
    "    \"GP2_to_Bavaria\": (gp_dict, bavaria_dict), \n",
    "    \"GP2_to_ELD\" : (gp_dict, electricity_dict)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELD_to_Bavaria\n",
      "Skipping NHiTS for ELD_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping NHiTS for ELD_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping NHiTS for ELD_to_Bavaria with full TL metrics already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with full TL metrics already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with full TL metrics already filled.\n",
      "Skipping NHiTS for ELD_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping NHiTS for ELD_to_Bavaria with as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with as metrics are already filled.\n",
      "ELD_to_GP2\n",
      "Skipping NHiTS for ELD_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping NHiTS for ELD_to_GP2 with shot TL metrics already filled.\n",
      "Skipping NHiTS for ELD_to_GP2 with full TL metrics already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with shot TL metrics already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with full TL metrics already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with shot TL metrics already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with full TL metrics already filled.\n",
      "Skipping NHiTS for ELD_to_GP2 with as baseline metrics are already filled.\n",
      "Skipping NHiTS for ELD_to_GP2 with as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with as baseline metrics are already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with as baseline metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with as metrics are already filled.\n",
      "Bavaria_to_ELD\n",
      "Skipping NHiTS for Bavaria_to_ELD with zero-shot metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_ELD with shot TL metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_ELD with full TL metrics already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with zero-shot metrics already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with shot TL metrics already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with full TL metrics already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with zero-shot metrics already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with shot TL metrics already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with full TL metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_ELD with as baseline metrics are already filled.\n",
      "Skipping NHiTS for Bavaria_to_ELD with as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with as baseline metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with as metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with as baseline metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with as metrics are already filled.\n",
      "Bavaria_to_GP2\n",
      "Skipping NHiTS for Bavaria_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_GP2 with shot TL metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_GP2 with full TL metrics already filled.\n",
      "Skipping Transformer for Bavaria_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping Transformer for Bavaria_to_GP2 with shot TL metrics already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 2.9 K \n",
      "4 | encoder             | Linear              | 372 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 2.8 M \n",
      "7 | decoder             | Linear              | 35.9 M\n",
      "------------------------------------------------------------\n",
      "39.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.0 M    Total params\n",
      "156.078   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 304/304 [00:14<00:00, 20.36it/s, train_loss=0.00037, val_loss=nan.0]    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 304/304 [00:14<00:00, 20.36it/s, train_loss=0.00037, val_loss=nan.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Attempting to retrain/fine-tune the model without resuming from a checkpoint. This is currently discouraged. Consider model `TransformerModel.load_weights()` to load the weights for fine-tuning.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 2.9 K \n",
      "4 | encoder             | Linear              | 372 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 2.8 M \n",
      "7 | decoder             | Linear              | 35.9 M\n",
      "------------------------------------------------------------\n",
      "39.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.0 M    Total params\n",
      "156.078   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:15<00:00, 19.88it/s, train_loss=0.792]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:15<00:00, 19.88it/s, train_loss=0.792]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:1159: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:242: RuntimeWarning: Mean of empty slice\n",
      "  vals = np.expand_dims(component_reduction(vals, axis=COMP_AX), axis=COMP_AX)\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:783: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/tmp/ipykernel_43380/3178925498.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_43380/3178925498.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for Transformer in Bavaria_to_GP2 with zero-shot fine-tuning: MAE = nan, MSE = nan\n",
      "Skipping TSMixer for Bavaria_to_GP2 with zero-shot metrics already filled.\n",
      "Skipping TSMixer for Bavaria_to_GP2 with shot TL metrics already filled.\n",
      "Skipping TSMixer for Bavaria_to_GP2 with full TL metrics already filled.\n",
      "Skipping NHiTS for Bavaria_to_GP2 with as baseline metrics are already filled.\n",
      "Skipping NHiTS for Bavaria_to_GP2 with as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_GP2 with as baseline metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 2.9 K \n",
      "4 | encoder             | Linear              | 372 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 2.8 M \n",
      "7 | decoder             | Linear              | 35.9 M\n",
      "------------------------------------------------------------\n",
      "39.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.0 M    Total params\n",
      "156.078   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 314/314 [00:14<00:00, 22.14it/s, train_loss=0.788, val_loss=nan.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 314/314 [00:14<00:00, 22.13it/s, train_loss=0.788, val_loss=nan.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 14.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:1159: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:242: RuntimeWarning: Mean of empty slice\n",
      "  vals = np.expand_dims(component_reduction(vals, axis=COMP_AX), axis=COMP_AX)\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:783: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/tmp/ipykernel_43380/3178925498.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_43380/3178925498.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping TSMixer for Bavaria_to_GP2 with as baseline metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_GP2 with as metrics are already filled.\n",
      "GP2_to_Bavaria\n",
      "Skipping NHiTS for GP2_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping NHiTS for GP2_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping NHiTS for GP2_to_Bavaria with full TL metrics already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with full TL metrics already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with zero-shot metrics already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with shot TL metrics already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with full TL metrics already filled.\n",
      "Skipping NHiTS for GP2_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping NHiTS for GP2_to_Bavaria with as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with as baseline metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with as metrics are already filled.\n",
      "GP2_to_ELD\n",
      "Skipping NHiTS for GP2_to_ELD with zero-shot metrics already filled.\n",
      "Skipping NHiTS for GP2_to_ELD with shot TL metrics already filled.\n",
      "Skipping NHiTS for GP2_to_ELD with full TL metrics already filled.\n",
      "Skipping Transformer for GP2_to_ELD with zero-shot metrics already filled.\n",
      "Skipping Transformer for GP2_to_ELD with shot TL metrics already filled.\n",
      "Skipping Transformer for GP2_to_ELD with full TL metrics already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with zero-shot metrics already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with shot TL metrics already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with full TL metrics already filled.\n",
      "Skipping NHiTS for GP2_to_ELD with as baseline metrics are already filled.\n",
      "Skipping NHiTS for GP2_to_ELD with as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_ELD with as baseline metrics are already filled.\n",
      "Skipping Transformer for GP2_to_ELD with as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with as baseline metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with as metrics are already filled.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NHiTS</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>TSMixer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setup</th>\n",
       "      <th>Learning_scenario</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.001612</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.029768</td>\n",
       "      <td>0.029673</td>\n",
       "      <td>0.034182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010753</td>\n",
       "      <td>0.010680</td>\n",
       "      <td>0.012290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009179</td>\n",
       "      <td>0.009851</td>\n",
       "      <td>0.008743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.008886</td>\n",
       "      <td>0.009337</td>\n",
       "      <td>0.009330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.011392</td>\n",
       "      <td>0.011714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.927760</td>\n",
       "      <td>0.986503</td>\n",
       "      <td>1.233384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.616421</td>\n",
       "      <td>0.655510</td>\n",
       "      <td>0.695620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.995074</td>\n",
       "      <td>1.041323</td>\n",
       "      <td>0.865992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.641355</td>\n",
       "      <td>0.664097</td>\n",
       "      <td>0.524999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.980549</td>\n",
       "      <td>0.975606</td>\n",
       "      <td>0.657875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.653280</td>\n",
       "      <td>0.649784</td>\n",
       "      <td>0.433311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.980830</td>\n",
       "      <td>0.977230</td>\n",
       "      <td>0.674455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.649966</td>\n",
       "      <td>0.650806</td>\n",
       "      <td>0.441427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.001582</td>\n",
       "      <td>1.048865</td>\n",
       "      <td>1.053140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.660117</td>\n",
       "      <td>0.665634</td>\n",
       "      <td>0.577975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>14.306585</td>\n",
       "      <td>10.764251</td>\n",
       "      <td>13.597932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.264933</td>\n",
       "      <td>2.907783</td>\n",
       "      <td>2.809807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.686743</td>\n",
       "      <td>0.958401</td>\n",
       "      <td>0.928438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.643095</td>\n",
       "      <td>0.813941</td>\n",
       "      <td>0.802077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.948382</td>\n",
       "      <td>0.214651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.414757</td>\n",
       "      <td>0.809264</td>\n",
       "      <td>0.300557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.358858</td>\n",
       "      <td>0.947744</td>\n",
       "      <td>0.226847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.414961</td>\n",
       "      <td>0.809475</td>\n",
       "      <td>0.309050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.434020</td>\n",
       "      <td>0.954644</td>\n",
       "      <td>0.480004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.474205</td>\n",
       "      <td>0.813598</td>\n",
       "      <td>0.485502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>6.936576</td>\n",
       "      <td>7.596890</td>\n",
       "      <td>8.128555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.952257</td>\n",
       "      <td>2.046025</td>\n",
       "      <td>2.061725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.029320</td>\n",
       "      <td>1.059521</td>\n",
       "      <td>0.866328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.661392</td>\n",
       "      <td>0.673235</td>\n",
       "      <td>0.532831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.976055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.644111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.648918</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.428923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.978798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.651744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.969528</td>\n",
       "      <td>1.043119</td>\n",
       "      <td>1.066945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.640075</td>\n",
       "      <td>0.664053</td>\n",
       "      <td>0.584738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.001689</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.030085</td>\n",
       "      <td>0.030479</td>\n",
       "      <td>0.026276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010296</td>\n",
       "      <td>0.010822</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.008924</td>\n",
       "      <td>0.009349</td>\n",
       "      <td>0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000290</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009144</td>\n",
       "      <td>0.009454</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009837</td>\n",
       "      <td>0.011575</td>\n",
       "      <td>0.011267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.958519</td>\n",
       "      <td>0.956663</td>\n",
       "      <td>0.864612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.812093</td>\n",
       "      <td>0.812249</td>\n",
       "      <td>0.712851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.485509</td>\n",
       "      <td>0.949605</td>\n",
       "      <td>0.311543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.519202</td>\n",
       "      <td>0.810760</td>\n",
       "      <td>0.373766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.374245</td>\n",
       "      <td>0.948054</td>\n",
       "      <td>0.214202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.424068</td>\n",
       "      <td>0.809283</td>\n",
       "      <td>0.301724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.350692</td>\n",
       "      <td>0.947296</td>\n",
       "      <td>0.211217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.410449</td>\n",
       "      <td>0.809581</td>\n",
       "      <td>0.297806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.422826</td>\n",
       "      <td>0.955353</td>\n",
       "      <td>0.373202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.463992</td>\n",
       "      <td>0.812563</td>\n",
       "      <td>0.417805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               NHiTS  Transformer    TSMixer\n",
       "Setup          Learning_scenario   Metric                                   \n",
       "ELD_to_Bavaria Zero-Shot           MSE      0.001619     0.001612   0.002046\n",
       "                                   MAE      0.029768     0.029673   0.034182\n",
       "               four_weeks_tl       MSE      0.000470     0.000489   0.000521\n",
       "                                   MAE      0.010753     0.010680   0.012290\n",
       "               full_tl             MSE      0.000285     0.000327   0.000276\n",
       "                                   MAE      0.009179     0.009851   0.008743\n",
       "               full_training       MSE      0.000284     0.000318   0.000304\n",
       "                                   MAE      0.008886     0.009337   0.009330\n",
       "               four_weeks_training MSE      0.000355     0.000498   0.000504\n",
       "                                   MAE      0.010746     0.011392   0.011714\n",
       "ELD_to_GP2     Zero-Shot           MSE      0.927760     0.986503   1.233384\n",
       "                                   MAE      0.616421     0.655510   0.695620\n",
       "               four_weeks_tl       MSE      0.995074     1.041323   0.865992\n",
       "                                   MAE      0.641355     0.664097   0.524999\n",
       "               full_tl             MSE      0.980549     0.975606   0.657875\n",
       "                                   MAE      0.653280     0.649784   0.433311\n",
       "               full_training       MSE      0.980830     0.977230   0.674455\n",
       "                                   MAE      0.649966     0.650806   0.441427\n",
       "               four_weeks_training MSE      1.001582     1.048865   1.053140\n",
       "                                   MAE      0.660117     0.665634   0.577975\n",
       "Bavaria_to_ELD Zero-Shot           MSE     14.306585    10.764251  13.597932\n",
       "                                   MAE      3.264933     2.907783   2.809807\n",
       "               four_weeks_tl       MSE      0.686743     0.958401   0.928438\n",
       "                                   MAE      0.643095     0.813941   0.802077\n",
       "               full_tl             MSE      0.363720     0.948382   0.214651\n",
       "                                   MAE      0.414757     0.809264   0.300557\n",
       "               full_training       MSE      0.358858     0.947744   0.226847\n",
       "                                   MAE      0.414961     0.809475   0.309050\n",
       "               four_weeks_training MSE      0.434020     0.954644   0.480004\n",
       "                                   MAE      0.474205     0.813598   0.485502\n",
       "Bavaria_to_GP2 Zero-Shot           MSE      6.936576     7.596890   8.128555\n",
       "                                   MAE      1.952257     2.046025   2.061725\n",
       "               four_weeks_tl       MSE      1.029320     1.059521   0.866328\n",
       "                                   MAE      0.661392     0.673235   0.532831\n",
       "               full_tl             MSE      0.976055          NaN   0.644111\n",
       "                                   MAE      0.648918          NaN   0.428923\n",
       "               full_training       MSE      0.978798          NaN   0.680707\n",
       "                                   MAE      0.651744          NaN   0.443016\n",
       "               four_weeks_training MSE      0.969528     1.043119   1.066945\n",
       "                                   MAE      0.640075     0.664053   0.584738\n",
       "GP2_to_Bavaria Zero-Shot           MSE      0.001653     0.001689   0.001333\n",
       "                                   MAE      0.030085     0.030479   0.026276\n",
       "               four_weeks_tl       MSE      0.000389     0.000488   0.000482\n",
       "                                   MAE      0.010296     0.010822   0.011400\n",
       "               full_tl             MSE      0.000277     0.000319   0.000273\n",
       "                                   MAE      0.008924     0.009349   0.008793\n",
       "               full_training       MSE      0.000290     0.000320   0.000301\n",
       "                                   MAE      0.009144     0.009454   0.009010\n",
       "               four_weeks_training MSE      0.000339     0.000499   0.000496\n",
       "                                   MAE      0.009837     0.011575   0.011267\n",
       "GP2_to_ELD     Zero-Shot           MSE      0.958519     0.956663   0.864612\n",
       "                                   MAE      0.812093     0.812249   0.712851\n",
       "               four_weeks_tl       MSE      0.485509     0.949605   0.311543\n",
       "                                   MAE      0.519202     0.810760   0.373766\n",
       "               full_tl             MSE      0.374245     0.948054   0.214202\n",
       "                                   MAE      0.424068     0.809283   0.301724\n",
       "               full_training       MSE      0.350692     0.947296   0.211217\n",
       "                                   MAE      0.410449     0.809581   0.297806\n",
       "               four_weeks_training MSE      0.422826     0.955353   0.373202\n",
       "                                   MAE      0.463992     0.812563   0.417805"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"NHiTS\": train_nhits,\n",
    "  #  \"NBEATS\": train_nbeats,\n",
    "    \"Transformer\": train_transformer,\n",
    "    \"TSMixer\": train_tsmixer\n",
    "}\n",
    "\n",
    "# Initialize the DataFrame\n",
    "try:\n",
    "    results_df = pd.read_csv(metrics_output_path, index_col=[0, 1, 2])\n",
    "except FileNotFoundError:\n",
    "    metrics = [\"MSE\", \"MAE\"]\n",
    "    learning_scenarios = [\"Zero-Shot\", \"four_weeks_tl\", \"full_tl\", \"full_training\", \"four_weeks_training\"]\n",
    "    index = pd.MultiIndex.from_product([tl_setups.keys(), learning_scenarios, metrics], names=[\"Setup\", \"Learning_scenario\", \"Metric\"])\n",
    "    results_df = pd.DataFrame(columns=models.keys(), index=index)\n",
    "\n",
    "# Helper functions\n",
    "def update_metrics(setup_name, model_name, learning_scenario, mae, mse):\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
    "\n",
    "def is_metric_filled(setup_name, model_name, learning_scenario):\n",
    "    # Check if specific metrics for a model in a setup and fine-tuning scenario are NaN or not\n",
    "    metrics_filled = not results_df.loc[(setup_name, learning_scenario, slice(None)), model_name].isnull().any()\n",
    "    return metrics_filled\n",
    "\n",
    "def run_model_tl(setup_name, tl_data):\n",
    "    source_train = tl_data[\"source_train\"]\n",
    "    source_val = tl_data[\"source_validation\"]\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "    #target_val = tl_data[\"target_validation\"]\n",
    "\n",
    "    model_trained = False\n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"Zero-Shot\") :\n",
    "            print(f\"Skipping {model_name} for {setup_name} with zero-shot metrics already filled.\")\n",
    "        else:          \n",
    "            # Train model with source dataset (Zero-Shot)\n",
    "            model = model_func(source_train, source_val, epochs=TRAIN_EPOCHS)\n",
    "            metrics = evaluate(model, target_test)\n",
    "            model_trained = True\n",
    "            update_metrics(setup_name, model_name, \"Zero-Shot\", metrics['MAE'], metrics['MSE'])\n",
    "            full_tl_model = copy.deepcopy(model)\n",
    "            print(f\"Metrics updated for {model_name} in {setup_name} with zero-shot fine-tuning: MAE = {metrics['MAE']}, MSE = {metrics['MSE']}\")\n",
    "        \n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "        if is_metric_filled(setup_name, model_name, \"four_weeks_tl\") :\n",
    "            print(f\"Skipping {model_name} for {setup_name} with shot TL metrics already filled.\")\n",
    "        else:          \n",
    "            # Fine-tune on small target train set (four_weeks_tl)\n",
    "            if model_trained == False:\n",
    "                model = model_func(source_train, source_val, epochs=TRAIN_EPOCHS)\n",
    "            model = fine_tune_model(model, target_fine_tuning, epochs=TUNE_EPOCHS + 5)\n",
    "            metrics = evaluate(model, target_test)\n",
    "            update_metrics(setup_name, model_name, \"four_weeks_tl\", metrics['MAE'], metrics['MSE'])\n",
    "            print(f\"Metrics updated for {model_name} in {setup_name} with zero-shot fine-tuning: MAE = {metrics['MAE']}, MSE = {metrics['MSE']}\")\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "\n",
    "        if is_metric_filled(setup_name, model_name, \"full_tl\") :\n",
    "            print(f\"Skipping {model_name} for {setup_name} with full TL metrics already filled.\")\n",
    "        else:          \n",
    "            # Fine-tune on full target train set (four_weeks_tl)\n",
    "            if model_trained == False:\n",
    "                full_tl_model = model_func(source_train, source_val, epochs=TRAIN_EPOCHS)\n",
    "            # Fine-tune on full target train set (full_tl)\n",
    "            full_tl_model = fine_tune_model(full_tl_model, target_train, epochs=TUNE_EPOCHS)\n",
    "            metrics = evaluate(full_tl_model, target_test)\n",
    "            update_metrics(setup_name, model_name, \"full_tl\", metrics['MAE'], metrics['MSE'])\n",
    "            print(f\"Metrics updated for {model_name} in {setup_name} with zero-shot fine-tuning: MAE = {metrics['MAE']}, MSE = {metrics['MSE']}\")\n",
    "\n",
    "        # Save after every dataset combination\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "def train_baselines(setup_name, tl_data):\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "    target_validation = tl_data[\"target_validation\"]\n",
    " \n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"four_weeks_training\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with as baseline metrics are already filled.\")\n",
    "        else:\n",
    "             # Train on short target train set (four_weeks_training)\n",
    "            model = model_func(target_fine_tuning, target_validation, epochs=TRAIN_EPOCHS)\n",
    "            metrics = evaluate(model, target_test)\n",
    "            update_metrics(setup_name, model_name, \"four_weeks_training\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "        if is_metric_filled(setup_name, model_name, \"full_training\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with as metrics are already filled.\")\n",
    "        else:\n",
    "            # Train on full target train set (full_training)\n",
    "            model = model_func(target_train, target_validation, epochs=15)\n",
    "            metrics = evaluate(model, target_test)\n",
    "            update_metrics(setup_name, model_name, \"full_training\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "# Execute for each setup and fine-tuning scenario\n",
    "for setup_name, (source_data, target_data) in tl_setups.items():\n",
    "    print(setup_name)\n",
    "    tl_data = process_tl_data(source_data, target_data)\n",
    "    run_model_tl(setup_name, tl_data)\n",
    "    train_baselines(setup_name, tl_data)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
