{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training using darts library\n",
    "\n",
    "TL using the same number of IDs is possible\n",
    "\n",
    "Reshaping does not seem possible.\n",
    "\n",
    "when the target dataset has more IDs than the source set, we use the same model to predict multiple ids \n",
    "\n",
    "the models are trained on the same amount of IDs as the target test set contains \n",
    "\n",
    "residuals of the target test set are not considered \n",
    "\n",
    "TODO: Fine tuning and saving outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.utils.losses import *\n",
    "from darts.models import *\n",
    "from darts.metrics.metrics import mse\n",
    "\n",
    "from utils import data_handling, helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2463, 67])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# euro dataset\n",
    "data_tensor = data_handling.eu_electricity_to_tensor()\n",
    "euro_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(source_data_train, source_data_val, epochs=1):\n",
    "    \"\"\"\n",
    "    -Convert train/val data into Darts TimeSeries format\n",
    "    -Instantiate different models\n",
    "    -Fit models to dataset\n",
    "\n",
    "    Return: fitted models\n",
    "    \"\"\"\n",
    "    ts_train_source = TimeSeries.from_values(source_data_train)\n",
    "    ts_val_source = TimeSeries.from_values(source_data_val)\n",
    "   \n",
    "   \n",
    "    # model definition\n",
    "\n",
    "    # Slicing hyper-params:\n",
    "    IN_LEN = 96\n",
    "    OUT_LEN = 96\n",
    "\n",
    "    # Architecture hyper-params:\n",
    "    NUM_STACKS = 4\n",
    "    NUM_BLOCKS = 1\n",
    "    NUM_LAYERS = 2\n",
    "    LAYER_WIDTH = 128\n",
    "    COEFFS_DIM = 11\n",
    "\n",
    "    # Training settings:\n",
    "    LR = 1e-3\n",
    "    BATCH_SIZE = 64\n",
    "\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    USE_REVIN = True\n",
    "\n",
    "    LOSS_FN = torch.nn.MSELoss()\n",
    "\n",
    "    # reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs={\n",
    "            \"enable_progress_bar\": True,\n",
    "            # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "            \"accelerator\": \"gpu\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        output_chunk_shift=0, \n",
    "        d_model=64, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=512, \n",
    "        dropout=0.1, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=None, \n",
    "        custom_encoder=None, \n",
    "        custom_decoder=None,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "    )\n",
    "\n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        output_chunk_shift=0,\n",
    "        hidden_size=64, \n",
    "        ff_size=64, \n",
    "        num_blocks=2, \n",
    "        activation='ReLU', \n",
    "        dropout=0.1, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type='LayerNorm', \n",
    "        normalize_before=False, \n",
    "        use_static_covariates=False,\n",
    "    )\n",
    "\n",
    "    nbeats_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "    transformer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "\n",
    "    return transformer_model, nbeats_model, tsmixer_model\n",
    "\n",
    "def fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning, epochs=1):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    nbeats_model.fit(\n",
    "        ts_fine_tuning,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "    transformer_model.fit(\n",
    "        ts_fine_tuning,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(\n",
    "        ts_fine_tuning,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "    )\n",
    "\n",
    "    return transformer_model, nbeats_model, tsmixer_model\n",
    "\n",
    "\n",
    "def evaluate(transformer, nhits, tsnmix, target_test_reshaped):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    \n",
    "\n",
    "    Input:  -trained models\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: [transformer, nhits, tsnmix]-Losses\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate multiple multivariate ID chunks\n",
    "    big_window = []\n",
    "    big_target = []\n",
    "\n",
    "    for element in target_test_reshaped:\n",
    "        element = TimeSeries.from_values(element)\n",
    "        forecasting_endpoint = int(len(element)) - 96*2\n",
    "\n",
    "        window = [element[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "        target = [element[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "        big_window.append(window)\n",
    "        big_target.append(target)\n",
    "\n",
    "    window = [item for sublist in big_window for item in sublist]\n",
    "    target = [item for sublist in big_target for item in sublist]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    preds_transformer = transformer.predict(n=96, series=window)\n",
    "    preds_nhits = nhits.predict(n=96, series=window)\n",
    "    preds_tsnmix = tsnmix.predict(n=96, series=window)\n",
    "\n",
    "    loss_transformer = mse(preds_transformer, target)\n",
    "    loss_nhits = mse(preds_nhits, target)\n",
    "    loss_tsnmix = mse(preds_tsnmix, target)\n",
    "\n",
    "    mean_loss_transformer = sum(loss_transformer) / len(loss_transformer)\n",
    "    mean_loss_nhits = sum(loss_nhits) / len(loss_nhits)\n",
    "    mean_loss_tsnmix = sum(loss_tsnmix) / len(loss_tsnmix)\n",
    "\n",
    "    return mean_loss_transformer, mean_loss_nhits, mean_loss_tsnmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    # now we do fine-tuning\\n    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\\n    one_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\\n\\n    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\\n    two_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\\n\\n    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\\n    three_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\\n\\n    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\\n    four_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\\n\\n    fine_tuning_loss = [one_epoch_loss, two_epoch_loss, three_epoch_loss, four_epoch_loss]\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_zero_shot(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    \n",
    "\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_val = source_data[\"validation\"][:,:target_ids]\n",
    "        \n",
    "        target_test = [target_data[\"test\"]]\n",
    "\n",
    "        target_fine_tuning = target_data[\"train\"][-24*28:,:target_ids]\n",
    "        ts_fine_tuning = TimeSeries.from_values(target_fine_tuning)\n",
    "\n",
    "\n",
    "    else:\n",
    "        source_train = source_data[\"train\"]\n",
    "        source_val = source_data[\"validation\"]\n",
    "        \n",
    "        n_subset = int(target_ids / source_ids)\n",
    "        target_test = []\n",
    "        for i in range(n_subset):\n",
    "            target_test.append(target_data[\"test\"][:,(i*source_ids): (i*source_ids + source_ids)])\n",
    "\n",
    "        target_fine_tuning = target_data[\"train\"][-24*28:,:source_ids]\n",
    "        ts_fine_tuning = TimeSeries.from_values(target_fine_tuning)\n",
    "\n",
    "    transformer, nhits, tsnmix = train_models(source_train, source_val, epochs=5)\n",
    "\n",
    "    zero_shot_loss = evaluate(transformer, nhits, tsnmix, target_test)\n",
    "    \n",
    "    return zero_shot_loss#, fine_tuning_loss\n",
    "\n",
    "\"\"\"\n",
    "    # now we do fine-tuning\n",
    "    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\n",
    "    one_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\n",
    "\n",
    "    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\n",
    "    two_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\n",
    "\n",
    "    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\n",
    "    three_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\n",
    "\n",
    "    transformer_model, nbeats_model, tsmixer_model = fine_tune_models(transformer_model, nbeats_model, tsmixer_model, ts_fine_tuning)\n",
    "    four_epoch_loss = evaluate(transformer, nhits, tsnmix, ts_test_target)\n",
    "\n",
    "    fine_tuning_loss = [one_epoch_loss, two_epoch_loss, three_epoch_loss, four_epoch_loss]\n",
    "\"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elec_to_bavaria': 0.00237484017468907,\n",
       " 'elec_to_eu': 1.4420697944454963,\n",
       " 'bavaria_to_elec': 9.55189398605458,\n",
       " 'bavaria_to_euro': 9.893485133281766,\n",
       " 'euro_to_bavaria': 0.002463448156121668,\n",
       " 'euro_to_elec': 1.541811576072317}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elec_to_bavaria': 0.002277523254883568,\n",
       " 'elec_to_eu': 1.016388186012315,\n",
       " 'bavaria_to_elec': 4.063811886484605,\n",
       " 'bavaria_to_euro': 3.042869932451673,\n",
       " 'euro_to_bavaria': 0.002474944778349619,\n",
       " 'euro_to_elec': 1.2644093441267084}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_nhits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'elec_to_bavaria': 2.406322558633574,\n",
       " 'elec_to_eu': 11.454085518858218,\n",
       " 'bavaria_to_elec': 1.3134613719082227,\n",
       " 'bavaria_to_euro': 34.74948891330017,\n",
       " 'euro_to_bavaria': 7.245469826918382,\n",
       " 'euro_to_elec': 1.7667600586466545}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_tsnmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.54it/s, train_loss=0.277, val_loss=0.521]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.50it/s, train_loss=0.277, val_loss=0.521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.56it/s, train_loss=0.159, val_loss=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.53it/s, train_loss=0.159, val_loss=0.690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.80it/s, train_loss=0.364, val_loss=0.448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.76it/s, train_loss=0.364, val_loss=0.448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.88it/s, train_loss=0.131, val_loss=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.84it/s, train_loss=0.131, val_loss=0.550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.43it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.40it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.24it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.21it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 30.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.12it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.09it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.66it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.64it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 29.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.28it/s, train_loss=0.302, val_loss=1.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.26it/s, train_loss=0.302, val_loss=1.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.04it/s, train_loss=0.248, val_loss=2.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.03it/s, train_loss=0.248, val_loss=2.050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 23.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.18it/s, train_loss=0.375, val_loss=0.767]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.17it/s, train_loss=0.375, val_loss=0.767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.88it/s, train_loss=0.434, val_loss=0.728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.87it/s, train_loss=0.434, val_loss=0.728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.16it/s, train_loss=0.211, val_loss=1.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.15it/s, train_loss=0.211, val_loss=1.260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.11it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_transformer = {}\n",
    "loss_nhits = {}\n",
    "loss_tsnmix = {}\n",
    "\n",
    "loss_transformer[\"elec_to_bavaria\"], loss_nhits[\"elec_to_bavaria\"], loss_tsnmix[\"elec_to_bavaria\"] = train_and_zero_shot(electricity_dict, bavaria_dict)\n",
    "loss_transformer[\"elec_to_eu\"], loss_nhits[\"elec_to_eu\"], loss_tsnmix[\"elec_to_eu\"] = train_and_zero_shot(electricity_dict, euro_dict)\n",
    "\n",
    "loss_transformer[\"bavaria_to_elec\"], loss_nhits[\"bavaria_to_elec\"], loss_tsnmix[\"bavaria_to_elec\"] = train_and_zero_shot(bavaria_dict, electricity_dict)\n",
    "loss_transformer[\"bavaria_to_euro\"], loss_nhits[\"bavaria_to_euro\"], loss_tsnmix[\"bavaria_to_euro\"] = train_and_zero_shot(bavaria_dict, euro_dict)\n",
    "\n",
    "loss_transformer[\"euro_to_bavaria\"], loss_nhits[\"euro_to_bavaria\"], loss_tsnmix[\"euro_to_bavaria\"] = train_and_zero_shot(euro_dict, bavaria_dict)\n",
    "loss_transformer[\"euro_to_elec\"], loss_nhits[\"euro_to_elec\"], loss_tsnmix[\"euro_to_elec\"] = train_and_zero_shot(euro_dict, electricity_dict)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
