{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# traini g using darts library\n",
    "\n",
    "TL using the same number of IDs is possible\n",
    "\n",
    "Reshaping does not seem possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from darts import TimeSeries\n",
    "from darts.utils.losses import *\n",
    "from darts.metrics import mse\n",
    "from darts.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import data_handling, helpers\n",
    "# use electricity dataset\n",
    "\n",
    "data_dict = data_handling.format_electricity()\n",
    "\n",
    "df = data_dict\n",
    "\n",
    "for key, value in df.items():\n",
    "\t\t\tdf[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "df[\"train\"], train_standardize_dict = helpers.custom_standardizer(df[\"train\"])\n",
    "df[\"validation\"], _ = helpers.custom_standardizer(df[\"validation\"], train_standardize_dict)\n",
    "df[\"test\"], _ = helpers.custom_standardizer(df[\"test\"], train_standardize_dict)\n",
    "\n",
    "ts_train = TimeSeries.from_values(df[\"train\"])\n",
    "ts_val = TimeSeries.from_values(df[\"validation\"])\n",
    "ts_test = TimeSeries.from_values(df[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# convert to datalaoder\n",
    "ts_bavaria_train = TimeSeries.from_values(bavaria_dict[\"train\"])\n",
    "ts_bavaria_val = TimeSeries.from_values(bavaria_dict[\"validation\"])\n",
    "ts_bavaria_test = TimeSeries.from_values(bavaria_dict[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    "\n",
    "# Slicing hyper-params:\n",
    "IN_LEN = 96\n",
    "OUT_LEN = 96\n",
    "\n",
    "# Architecture hyper-params:\n",
    "NUM_STACKS = 4\n",
    "NUM_BLOCKS = 1\n",
    "NUM_LAYERS = 2\n",
    "LAYER_WIDTH = 128\n",
    "COEFFS_DIM = 11\n",
    "\n",
    "# Training settings:\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "USE_REVIN = True\n",
    "\n",
    "LOSS_FN = torch.nn.MSELoss()\n",
    "\n",
    "# reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "nbeats_model = NBEATSModel(\n",
    "    input_chunk_length=IN_LEN,\n",
    "    output_chunk_length=OUT_LEN,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_stacks=NUM_STACKS,\n",
    "    num_blocks=NUM_BLOCKS,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    layer_widths=LAYER_WIDTH,\n",
    "    expansion_coefficient_dim=COEFFS_DIM,\n",
    "    loss_fn=LOSS_FN,\n",
    "    use_reversible_instance_norm=USE_REVIN,\n",
    "    optimizer_kwargs={\"lr\": LR},\n",
    "    pl_trainer_kwargs={\n",
    "        \"enable_progress_bar\": True,\n",
    "        # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "        \"accelerator\": \"gpu\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "transformer_model = TransformerModel(\n",
    "    input_chunk_length=IN_LEN, \n",
    "    output_chunk_length=OUT_LEN,\n",
    "    output_chunk_shift=0, \n",
    "    d_model=64, \n",
    "    nhead=4, \n",
    "    num_encoder_layers=3, \n",
    "    num_decoder_layers=3, \n",
    "    dim_feedforward=512, \n",
    "    dropout=0.1, \n",
    "    activation='relu', \n",
    "    loss_fn=LOSS_FN,\n",
    "    norm_type=None, \n",
    "    custom_encoder=None, \n",
    "    custom_decoder=None,\n",
    "    use_reversible_instance_norm=USE_REVIN,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "nbeats_model.fit(\n",
    "    ts_train,\n",
    "    num_loader_workers=4,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    max_samples_per_ts=None,\n",
    ")\n",
    "\n",
    "preds = nbeats_model.predict(n=96, series=ts_bavaria_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "transformer_model.fit(\n",
    "    ts_train[:][:66],\n",
    "    num_loader_workers=4,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    max_samples_per_ts=None,\n",
    ")\n",
    "\n",
    "preds = transformer_model.predict(n=96, series=ts_bavaria_test[0:96])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
