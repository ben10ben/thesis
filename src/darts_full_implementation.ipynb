{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel, NHiTSModel, TransformerModel, TSMixerModel\n",
    "from darts.utils.losses import *\n",
    "from darts.metrics import metrics as darts_metrics\n",
    "from utils import data_handling, helpers\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import config\n",
    "import copy\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "\n",
    "# Constants\n",
    "DEVICE = [1]\n",
    "IN_LEN = 96\n",
    "OUT_LEN = 96\n",
    "LOSS_FN = torch.nn.MSELoss()\n",
    "LAYER_WIDTH = 256\n",
    "NUM_STACKS = 4\n",
    "NUM_BLOCKS = 2\n",
    "NUM_LAYERS = 2\n",
    "COEFFS_DIM = 5\n",
    "DROPOUT = 0.25\n",
    "VERBOSE = True\n",
    "TRAIN_EPOCHS = 15\n",
    "TUNE_EPOCHS = 5\n",
    "four_weeks = -24*7*4\n",
    "LR = 0.005\n",
    "\n",
    "metrics_output_path = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"darts_metrics.csv\"\n",
    "\n",
    "model_path = config.CONFIG_MODEL_LOCATION[\"darts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_source_to_target_id_count(source, target):\n",
    "    source_id_count = source[\"train\"].shape[1]\n",
    "    target_id_count = target[\"train\"].shape[1]\n",
    "\n",
    "    full_repeats = target_id_count // source_id_count\n",
    "    remainder = target_id_count % source_id_count\n",
    "\n",
    "    repeated_tensor = source[\"train\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"train\"][:, :remainder]\n",
    "    source_train = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    \n",
    "    assert target_id_count == source_train.size(1), f\"Reshaping was incorrect. Target_train = {target_id_count}, source_train = {source_train.size(1)}.\"\n",
    "\n",
    "    repeated_tensor = source[\"validation\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"validation\"][:, :remainder]\n",
    "    source_validation = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    assert target_id_count == source_validation.size(1), f\"Reshaping was incorrect. Target_val = {target_id_count}, source_val = {source_validation.size(1)}.\"\n",
    "\n",
    "    return source_train, source_validation\n",
    "\n",
    "\n",
    "def process_tl_data(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    fine_tune_horizon = -24*7*4\n",
    "    target_test = target_data[\"test\"]\n",
    "    target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,:]\n",
    "\n",
    "    # remove IDs if source is bigger than target or\n",
    "    # repeat IDs if target is bigger than source\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_validation = source_data[\"validation\"][:,:target_ids]\n",
    "    else:\n",
    "        source_train, source_validation = extend_source_to_target_id_count(source_data, target_data)\n",
    "\n",
    "    # convert to TimeSeries dataframe\n",
    "    source_train = TimeSeries.from_values(source_train)\n",
    "    source_validation = TimeSeries.from_values(source_validation)\n",
    "    target_test = TimeSeries.from_values(target_test)\n",
    "    target_fine_tuning = TimeSeries.from_values(target_fine_tuning)\n",
    "    target_train = TimeSeries.from_values(target_data[\"train\"])\n",
    "    target_validation = TimeSeries.from_values(target_data[\"validation\"])\n",
    "\n",
    "    tl_dataset = {\n",
    "                    \"source_train\" : source_train,\n",
    "                    \"source_validation\" : source_validation,\n",
    "                    \"target_fine_tuning\" : target_fine_tuning,\n",
    "                    \"target_test\" : target_test,\n",
    "                    \"target_train\" : target_train,\n",
    "                    \"target_validation\" : target_validation\n",
    "                }\n",
    "\n",
    "    return tl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nhits(ts_train, ts_val, epochs=1):   \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    nhits_model = NHiTSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        activation='ReLU',\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        dropout=DROPOUT,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )\n",
    "\n",
    "    nhits_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nhits_model\n",
    "\n",
    "# Train NBEATS model\n",
    "def train_nbeats(ts_train, ts_val, epochs=1):   \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=32,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        activation='ReLU',\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )    \n",
    "\n",
    "    nbeats_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nbeats_model\n",
    "\n",
    "# Train Transformer model\n",
    "def train_transformer(ts_train, ts_val, epochs=1):    \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        d_model=LAYER_WIDTH, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=LAYER_WIDTH, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "        )\n",
    "    \n",
    "    transformer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return transformer_model \n",
    "\n",
    "# Train TSMixer model\n",
    "def train_tsmixer(ts_train, ts_val, epochs=1):    \n",
    "    TRAINER_ARGS = {\"enable_progress_bar\": True, \n",
    "                \"accelerator\": \"gpu\",  \n",
    "                \"devices\" : DEVICE,\n",
    "             }\n",
    "    \n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        hidden_size=LAYER_WIDTH, \n",
    "        ff_size=LAYER_WIDTH, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type='LayerNorm', \n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs=TRAINER_ARGS,\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return tsmixer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, target_test):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    Input:  -trained model\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: Dict{MSE, MAE}\n",
    "    \"\"\"\n",
    "\n",
    "    forecasting_endpoint = int(len(target_test)) - 96*2\n",
    "    window = [target_test[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "    target = [target_test[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    predictions = model.predict(n=96, series=window)\n",
    "\n",
    "    mse = darts_metrics.mse(predictions, target)\n",
    "    mae = darts_metrics.mae(predictions, target)\n",
    "\n",
    "    mse = sum(mse) / len(predictions)\n",
    "    mae = sum(mae) / len(predictions)\n",
    "\n",
    "    return {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "\n",
    "def fine_tune_model(model, target_fine_tuning, epochs=1):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    model.fit(\n",
    "            target_fine_tuning,\n",
    "            num_loader_workers=4,\n",
    "            epochs=epochs,\n",
    "            max_samples_per_ts=None,\n",
    "        )\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"4_weeks_train\"] = electricity_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "electricity_dict[\"4_weeks_train\"], _ = helpers.custom_standardizer(electricity_dict[\"4_weeks_train\"], train_standardize_dict)\n",
    "\n",
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "bavaria_dict[\"4_weeks_train\"] = bavaria_dict[\"train\"][four_weeks:,:]\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "gp_dict[\"4_weeks_train\"] = gp_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_setups = {\n",
    "    \"ELD_to_Bavaria\" : (electricity_dict, bavaria_dict), \n",
    "    \"ELD_to_GP2\" : (electricity_dict, gp_dict),\n",
    "    \"Bavaria_to_ELD\" : (bavaria_dict, electricity_dict), \n",
    "    \"Bavaria_to_GP2\" : (bavaria_dict, gp_dict), \n",
    "    \"GP2_to_Bavaria\": (gp_dict, bavaria_dict), \n",
    "    \"GP2_to_ELD\" : (gp_dict, electricity_dict)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELD_to_GP2\n",
      "Skipping Transformer for ELD_to_GP2 with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 2.9 K \n",
      "4 | encoder             | Linear              | 372 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 3.2 M \n",
      "7 | decoder             | Linear              | 35.9 M\n",
      "------------------------------------------------------------\n",
      "39.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.4 M    Total params\n",
      "157.661   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 314/314 [00:28<00:00, 11.17it/s, train_loss=0.777, val_loss=nan.0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 314/314 [00:28<00:00, 11.17it/s, train_loss=0.777, val_loss=nan.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:1159: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:242: RuntimeWarning: Mean of empty slice\n",
      "  vals = np.expand_dims(component_reduction(vals, axis=COMP_AX), axis=COMP_AX)\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/darts/metrics/metrics.py:783: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(\n",
      "/tmp/ipykernel_25723/1685300477.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_25723/1685300477.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MSE': nan, 'MAE': nan}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 2.9 K \n",
      "4 | encoder             | Linear              | 372 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 3.2 M \n",
      "7 | decoder             | Linear              | 35.9 M\n",
      "------------------------------------------------------------\n",
      "39.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "39.4 M    Total params\n",
      "157.661   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s, train_loss=0.766, val_loss=0.787]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 16/16 [00:02<00:00,  5.41it/s, train_loss=0.766, val_loss=0.787]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 11.96it/s]\n",
      "{'MSE': 1.0486344807326684, 'MAE': 0.666307353014484}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25723/1685300477.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_25723/1685300477.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NHiTS</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>TSMixer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setup</th>\n",
       "      <th>Learning_scenario</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.619146e-03</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.976792e-02</td>\n",
       "      <td>0.029754</td>\n",
       "      <td>0.034182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>4.697010e-04</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.075261e-02</td>\n",
       "      <td>0.010888</td>\n",
       "      <td>0.012290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.851176e-04</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>9.179015e-03</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.008743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.838999e-04</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.886287e-03</td>\n",
       "      <td>0.009180</td>\n",
       "      <td>0.009330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.550585e-04</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.074552e-02</td>\n",
       "      <td>0.011654</td>\n",
       "      <td>0.011714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.277600e-01</td>\n",
       "      <td>0.988170</td>\n",
       "      <td>1.233384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.164209e-01</td>\n",
       "      <td>0.656070</td>\n",
       "      <td>0.695620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.950743e-01</td>\n",
       "      <td>1.019768</td>\n",
       "      <td>0.865992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.413549e-01</td>\n",
       "      <td>0.660914</td>\n",
       "      <td>0.524999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.805492e-01</td>\n",
       "      <td>0.975071</td>\n",
       "      <td>0.657875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.532800e-01</td>\n",
       "      <td>0.647807</td>\n",
       "      <td>0.433311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.808304e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.674455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.499664e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.812819e+00</td>\n",
       "      <td>1.048634</td>\n",
       "      <td>1.053140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.286878e+00</td>\n",
       "      <td>0.666307</td>\n",
       "      <td>0.577975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.430658e+01</td>\n",
       "      <td>10.621312</td>\n",
       "      <td>13.597932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.264933e+00</td>\n",
       "      <td>2.885642</td>\n",
       "      <td>2.809807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>6.867430e-01</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>0.928438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.430946e-01</td>\n",
       "      <td>0.813232</td>\n",
       "      <td>0.802077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.637200e-01</td>\n",
       "      <td>0.947210</td>\n",
       "      <td>0.214651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.147567e-01</td>\n",
       "      <td>0.808654</td>\n",
       "      <td>0.300557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.588576e-01</td>\n",
       "      <td>0.947477</td>\n",
       "      <td>0.226847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.149607e-01</td>\n",
       "      <td>0.809668</td>\n",
       "      <td>0.309050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>4.340198e-01</td>\n",
       "      <td>0.953537</td>\n",
       "      <td>0.480004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.742046e-01</td>\n",
       "      <td>0.812253</td>\n",
       "      <td>0.485502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.035199e+06</td>\n",
       "      <td>7.735226</td>\n",
       "      <td>8.128555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.715389e+02</td>\n",
       "      <td>2.066784</td>\n",
       "      <td>2.061725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.555567e+02</td>\n",
       "      <td>1.073695</td>\n",
       "      <td>0.866328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.141571e+01</td>\n",
       "      <td>0.679530</td>\n",
       "      <td>0.532831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.348713e-01</td>\n",
       "      <td>0.975385</td>\n",
       "      <td>0.644111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.251944e-01</td>\n",
       "      <td>0.648239</td>\n",
       "      <td>0.428923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.746067e-01</td>\n",
       "      <td>0.975527</td>\n",
       "      <td>0.680707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.488926e-01</td>\n",
       "      <td>0.648849</td>\n",
       "      <td>0.443016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.160768e+00</td>\n",
       "      <td>1.045447</td>\n",
       "      <td>1.066945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>6.961357e-01</td>\n",
       "      <td>0.664533</td>\n",
       "      <td>0.584738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.653185e-03</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>0.001333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>3.008492e-02</td>\n",
       "      <td>0.030630</td>\n",
       "      <td>0.026276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.885315e-04</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.029623e-02</td>\n",
       "      <td>0.010714</td>\n",
       "      <td>0.011400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.770908e-04</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.000273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.923608e-03</td>\n",
       "      <td>0.009737</td>\n",
       "      <td>0.008793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.899523e-04</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>9.143972e-03</td>\n",
       "      <td>0.009527</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.392494e-04</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.000496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>9.836575e-03</td>\n",
       "      <td>0.011501</td>\n",
       "      <td>0.011267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>9.585188e-01</td>\n",
       "      <td>0.959904</td>\n",
       "      <td>0.864612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>8.120929e-01</td>\n",
       "      <td>0.811470</td>\n",
       "      <td>0.712851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>4.855094e-01</td>\n",
       "      <td>0.951312</td>\n",
       "      <td>0.311543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>5.192017e-01</td>\n",
       "      <td>0.812263</td>\n",
       "      <td>0.373766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.742451e-01</td>\n",
       "      <td>0.949924</td>\n",
       "      <td>0.214202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.240682e-01</td>\n",
       "      <td>0.810878</td>\n",
       "      <td>0.301724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>3.506920e-01</td>\n",
       "      <td>0.947826</td>\n",
       "      <td>0.211217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.104486e-01</td>\n",
       "      <td>0.808821</td>\n",
       "      <td>0.297806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>4.228264e-01</td>\n",
       "      <td>0.956393</td>\n",
       "      <td>0.373202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>4.639925e-01</td>\n",
       "      <td>0.813782</td>\n",
       "      <td>0.417805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  NHiTS  Transformer  \\\n",
       "Setup          Learning_scenario   Metric                              \n",
       "ELD_to_Bavaria Zero-Shot           MSE     1.619146e-03     0.001618   \n",
       "                                   MAE     2.976792e-02     0.029754   \n",
       "               four_weeks_tl       MSE     4.697010e-04     0.000492   \n",
       "                                   MAE     1.075261e-02     0.010888   \n",
       "               full_tl             MSE     2.851176e-04     0.000328   \n",
       "                                   MAE     9.179015e-03     0.009856   \n",
       "               full_training       MSE     2.838999e-04     0.000315   \n",
       "                                   MAE     8.886287e-03     0.009180   \n",
       "               four_weeks_training MSE     3.550585e-04     0.000502   \n",
       "                                   MAE     1.074552e-02     0.011654   \n",
       "ELD_to_GP2     Zero-Shot           MSE     9.277600e-01     0.988170   \n",
       "                                   MAE     6.164209e-01     0.656070   \n",
       "               four_weeks_tl       MSE     9.950743e-01     1.019768   \n",
       "                                   MAE     6.413549e-01     0.660914   \n",
       "               full_tl             MSE     9.805492e-01     0.975071   \n",
       "                                   MAE     6.532800e-01     0.647807   \n",
       "               full_training       MSE     9.808304e-01          NaN   \n",
       "                                   MAE     6.499664e-01          NaN   \n",
       "               four_weeks_training MSE     3.812819e+00     1.048634   \n",
       "                                   MAE     1.286878e+00     0.666307   \n",
       "Bavaria_to_ELD Zero-Shot           MSE     1.430658e+01    10.621312   \n",
       "                                   MAE     3.264933e+00     2.885642   \n",
       "               four_weeks_tl       MSE     6.867430e-01     0.959930   \n",
       "                                   MAE     6.430946e-01     0.813232   \n",
       "               full_tl             MSE     3.637200e-01     0.947210   \n",
       "                                   MAE     4.147567e-01     0.808654   \n",
       "               full_training       MSE     3.588576e-01     0.947477   \n",
       "                                   MAE     4.149607e-01     0.809668   \n",
       "               four_weeks_training MSE     4.340198e-01     0.953537   \n",
       "                                   MAE     4.742046e-01     0.812253   \n",
       "Bavaria_to_GP2 Zero-Shot           MSE     1.035199e+06     7.735226   \n",
       "                                   MAE     6.715389e+02     2.066784   \n",
       "               four_weeks_tl       MSE     3.555567e+02     1.073695   \n",
       "                                   MAE     1.141571e+01     0.679530   \n",
       "               full_tl             MSE     9.348713e-01     0.975385   \n",
       "                                   MAE     6.251944e-01     0.648239   \n",
       "               full_training       MSE     9.746067e-01     0.975527   \n",
       "                                   MAE     6.488926e-01     0.648849   \n",
       "               four_weeks_training MSE     1.160768e+00     1.045447   \n",
       "                                   MAE     6.961357e-01     0.664533   \n",
       "GP2_to_Bavaria Zero-Shot           MSE     1.653185e-03     0.001701   \n",
       "                                   MAE     3.008492e-02     0.030630   \n",
       "               four_weeks_tl       MSE     3.885315e-04     0.000488   \n",
       "                                   MAE     1.029623e-02     0.010714   \n",
       "               full_tl             MSE     2.770908e-04     0.000326   \n",
       "                                   MAE     8.923608e-03     0.009737   \n",
       "               full_training       MSE     2.899523e-04     0.000322   \n",
       "                                   MAE     9.143972e-03     0.009527   \n",
       "               four_weeks_training MSE     3.392494e-04     0.000499   \n",
       "                                   MAE     9.836575e-03     0.011501   \n",
       "GP2_to_ELD     Zero-Shot           MSE     9.585188e-01     0.959904   \n",
       "                                   MAE     8.120929e-01     0.811470   \n",
       "               four_weeks_tl       MSE     4.855094e-01     0.951312   \n",
       "                                   MAE     5.192017e-01     0.812263   \n",
       "               full_tl             MSE     3.742451e-01     0.949924   \n",
       "                                   MAE     4.240682e-01     0.810878   \n",
       "               full_training       MSE     3.506920e-01     0.947826   \n",
       "                                   MAE     4.104486e-01     0.808821   \n",
       "               four_weeks_training MSE     4.228264e-01     0.956393   \n",
       "                                   MAE     4.639925e-01     0.813782   \n",
       "\n",
       "                                             TSMixer  \n",
       "Setup          Learning_scenario   Metric             \n",
       "ELD_to_Bavaria Zero-Shot           MSE      0.002046  \n",
       "                                   MAE      0.034182  \n",
       "               four_weeks_tl       MSE      0.000521  \n",
       "                                   MAE      0.012290  \n",
       "               full_tl             MSE      0.000276  \n",
       "                                   MAE      0.008743  \n",
       "               full_training       MSE      0.000304  \n",
       "                                   MAE      0.009330  \n",
       "               four_weeks_training MSE      0.000504  \n",
       "                                   MAE      0.011714  \n",
       "ELD_to_GP2     Zero-Shot           MSE      1.233384  \n",
       "                                   MAE      0.695620  \n",
       "               four_weeks_tl       MSE      0.865992  \n",
       "                                   MAE      0.524999  \n",
       "               full_tl             MSE      0.657875  \n",
       "                                   MAE      0.433311  \n",
       "               full_training       MSE      0.674455  \n",
       "                                   MAE      0.441427  \n",
       "               four_weeks_training MSE      1.053140  \n",
       "                                   MAE      0.577975  \n",
       "Bavaria_to_ELD Zero-Shot           MSE     13.597932  \n",
       "                                   MAE      2.809807  \n",
       "               four_weeks_tl       MSE      0.928438  \n",
       "                                   MAE      0.802077  \n",
       "               full_tl             MSE      0.214651  \n",
       "                                   MAE      0.300557  \n",
       "               full_training       MSE      0.226847  \n",
       "                                   MAE      0.309050  \n",
       "               four_weeks_training MSE      0.480004  \n",
       "                                   MAE      0.485502  \n",
       "Bavaria_to_GP2 Zero-Shot           MSE      8.128555  \n",
       "                                   MAE      2.061725  \n",
       "               four_weeks_tl       MSE      0.866328  \n",
       "                                   MAE      0.532831  \n",
       "               full_tl             MSE      0.644111  \n",
       "                                   MAE      0.428923  \n",
       "               full_training       MSE      0.680707  \n",
       "                                   MAE      0.443016  \n",
       "               four_weeks_training MSE      1.066945  \n",
       "                                   MAE      0.584738  \n",
       "GP2_to_Bavaria Zero-Shot           MSE      0.001333  \n",
       "                                   MAE      0.026276  \n",
       "               four_weeks_tl       MSE      0.000482  \n",
       "                                   MAE      0.011400  \n",
       "               full_tl             MSE      0.000273  \n",
       "                                   MAE      0.008793  \n",
       "               full_training       MSE      0.000301  \n",
       "                                   MAE      0.009010  \n",
       "               four_weeks_training MSE      0.000496  \n",
       "                                   MAE      0.011267  \n",
       "GP2_to_ELD     Zero-Shot           MSE      0.864612  \n",
       "                                   MAE      0.712851  \n",
       "               four_weeks_tl       MSE      0.311543  \n",
       "                                   MAE      0.373766  \n",
       "               full_tl             MSE      0.214202  \n",
       "                                   MAE      0.301724  \n",
       "               full_training       MSE      0.211217  \n",
       "                                   MAE      0.297806  \n",
       "               four_weeks_training MSE      0.373202  \n",
       "                                   MAE      0.417805  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    \"NHiTS\": train_nhits,\n",
    "  #  \"NBEATS\": train_nbeats,\n",
    "    \"Transformer\": train_transformer,\n",
    "    \"TSMixer\": train_tsmixer\n",
    "}\n",
    "\n",
    "# Initialize the DataFrame\n",
    "try:\n",
    "    results_df = pd.read_csv(metrics_output_path, index_col=[0, 1, 2])\n",
    "except FileNotFoundError:\n",
    "    metrics = [\"MSE\", \"MAE\"]\n",
    "    learning_scenarios = [\"Zero-Shot\", \"four_weeks_tl\", \"full_tl\", \"full_training\", \"four_weeks_training\"]\n",
    "    index = pd.MultiIndex.from_product([tl_setups.keys(), learning_scenarios, metrics], names=[\"Setup\", \"Learning_scenario\", \"Metric\"])\n",
    "    results_df = pd.DataFrame(columns=models.keys(), index=index)\n",
    "\n",
    "# Helper functions\n",
    "def update_metrics(setup_name, model_name, learning_scenario, mae, mse):\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
    "\n",
    "def is_metric_filled(setup_name, model_name, learning_scenario):\n",
    "    # Check if specific metrics for a model in a setup and fine-tuning scenario are NaN or not\n",
    "    metrics_filled = not results_df.loc[(setup_name, learning_scenario, slice(None)), model_name].isnull().any()\n",
    "    return metrics_filled\n",
    "\n",
    "def run_model_tl(setup_name, tl_data):\n",
    "    source_train = tl_data[\"source_train\"]\n",
    "    source_val = tl_data[\"source_validation\"]\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "    #target_val = tl_data[\"target_validation\"]\n",
    "\n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"full_tl\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with full fine-tuning as metrics are already filled.\")\n",
    "            continue\n",
    "        \n",
    "        # Train model with source dataset (Zero-Shot)\n",
    "        model = model_func(source_train, source_val, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "\n",
    "        # Create deep copy for full fine-tuning\n",
    "        full_tl_model = copy.deepcopy(model)\n",
    "\n",
    "        update_metrics(setup_name, model_name, \"Zero-Shot\", metrics['MAE'], metrics['MSE'])\n",
    "        print(f\"Metrics updated for {model_name} in {setup_name} with zero-shot fine-tuning: MAE = {metrics['MAE']}, MSE = {metrics['MSE']}\")\n",
    "        \n",
    "        # Fine-tune on small target train set (four_weeks_tl)\n",
    "        model = fine_tune_model(model, target_fine_tuning, epochs=TUNE_EPOCHS + 5)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"four_weeks_tl\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Fine-tune on full target train set (full_tl)\n",
    "        full_tl_model = fine_tune_model(full_tl_model, target_train, epochs=TUNE_EPOCHS)\n",
    "        metrics = evaluate(full_tl_model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"full_tl\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Save after every dataset combination\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "def train_baselines(setup_name, tl_data):\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "    target_validation = tl_data[\"target_validation\"]\n",
    "\n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"four_weeks_training\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with as metrics are already filled.\")\n",
    "            continue\n",
    "\n",
    "        # Train on full target train set (full_training)\n",
    "        model = model_func(target_train, target_validation, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"full_training\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Train on short target train set (four_weeks_training)\n",
    "        model = model_func(target_fine_tuning, target_validation, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"four_weeks_training\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "# Execute for each setup and fine-tuning scenario\n",
    "for setup_name, (source_data, target_data) in tl_setups.items():\n",
    "    print(setup_name)\n",
    "    tl_data = process_tl_data(source_data, target_data)\n",
    "    run_model_tl(setup_name, tl_data)\n",
    "    train_baselines(setup_name, tl_data)\n",
    "\n",
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
