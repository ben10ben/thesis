{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import NBEATSModel, NHiTSModel, TransformerModel, TSMixerModel\n",
    "from darts.utils.losses import *\n",
    "from darts.metrics import metrics as darts_metrics\n",
    "from utils import data_handling, helpers\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import config\n",
    "import copy\n",
    "\n",
    "# Constants\n",
    "DEVICE = [1]\n",
    "NUM_EPOCHS = 5\n",
    "IN_LEN = 96\n",
    "OUT_LEN = 96\n",
    "LOSS_FN = torch.nn.MSELoss()\n",
    "LAYER_WIDTH = 256\n",
    "NUM_STACKS = 4\n",
    "NUM_BLOCKS = 2\n",
    "NUM_LAYERS = 2\n",
    "COEFFS_DIM = 5\n",
    "DROPOUT = 0.2\n",
    "VERBOSE = False\n",
    "TRAIN_EPOCHS = 15\n",
    "TUNE_EPOCHS = 5\n",
    "four_weeks = -24*7*4\n",
    "\n",
    "metrics_output_path = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"darts_metrics.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_source_to_target_id_count(source, target):\n",
    "    source_id_count = source[\"train\"].shape[1]\n",
    "    target_id_count = target[\"train\"].shape[1]\n",
    "\n",
    "    full_repeats = target_id_count // source_id_count\n",
    "    remainder = target_id_count % source_id_count\n",
    "\n",
    "    repeated_tensor = source[\"train\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"train\"][:, :remainder]\n",
    "    source_train = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    \n",
    "    assert target_id_count == source_train.size(1), f\"Reshaping was incorrect. Target_train = {target_id_count}, source_train = {source_train.size(1)}.\"\n",
    "\n",
    "    repeated_tensor = source[\"validation\"].repeat(1, full_repeats)\n",
    "    remainder_tensor = source[\"validation\"][:, :remainder]\n",
    "    source_validation = torch.cat((repeated_tensor, remainder_tensor), dim=1)\n",
    "    assert target_id_count == source_validation.size(1), f\"Reshaping was incorrect. Target_val = {target_id_count}, source_val = {source_validation.size(1)}.\"\n",
    "\n",
    "    return source_train, source_validation\n",
    "\n",
    "\n",
    "def process_tl_data(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    fine_tune_horizon = -24*7*4\n",
    "    target_test = target_data[\"test\"]\n",
    "    target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,:]\n",
    "\n",
    "    # remove IDs if source is bigger than target or\n",
    "    # repeat IDs if target is bigger than source\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_validation = source_data[\"validation\"][:,:target_ids]\n",
    "    else:\n",
    "        source_train, source_validation = extend_source_to_target_id_count(source_data, target_data)\n",
    "\n",
    "    # convert to TimeSeries dataframe\n",
    "    source_train = TimeSeries.from_values(source_train)\n",
    "    source_validation = TimeSeries.from_values(source_validation)\n",
    "    target_test = TimeSeries.from_values(target_test)\n",
    "    target_fine_tuning = TimeSeries.from_values(target_fine_tuning)\n",
    "    target_train = TimeSeries.from_values(target_data[\"train\"])\n",
    "    target_validation = TimeSeries.from_values(target_data[\"validation\"])\n",
    "\n",
    "    tl_dataset = {\n",
    "                    \"source_train\" : source_train,\n",
    "                    \"source_validation\" : source_validation,\n",
    "                    \"target_fine_tuning\" : target_fine_tuning,\n",
    "                    \"target_test\" : target_test,\n",
    "                    \"target_train\" : target_train,\n",
    "                    \"target_validation\" : target_validation\n",
    "                }\n",
    "\n",
    "    return tl_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nhits(ts_train, ts_val, epochs=1):\n",
    "    nhits_model = NHiTSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        activation='ReLU',\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        dropout=DROPOUT,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs={\"enable_progress_bar\": True, \"accelerator\": \"gpu\",  \"devices\" : DEVICE},\n",
    "    )\n",
    "    nhits_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nhits_model\n",
    "\n",
    "# Train NBEATS model\n",
    "def train_nbeats(ts_train, ts_val, epochs=1):\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=32,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        activation='ReLU',\n",
    "        #optimizer_kwargs={\"lr\": 0.0005},\n",
    "        pl_trainer_kwargs={\"enable_progress_bar\": True, \"accelerator\": \"gpu\",  \"devices\" : DEVICE},\n",
    "    )\n",
    "    nbeats_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return nbeats_model\n",
    "\n",
    "# Train Transformer model\n",
    "def train_transformer(ts_train, ts_val, epochs=1):\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        d_model=LAYER_WIDTH, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=LAYER_WIDTH, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs={\"enable_progress_bar\": True, \"accelerator\": \"gpu\",  \"devices\" : DEVICE},\n",
    "\n",
    "    )\n",
    "    transformer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return transformer_model\n",
    "\n",
    "# Train TSMixer model\n",
    "def train_tsmixer(ts_train, ts_val, epochs=1):\n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        hidden_size=LAYER_WIDTH, \n",
    "        ff_size=LAYER_WIDTH, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type='LayerNorm', \n",
    "        use_reversible_instance_norm=True,\n",
    "        pl_trainer_kwargs={\"enable_progress_bar\": True, \"accelerator\": \"gpu\", \"devices\" : DEVICE},\n",
    "\n",
    "    )\n",
    "    tsmixer_model.fit(ts_train, val_series=ts_val, epochs=epochs, verbose=VERBOSE)\n",
    "    return tsmixer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, target_test):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    Input:  -trained model\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: Dict{MSE, MAE}\n",
    "    \"\"\"\n",
    "\n",
    "    forecasting_endpoint = int(len(target_test)) - 96*2\n",
    "    window = [target_test[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "    target = [target_test[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    predictions = model.predict(n=96, series=window)\n",
    "\n",
    "    mse = darts_metrics.mse(predictions, target)\n",
    "    mae = darts_metrics.mae(predictions, target)\n",
    "\n",
    "    mse = sum(mse) / len(predictions)\n",
    "    mae = sum(mae) / len(predictions)\n",
    "\n",
    "    return {'MSE': mse, 'MAE': mae}\n",
    "\n",
    "\n",
    "def fine_tune_model(model, target_fine_tuning, epochs=1):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    model.fit(\n",
    "            target_fine_tuning,\n",
    "            num_loader_workers=4,\n",
    "            epochs=epochs,\n",
    "            max_samples_per_ts=None,\n",
    "        )\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"4_weeks_train\"] = electricity_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "electricity_dict[\"4_weeks_train\"], _ = helpers.custom_standardizer(electricity_dict[\"4_weeks_train\"], train_standardize_dict)\n",
    "\n",
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "bavaria_dict[\"4_weeks_train\"] = bavaria_dict[\"train\"][four_weeks:,:]\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "gp_dict[\"4_weeks_train\"] = gp_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_setups = {\n",
    "    \"ELD_to_Bavaria\" : (electricity_dict, bavaria_dict), \n",
    "    \"ELD_to_GP2\" : (electricity_dict, gp_dict),\n",
    "    \"Bavaria_to_ELD\" : (bavaria_dict, electricity_dict), \n",
    "    \"Bavaria_to_GP2\" : (bavaria_dict, gp_dict), \n",
    "    \"GP2_to_Bavaria\": (gp_dict, bavaria_dict), \n",
    "    \"GP2_to_ELD\" : (gp_dict, electricity_dict)\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ELD_to_Bavaria\n",
      "Skipping NHiTS for ELD_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping NBEATS for ELD_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping NHiTS for ELD_to_Bavaria with as metrics are already filled.\n",
      "Skipping NBEATS for ELD_to_Bavaria with as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_Bavaria with as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_Bavaria with as metrics are already filled.\n",
      "ELD_to_GP2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/torch/random.py:107: UserWarning: CUDA reports that you have 3 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of GPUs.  If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using.  For example, if you are using CPU only, set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.\n",
      "  warnings.warn(\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for NHiTS in ELD_to_GP2 with zero-shot fine-tuning: MAE = 0.6177704326631382, MSE = 0.9489661906820329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 2.9 K \n",
      "4 | stacks        | ModuleList       | 308 M \n",
      "---------------------------------------------------\n",
      "272 M     Trainable params\n",
      "35.9 M    Non-trainable params\n",
      "308 M     Total params\n",
      "1,232.630 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 13.71it/s, train_loss=0.544]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 13.70it/s, train_loss=0.544]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 16.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 2.9 K \n",
      "4 | stacks        | ModuleList       | 308 M \n",
      "---------------------------------------------------\n",
      "272 M     Trainable params\n",
      "35.9 M    Non-trainable params\n",
      "308 M     Total params\n",
      "1,232.630 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:16<00:00, 18.49it/s, train_loss=2.430]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:16<00:00, 18.49it/s, train_loss=2.430]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.21it/s]\n",
      "Skipping NBEATS for ELD_to_GP2 with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping NBEATS for ELD_to_GP2 with as metrics are already filled.\n",
      "Skipping Transformer for ELD_to_GP2 with as metrics are already filled.\n",
      "Skipping TSMixer for ELD_to_GP2 with as metrics are already filled.\n",
      "Bavaria_to_ELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 30.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 696   \n",
      "4 | stacks        | ModuleList       | 74.2 M\n",
      "---------------------------------------------------\n",
      "65.6 M    Trainable params\n",
      "8.6 M     Non-trainable params\n",
      "74.2 M    Total params\n",
      "296.622   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for NHiTS in Bavaria_to_ELD with zero-shot fine-tuning: MAE = 2.7001973814772864, MSE = 10.242844864399764\n",
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 16.59it/s, train_loss=0.540]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 16.54it/s, train_loss=0.540]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 32.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 696   \n",
      "4 | stacks        | ModuleList       | 74.2 M\n",
      "---------------------------------------------------\n",
      "65.6 M    Trainable params\n",
      "8.6 M     Non-trainable params\n",
      "74.2 M    Total params\n",
      "296.622   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:05<00:00, 29.88it/s, train_loss=0.216]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:05<00:00, 29.86it/s, train_loss=0.216]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 30.98it/s]\n",
      "Skipping NBEATS for Bavaria_to_ELD with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.08it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping NBEATS for Bavaria_to_ELD with as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_ELD with as metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_ELD with as metrics are already filled.\n",
      "Bavaria_to_GP2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 16.33it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for NHiTS in Bavaria_to_GP2 with zero-shot fine-tuning: MAE = 11.542150590275934, MSE = 466.38008264475377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 2.9 K \n",
      "4 | stacks        | ModuleList       | 308 M \n",
      "---------------------------------------------------\n",
      "272 M     Trainable params\n",
      "35.9 M    Non-trainable params\n",
      "308 M     Total params\n",
      "1,232.630 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 11.76it/s, train_loss=0.863] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 11.74it/s, train_loss=0.863]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 2.9 K \n",
      "4 | stacks        | ModuleList       | 308 M \n",
      "---------------------------------------------------\n",
      "272 M     Trainable params\n",
      "35.9 M    Non-trainable params\n",
      "308 M     Total params\n",
      "1,232.630 Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:17<00:00, 18.35it/s, train_loss=0.510]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 314/314 [00:17<00:00, 18.35it/s, train_loss=0.510]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.63it/s]\n",
      "Skipping NBEATS for Bavaria_to_GP2 with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_GP2 with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_GP2 with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 15.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 14.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping NBEATS for Bavaria_to_GP2 with as metrics are already filled.\n",
      "Skipping Transformer for Bavaria_to_GP2 with as metrics are already filled.\n",
      "Skipping TSMixer for Bavaria_to_GP2 with as metrics are already filled.\n",
      "GP2_to_Bavaria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 22.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 118   \n",
      "4 | stacks        | ModuleList       | 13.0 M\n",
      "---------------------------------------------------\n",
      "11.6 M    Trainable params\n",
      "1.5 M     Non-trainable params\n",
      "13.0 M    Total params\n",
      "52.043    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for NHiTS in GP2_to_Bavaria with zero-shot fine-tuning: MAE = 0.06976689363011357, MSE = 0.012210232356058745\n",
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 16.66it/s, train_loss=6.54e-5] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:00<00:00, 16.57it/s, train_loss=6.54e-5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 40.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 118   \n",
      "4 | stacks        | ModuleList       | 13.0 M\n",
      "---------------------------------------------------\n",
      "11.6 M    Trainable params\n",
      "1.5 M     Non-trainable params\n",
      "13.0 M    Total params\n",
      "52.043    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 304/304 [00:08<00:00, 33.96it/s, train_loss=0.000224]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 304/304 [00:08<00:00, 33.95it/s, train_loss=0.000224]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 33.19it/s]\n",
      "Skipping NBEATS for GP2_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 40.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 42.71it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping NBEATS for GP2_to_Bavaria with as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_Bavaria with as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_Bavaria with as metrics are already filled.\n",
      "GP2_to_ELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 31.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 696   \n",
      "4 | stacks        | ModuleList       | 74.2 M\n",
      "---------------------------------------------------\n",
      "65.6 M    Trainable params\n",
      "8.6 M     Non-trainable params\n",
      "74.2 M    Total params\n",
      "296.622   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics updated for NHiTS in GP2_to_ELD with zero-shot fine-tuning: MAE = 0.7101486052257301, MSE = 0.7841474201774945\n",
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 15.89it/s, train_loss=0.426]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 16/16 [00:01<00:00, 15.85it/s, train_loss=0.426]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 696   \n",
      "4 | stacks        | ModuleList       | 74.2 M\n",
      "---------------------------------------------------\n",
      "65.6 M    Trainable params\n",
      "8.6 M     Non-trainable params\n",
      "74.2 M    Total params\n",
      "296.622   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:04<00:00, 31.37it/s, train_loss=0.218]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:04<00:00, 31.35it/s, train_loss=0.218]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 28.44it/s]\n",
      "Skipping NBEATS for GP2_to_ELD with full fine-tuning as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_ELD with full fine-tuning as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with full fine-tuning as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 31.84it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 32.17it/s]\n",
      "Skipping NBEATS for GP2_to_ELD with as metrics are already filled.\n",
      "Skipping Transformer for GP2_to_ELD with as metrics are already filled.\n",
      "Skipping TSMixer for GP2_to_ELD with as metrics are already filled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15329/3755901336.py:19: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_15329/3755901336.py:20: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NHiTS</th>\n",
       "      <th>NBEATS</th>\n",
       "      <th>Transformer</th>\n",
       "      <th>TSMixer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setup</th>\n",
       "      <th>Learning_scenario</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.001162</td>\n",
       "      <td>1.088641e-03</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.001446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.024192</td>\n",
       "      <td>2.262520e-02</td>\n",
       "      <td>0.029292</td>\n",
       "      <td>0.027051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000353</td>\n",
       "      <td>5.003704e-04</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010298</td>\n",
       "      <td>1.153545e-02</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.010788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000305</td>\n",
       "      <td>3.152571e-04</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009601</td>\n",
       "      <td>9.828738e-03</td>\n",
       "      <td>0.009249</td>\n",
       "      <td>0.009016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000299</td>\n",
       "      <td>2.923995e-04</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009047</td>\n",
       "      <td>9.455105e-03</td>\n",
       "      <td>0.009248</td>\n",
       "      <td>0.009517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000368</td>\n",
       "      <td>5.265365e-04</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010557</td>\n",
       "      <td>1.164277e-02</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>0.012096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.948966</td>\n",
       "      <td>9.630598e+15</td>\n",
       "      <td>1.345365</td>\n",
       "      <td>1.367015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.617770</td>\n",
       "      <td>3.994391e+07</td>\n",
       "      <td>0.746985</td>\n",
       "      <td>0.759479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.819147</td>\n",
       "      <td>9.964590e+24</td>\n",
       "      <td>0.884830</td>\n",
       "      <td>0.913649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.541397</td>\n",
       "      <td>2.019681e+12</td>\n",
       "      <td>0.550886</td>\n",
       "      <td>0.535208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.270368</td>\n",
       "      <td>9.505193e+15</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.720716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.713655</td>\n",
       "      <td>5.947970e+07</td>\n",
       "      <td>0.431981</td>\n",
       "      <td>0.464716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.659480</td>\n",
       "      <td>4.650204e+13</td>\n",
       "      <td>0.633795</td>\n",
       "      <td>0.760106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.464154</td>\n",
       "      <td>3.837060e+06</td>\n",
       "      <td>0.423486</td>\n",
       "      <td>0.469301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.824351</td>\n",
       "      <td>1.669291e+14</td>\n",
       "      <td>0.873530</td>\n",
       "      <td>1.129679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.533056</td>\n",
       "      <td>7.476788e+06</td>\n",
       "      <td>0.525252</td>\n",
       "      <td>0.605395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>10.242845</td>\n",
       "      <td>5.666167e+20</td>\n",
       "      <td>9.365124</td>\n",
       "      <td>11.590646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>2.700197</td>\n",
       "      <td>1.062929e+10</td>\n",
       "      <td>2.690222</td>\n",
       "      <td>2.995148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.427707</td>\n",
       "      <td>1.846429e+16</td>\n",
       "      <td>0.952589</td>\n",
       "      <td>0.471168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.474106</td>\n",
       "      <td>7.225413e+07</td>\n",
       "      <td>0.813099</td>\n",
       "      <td>0.481619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.286422</td>\n",
       "      <td>2.197332e+06</td>\n",
       "      <td>0.321436</td>\n",
       "      <td>0.224299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.362894</td>\n",
       "      <td>1.061997e+03</td>\n",
       "      <td>0.375718</td>\n",
       "      <td>0.310464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.279225</td>\n",
       "      <td>2.779544e+06</td>\n",
       "      <td>0.310126</td>\n",
       "      <td>0.235956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.360106</td>\n",
       "      <td>1.164405e+03</td>\n",
       "      <td>0.363413</td>\n",
       "      <td>0.315740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.380317</td>\n",
       "      <td>2.762714e+09</td>\n",
       "      <td>0.407014</td>\n",
       "      <td>0.318748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.431907</td>\n",
       "      <td>3.819075e+04</td>\n",
       "      <td>0.444487</td>\n",
       "      <td>0.378217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>466.380083</td>\n",
       "      <td>1.561072e+21</td>\n",
       "      <td>7.924194</td>\n",
       "      <td>7.015851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>11.542151</td>\n",
       "      <td>1.603994e+10</td>\n",
       "      <td>2.090798</td>\n",
       "      <td>1.805375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>1.016150</td>\n",
       "      <td>9.454969e+19</td>\n",
       "      <td>1.129054</td>\n",
       "      <td>0.905254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.656820</td>\n",
       "      <td>3.837765e+09</td>\n",
       "      <td>0.663105</td>\n",
       "      <td>0.580962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.658909</td>\n",
       "      <td>1.565711e+13</td>\n",
       "      <td>0.652067</td>\n",
       "      <td>0.735345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.458732</td>\n",
       "      <td>2.279997e+06</td>\n",
       "      <td>0.435838</td>\n",
       "      <td>0.466485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.684025</td>\n",
       "      <td>6.799420e+14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.751727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.479501</td>\n",
       "      <td>1.416744e+07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.464294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.824021</td>\n",
       "      <td>5.312447e+17</td>\n",
       "      <td>0.914506</td>\n",
       "      <td>1.067181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.529945</td>\n",
       "      <td>4.333730e+08</td>\n",
       "      <td>0.533531</td>\n",
       "      <td>0.590445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.012210</td>\n",
       "      <td>8.759797e-03</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.002799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.069767</td>\n",
       "      <td>5.770039e-02</td>\n",
       "      <td>0.028474</td>\n",
       "      <td>0.038123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000589</td>\n",
       "      <td>1.022711e-03</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.014388</td>\n",
       "      <td>2.032992e-02</td>\n",
       "      <td>0.011165</td>\n",
       "      <td>0.010852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>3.025456e-04</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009276</td>\n",
       "      <td>9.730158e-03</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.009622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000301</td>\n",
       "      <td>3.206283e-04</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.000344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.009136</td>\n",
       "      <td>9.783117e-03</td>\n",
       "      <td>0.009070</td>\n",
       "      <td>0.009595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000377</td>\n",
       "      <td>5.235213e-04</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.010759</td>\n",
       "      <td>1.157042e-02</td>\n",
       "      <td>0.011608</td>\n",
       "      <td>0.011853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.784147</td>\n",
       "      <td>2.328977e+04</td>\n",
       "      <td>1.243249</td>\n",
       "      <td>1.326016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.710149</td>\n",
       "      <td>8.976374e+01</td>\n",
       "      <td>0.867076</td>\n",
       "      <td>0.883588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.401205</td>\n",
       "      <td>3.652951e+14</td>\n",
       "      <td>0.465202</td>\n",
       "      <td>0.312831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.450909</td>\n",
       "      <td>1.352897e+07</td>\n",
       "      <td>0.495156</td>\n",
       "      <td>0.379233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.288997</td>\n",
       "      <td>7.574842e+06</td>\n",
       "      <td>0.322184</td>\n",
       "      <td>0.223821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.365012</td>\n",
       "      <td>1.767878e+03</td>\n",
       "      <td>0.376486</td>\n",
       "      <td>0.308111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.266065</td>\n",
       "      <td>9.267395e+04</td>\n",
       "      <td>0.302426</td>\n",
       "      <td>0.233886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.349649</td>\n",
       "      <td>2.189598e+02</td>\n",
       "      <td>0.364883</td>\n",
       "      <td>0.314118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.376849</td>\n",
       "      <td>3.667518e+08</td>\n",
       "      <td>0.426265</td>\n",
       "      <td>0.349006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.426945</td>\n",
       "      <td>1.195014e+04</td>\n",
       "      <td>0.456393</td>\n",
       "      <td>0.391751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                NHiTS        NBEATS  \\\n",
       "Setup          Learning_scenario   Metric                             \n",
       "ELD_to_Bavaria Zero-Shot           MSE       0.001162  1.088641e-03   \n",
       "                                   MAE       0.024192  2.262520e-02   \n",
       "               four_weeks_tl       MSE       0.000353  5.003704e-04   \n",
       "                                   MAE       0.010298  1.153545e-02   \n",
       "               full_tl             MSE       0.000305  3.152571e-04   \n",
       "                                   MAE       0.009601  9.828738e-03   \n",
       "               full_training       MSE       0.000299  2.923995e-04   \n",
       "                                   MAE       0.009047  9.455105e-03   \n",
       "               four_weeks_training MSE       0.000368  5.265365e-04   \n",
       "                                   MAE       0.010557  1.164277e-02   \n",
       "ELD_to_GP2     Zero-Shot           MSE       0.948966  9.630598e+15   \n",
       "                                   MAE       0.617770  3.994391e+07   \n",
       "               four_weeks_tl       MSE       0.819147  9.964590e+24   \n",
       "                                   MAE       0.541397  2.019681e+12   \n",
       "               full_tl             MSE       1.270368  9.505193e+15   \n",
       "                                   MAE       0.713655  5.947970e+07   \n",
       "               full_training       MSE       0.659480  4.650204e+13   \n",
       "                                   MAE       0.464154  3.837060e+06   \n",
       "               four_weeks_training MSE       0.824351  1.669291e+14   \n",
       "                                   MAE       0.533056  7.476788e+06   \n",
       "Bavaria_to_ELD Zero-Shot           MSE      10.242845  5.666167e+20   \n",
       "                                   MAE       2.700197  1.062929e+10   \n",
       "               four_weeks_tl       MSE       0.427707  1.846429e+16   \n",
       "                                   MAE       0.474106  7.225413e+07   \n",
       "               full_tl             MSE       0.286422  2.197332e+06   \n",
       "                                   MAE       0.362894  1.061997e+03   \n",
       "               full_training       MSE       0.279225  2.779544e+06   \n",
       "                                   MAE       0.360106  1.164405e+03   \n",
       "               four_weeks_training MSE       0.380317  2.762714e+09   \n",
       "                                   MAE       0.431907  3.819075e+04   \n",
       "Bavaria_to_GP2 Zero-Shot           MSE     466.380083  1.561072e+21   \n",
       "                                   MAE      11.542151  1.603994e+10   \n",
       "               four_weeks_tl       MSE       1.016150  9.454969e+19   \n",
       "                                   MAE       0.656820  3.837765e+09   \n",
       "               full_tl             MSE       0.658909  1.565711e+13   \n",
       "                                   MAE       0.458732  2.279997e+06   \n",
       "               full_training       MSE       0.684025  6.799420e+14   \n",
       "                                   MAE       0.479501  1.416744e+07   \n",
       "               four_weeks_training MSE       0.824021  5.312447e+17   \n",
       "                                   MAE       0.529945  4.333730e+08   \n",
       "GP2_to_Bavaria Zero-Shot           MSE       0.012210  8.759797e-03   \n",
       "                                   MAE       0.069767  5.770039e-02   \n",
       "               four_weeks_tl       MSE       0.000589  1.022711e-03   \n",
       "                                   MAE       0.014388  2.032992e-02   \n",
       "               full_tl             MSE       0.000293  3.025456e-04   \n",
       "                                   MAE       0.009276  9.730158e-03   \n",
       "               full_training       MSE       0.000301  3.206283e-04   \n",
       "                                   MAE       0.009136  9.783117e-03   \n",
       "               four_weeks_training MSE       0.000377  5.235213e-04   \n",
       "                                   MAE       0.010759  1.157042e-02   \n",
       "GP2_to_ELD     Zero-Shot           MSE       0.784147  2.328977e+04   \n",
       "                                   MAE       0.710149  8.976374e+01   \n",
       "               four_weeks_tl       MSE       0.401205  3.652951e+14   \n",
       "                                   MAE       0.450909  1.352897e+07   \n",
       "               full_tl             MSE       0.288997  7.574842e+06   \n",
       "                                   MAE       0.365012  1.767878e+03   \n",
       "               full_training       MSE       0.266065  9.267395e+04   \n",
       "                                   MAE       0.349649  2.189598e+02   \n",
       "               four_weeks_training MSE       0.376849  3.667518e+08   \n",
       "                                   MAE       0.426945  1.195014e+04   \n",
       "\n",
       "                                           Transformer    TSMixer  \n",
       "Setup          Learning_scenario   Metric                          \n",
       "ELD_to_Bavaria Zero-Shot           MSE        0.001630   0.001446  \n",
       "                                   MAE        0.029292   0.027051  \n",
       "               four_weeks_tl       MSE        0.000488   0.000472  \n",
       "                                   MAE        0.010999   0.010788  \n",
       "               full_tl             MSE        0.000318   0.000299  \n",
       "                                   MAE        0.009249   0.009016  \n",
       "               full_training       MSE        0.000316   0.000359  \n",
       "                                   MAE        0.009248   0.009517  \n",
       "               four_weeks_training MSE        0.000497   0.000546  \n",
       "                                   MAE        0.010906   0.012096  \n",
       "ELD_to_GP2     Zero-Shot           MSE        1.345365   1.367015  \n",
       "                                   MAE        0.746985   0.759479  \n",
       "               four_weeks_tl       MSE        0.884830   0.913649  \n",
       "                                   MAE        0.550886   0.535208  \n",
       "               full_tl             MSE        0.642056   0.720716  \n",
       "                                   MAE        0.431981   0.464716  \n",
       "               full_training       MSE        0.633795   0.760106  \n",
       "                                   MAE        0.423486   0.469301  \n",
       "               four_weeks_training MSE        0.873530   1.129679  \n",
       "                                   MAE        0.525252   0.605395  \n",
       "Bavaria_to_ELD Zero-Shot           MSE        9.365124  11.590646  \n",
       "                                   MAE        2.690222   2.995148  \n",
       "               four_weeks_tl       MSE        0.952589   0.471168  \n",
       "                                   MAE        0.813099   0.481619  \n",
       "               full_tl             MSE        0.321436   0.224299  \n",
       "                                   MAE        0.375718   0.310464  \n",
       "               full_training       MSE        0.310126   0.235956  \n",
       "                                   MAE        0.363413   0.315740  \n",
       "               four_weeks_training MSE        0.407014   0.318748  \n",
       "                                   MAE        0.444487   0.378217  \n",
       "Bavaria_to_GP2 Zero-Shot           MSE        7.924194   7.015851  \n",
       "                                   MAE        2.090798   1.805375  \n",
       "               four_weeks_tl       MSE        1.129054   0.905254  \n",
       "                                   MAE        0.663105   0.580962  \n",
       "               full_tl             MSE        0.652067   0.735345  \n",
       "                                   MAE        0.435838   0.466485  \n",
       "               full_training       MSE             NaN   0.751727  \n",
       "                                   MAE             NaN   0.464294  \n",
       "               four_weeks_training MSE        0.914506   1.067181  \n",
       "                                   MAE        0.533531   0.590445  \n",
       "GP2_to_Bavaria Zero-Shot           MSE        0.001579   0.002799  \n",
       "                                   MAE        0.028474   0.038123  \n",
       "               four_weeks_tl       MSE        0.000486   0.000491  \n",
       "                                   MAE        0.011165   0.010852  \n",
       "               full_tl             MSE        0.000312   0.000350  \n",
       "                                   MAE        0.009100   0.009622  \n",
       "               full_training       MSE        0.000316   0.000344  \n",
       "                                   MAE        0.009070   0.009595  \n",
       "               four_weeks_training MSE        0.000528   0.000554  \n",
       "                                   MAE        0.011608   0.011853  \n",
       "GP2_to_ELD     Zero-Shot           MSE        1.243249   1.326016  \n",
       "                                   MAE        0.867076   0.883588  \n",
       "               four_weeks_tl       MSE        0.465202   0.312831  \n",
       "                                   MAE        0.495156   0.379233  \n",
       "               full_tl             MSE        0.322184   0.223821  \n",
       "                                   MAE        0.376486   0.308111  \n",
       "               full_training       MSE        0.302426   0.233886  \n",
       "                                   MAE        0.364883   0.314118  \n",
       "               four_weeks_training MSE        0.426265   0.349006  \n",
       "                                   MAE        0.456393   0.391751  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the DataFrame\n",
    "models = {\n",
    "    \"NHiTS\": train_nhits,\n",
    "    \"NBEATS\": train_nbeats,\n",
    "    \"Transformer\": train_transformer,\n",
    "    \"TSMixer\": train_tsmixer\n",
    "}\n",
    "\n",
    "try:\n",
    "    results_df = pd.read_csv(metrics_output_path, index_col=[0, 1, 2])\n",
    "except FileNotFoundError:\n",
    "    metrics = [\"MSE\", \"MAE\"]\n",
    "    learning_scenarios = [\"Zero-Shot\", \"four_weeks_tl\", \"full_tl\", \"full_training\", \"four_weeks_training\"]\n",
    "    index = pd.MultiIndex.from_product([tl_setups.keys(), learning_scenarios, metrics], names=[\"Setup\", \"Learning_scenario\", \"Metric\"])\n",
    "    results_df = pd.DataFrame(columns=models.keys(), index=index)\n",
    "\n",
    "# Helper functions\n",
    "def update_metrics(setup_name, model_name, learning_scenario, mae, mse):\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
    "\n",
    "def is_metric_filled(setup_name, model_name, learning_scenario):\n",
    "    # Check if specific metrics for a model in a setup and fine-tuning scenario are NaN or not\n",
    "    metrics_filled = not results_df.loc[(setup_name, learning_scenario, slice(None)), model_name].isnull().any()\n",
    "    return metrics_filled\n",
    "\n",
    "def run_model_tl(setup_name, tl_data):\n",
    "    source_train = tl_data[\"source_train\"]\n",
    "    source_val = tl_data[\"source_validation\"]\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "\n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"full_tl\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with full fine-tuning as metrics are already filled.\")\n",
    "            continue\n",
    "        \n",
    "        # Train model with source dataset (Zero-Shot)\n",
    "        model = model_func(source_train, source_val, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "\n",
    "        # Create deep copy for full fine-tuning\n",
    "        full_tl_model = copy.deepcopy(model)\n",
    "\n",
    "        update_metrics(setup_name, model_name, \"Zero-Shot\", metrics['MAE'], metrics['MSE'])\n",
    "        print(f\"Metrics updated for {model_name} in {setup_name} with zero-shot fine-tuning: MAE = {metrics['MAE']}, MSE = {metrics['MSE']}\")\n",
    "        \n",
    "        # Fine-tune on small target train set (four_weeks_tl)\n",
    "        model = fine_tune_model(model, target_fine_tuning, epochs=TUNE_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"four_weeks_tl\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Fine-tune on full target train set (full_tl)\n",
    "        full_tl_model = fine_tune_model(full_tl_model, target_train, epochs=TUNE_EPOCHS)\n",
    "        metrics = evaluate(full_tl_model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"full_tl\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Save after every dataset combination\n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "def train_baselines(setup_name, tl_data):\n",
    "    target_fine_tuning = tl_data[\"target_fine_tuning\"]\n",
    "    target_test = tl_data[\"target_test\"]\n",
    "    target_train = tl_data[\"target_train\"]\n",
    "    target_validation = tl_data[\"target_validation\"]\n",
    "\n",
    "    for model_name, model_func in models.items():\n",
    "        if is_metric_filled(setup_name, model_name, \"four_weeks_training\"):\n",
    "            print(f\"Skipping {model_name} for {setup_name} with as metrics are already filled.\")\n",
    "            continue\n",
    "\n",
    "        # Train on full target train set (full_training)\n",
    "        model = model_func(target_train, target_validation, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"full_training\", metrics['MAE'], metrics['MSE'])\n",
    "\n",
    "        # Train on short target train set (four_weeks_training)\n",
    "        model = model_func(target_fine_tuning, target_validation, epochs=TRAIN_EPOCHS)\n",
    "        metrics = evaluate(model, target_test)\n",
    "        update_metrics(setup_name, model_name, \"four_weeks_training\", metrics['MAE'], metrics['MSE'])\n",
    "        \n",
    "        results_df.to_csv(metrics_output_path)\n",
    "\n",
    "# Execute for each setup and fine-tuning scenario\n",
    "for setup_name, (source_data, target_data) in tl_setups.items():\n",
    "    print(setup_name)\n",
    "    tl_data = process_tl_data(source_data, target_data)\n",
    "    run_model_tl(setup_name, tl_data)\n",
    "    train_baselines(setup_name, tl_data)\n",
    "\n",
    "\n",
    "# split source/target df into 2 index columns\n",
    "results_df.to_csv(metrics_output_path)\n",
    "\n",
    "# Drop rows with NaN values and save the final results\n",
    "results_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
