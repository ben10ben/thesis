{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as Arima\n",
    "import config\n",
    "import pickle\n",
    "import torch\n",
    "\n",
    "from utils import data_handling, helpers\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TTrain ARIAMA and predict\n",
    "\n",
    "For every ID in all three datasets we fit an ARIMA model and do predictions over every 96 time step window of each datasets test set.\n",
    "\n",
    "We take the last 2000 datapoints of the train set for model training for computational reasons. We add multiple covariates, which are different laggs and time of day encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "train_standardize_dict = None\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "\n",
    "# load bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_tensor(df, lag):\n",
    "    if lag > 0:\n",
    "        return torch.cat((torch.zeros(lag, df.size(1)), df[:-lag]), dim=0)\n",
    "    return df\n",
    "\n",
    "# Example tensor of shape [2929, 348]\n",
    "def create_lagged(df):\n",
    "\n",
    "    # Lag by 24, ...\n",
    "    lagged_1 = lag_tensor(df, 1)\n",
    "    lagged_24 = lag_tensor(df, 24)\n",
    "    lagged_48 = lag_tensor(df, 24*2)\n",
    "    lagged_72 = lag_tensor(df, 24*3)\n",
    "    lagged_96 = lag_tensor(df, 24*4)\n",
    "\n",
    "    length = df.size(0)\n",
    "    ids = df.size(1)\n",
    "\n",
    "    # create time of day index\n",
    "    hours = torch.arange(0, 24)\n",
    "\n",
    "    # implement sin/cosine encoding for 24h\n",
    "    sin_encodings = torch.sin(2 * torch.pi * hours / 24)\n",
    "    cos_encodings = torch.cos(2 * torch.pi * hours / 24)\n",
    "\n",
    "    time_of_day_sin = sin_encodings.repeat(ids, length//23).transpose(0,1)[:length,:]\n",
    "    time_of_day_cos = cos_encodings.repeat(ids, length//23).transpose(0,1)[:length,:]\n",
    "    \n",
    "   # return torch.stack((lagged_24, lagged_48, lagged_72, lagged_96, time_of_day_sin, time_of_day_cos), dim=2)\n",
    "    return torch.stack((lagged_1, lagged_24, lagged_48, lagged_72, lagged_96, time_of_day_sin, time_of_day_cos), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict(df, dataset_name, data_split_description):\n",
    "    num_96_horizons = int(df[\"test\"][:,0].shape[0] / (96))\n",
    "    lagged_covariates_train = create_lagged(df[\"train\"])\n",
    "    lagged_covariates_test = create_lagged(df[\"test\"])\n",
    "\n",
    "    #filename = config.CONFIG_OUTPUT_PATH[\"arima\"] / f'arima_{key_}predictions.csv'\n",
    "    filename = config.CONFIG_OUTPUT_PATH[\"arima\"] / f'arima_{dataset_name}_predictions{data_split_description}_new.pkl'\n",
    "\n",
    "\n",
    "    # load predictions if available\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            prediction_list = pickle.load(file)\n",
    "    except: \n",
    "        print(\"no predictions available.\")\n",
    "        prediction_list = []\n",
    "\n",
    "\n",
    "    # fit a model for each id and iterate over the test split for inference\n",
    "    for id in range(len(prediction_list), df[\"train\"].size(1)):\n",
    "        model = Arima.auto_arima(df[\"train\"][-2000:,id], exogenous=lagged_covariates_train[-2000:,id,:], stepwise=True, seasonal=True, m=24, maxiter=3)\n",
    "\n",
    "        sum_mse = 0\n",
    "        sum_mae = 0\n",
    "        sum_mape = 0\n",
    "        for i in range(num_96_horizons):\n",
    "            time_step = i * 96\n",
    "            target = df[\"test\"][time_step : time_step+96, id]\n",
    "\n",
    "            lagged_window_test = lagged_covariates_test[time_step:time_step+96,id,:]\n",
    "            forecasts = model.predict(n_periods=96, return_conf_int=False, exogenous=lagged_window_test, alpha=0.1)\n",
    "\n",
    "            # evaluate forecasts\n",
    "            sum_mse += mean_squared_error(forecasts, target)\n",
    "            sum_mae += mean_absolute_error(forecasts, target)\n",
    "            sum_mape = mean_absolute_percentage_error(forecasts, target)\n",
    "            \n",
    "\n",
    "        prediction_list.append([sum_mse / num_96_horizons, sum_mae / num_96_horizons, sum_mape / num_96_horizons])\n",
    "        print(f\"MSE of {id}: \", sum_mse / num_96_horizons, \"MAE:\" ,sum_mae / num_96_horizons)\n",
    "\n",
    "\n",
    "        # save as pickle\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(prediction_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of 1045:  3.743397301046462 MAE: 1.7709848320762598\n",
      "MSE of 1046:  2.0035961656385766 MAE: 1.186081797254964\n",
      "MSE of 1047:  0.7317639544441809 MAE: 0.4430142489238984\n",
      "MSE of 1048:  1.2978196723126663 MAE: 0.9033094802445929\n",
      "MSE of 1049:  1.4352172072199374 MAE: 0.9299916789074498\n",
      "MSE of 1050:  0.9458829255018649 MAE: 0.7028529389411741\n",
      "MSE of 1051:  0.5897052524286407 MAE: 0.5500772314190294\n",
      "MSE of 1052:  1.0647105983117293 MAE: 0.7330611595433355\n",
      "MSE of 1053:  1.8759848881373669 MAE: 1.2537845755031105\n",
      "MSE of 1054:  0.8730469690460012 MAE: 0.8134619581436283\n",
      "MSE of 1055:  1.4415051195004622 MAE: 1.2006269693374634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/pmdarima/arima/auto.py:444: UserWarning: Input time-series is completely constant; returning a (0, 0, 0) ARMA.\n",
      "  warnings.warn('Input time-series is completely constant; '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of 1056:  0.5497402316977861 MAE: 0.6277373598901604\n",
      "MSE of 1057:  1.387017469986565 MAE: 0.8986977890452722\n",
      "MSE of 1058:  0.8574309693285864 MAE: 0.6702595645917718\n",
      "MSE of 1059:  0.7373556407430423 MAE: 0.704047061593814\n",
      "MSE of 1060:  4.3654037336058975 MAE: 1.8570150284293903\n",
      "MSE of 1061:  1.1845526273765594 MAE: 0.7956855346316755\n",
      "MSE of 1062:  0.9324574457590267 MAE: 0.7962995495367091\n",
      "MSE of 1063:  0.7324645768014081 MAE: 0.7199205169708931\n",
      "MSE of 1064:  0.9617324118069965 MAE: 0.7864263179346934\n",
      "MSE of 1065:  1.0948213094372465 MAE: 0.8104201571366939\n",
      "MSE of 1066:  1.4602990114956842 MAE: 0.8917560379460328\n",
      "MSE of 1067:  0.9782511776833169 MAE: 0.8053017244098073\n",
      "MSE of 1068:  0.7507103113571654 MAE: 0.7610999953346089\n",
      "MSE of 1069:  0.9283812112129468 MAE: 0.7777460822547437\n",
      "MSE of 1070:  1.1483807100967005 MAE: 0.8562584308415863\n",
      "MSE of 1071:  0.6557821580901193 MAE: 0.6002303249289798\n",
      "MSE of 1072:  1.2733377636483165 MAE: 0.8825217423852215\n",
      "MSE of 1073:  0.7788393913721009 MAE: 0.6821582801710944\n",
      "MSE of 1074:  0.8022348107955851 MAE: 0.7358539829684839\n",
      "MSE of 1075:  1.0708512389422005 MAE: 0.779922974248968\n",
      "MSE of 1076:  1.0120618726473913 MAE: 0.7951535227606816\n",
      "MSE of 1077:  1.1283785479099713 MAE: 0.8339305226873386\n",
      "MSE of 1078:  1.5199879368012148 MAE: 0.984418152015421\n",
      "MSE of 1079:  0.9034775260967803 MAE: 0.7603783687542677\n",
      "MSE of 1080:  2.2271965556693454 MAE: 1.3371214483782348\n",
      "MSE of 1081:  2.4142471570783894 MAE: 1.3739738273313713\n",
      "MSE of 1082:  1.04122849771689 MAE: 0.8810020700445046\n",
      "MSE of 1083:  0.866336484742483 MAE: 0.7664468759615886\n",
      "MSE of 1084:  1.3004270241561235 MAE: 0.6630961874631277\n",
      "MSE of 1085:  0.8411127975614765 MAE: 0.7723125215527659\n",
      "MSE of 1086:  1.477063567989803 MAE: 0.9669442905381038\n",
      "MSE of 1087:  0.8092734510566053 MAE: 0.693788375031096\n",
      "MSE of 1088:  0.8947462833338818 MAE: 0.7739881685979679\n",
      "MSE of 1089:  1.3655209180243852 MAE: 0.8884115193639399\n",
      "MSE of 1090:  0.7942565794118822 MAE: 0.7657448532627045\n",
      "MSE of 1091:  1.1443710542327943 MAE: 0.8678378530075688\n",
      "MSE of 1092:  0.7548316541017761 MAE: 0.6603558740926354\n",
      "MSE of 1093:  0.6565503701253983 MAE: 0.7155345073326227\n",
      "MSE of 1094:  0.4775365521525627 MAE: 0.5508908689529868\n",
      "MSE of 1095:  0.36540933404167536 MAE: 0.3633028801199433\n",
      "MSE of 1096:  3.3081255388776385 MAE: 1.1774499585342941\n",
      "MSE of 1097:  0.6950728398224751 MAE: 0.7159024908899951\n",
      "MSE of 1098:  2.433549047154203 MAE: 1.3891926390932339\n",
      "MSE of 1099:  0.6265645261797259 MAE: 0.6472399946950554\n",
      "MSE of 1100:  0.8328823945534592 MAE: 0.6046327353325663\n",
      "MSE of 1101:  1.3128743793484356 MAE: 0.9281551455446685\n",
      "MSE of 1102:  3.694350662022417 MAE: 1.6369514268996548\n",
      "MSE of 1103:  1.5049058822786607 MAE: 0.6527406494402264\n",
      "MSE of 1104:  0.24976446335511113 MAE: 0.4551305793256927\n",
      "MSE of 1105:  1.3210401065110395 MAE: 0.908203043649421\n",
      "MSE of 1106:  0.8747083090684556 MAE: 0.6829876745124015\n",
      "MSE of 1107:  0.8510267947552089 MAE: 0.7986078425284241\n",
      "MSE of 1108:  4.3290340847551985 MAE: 1.8603562419249622\n",
      "MSE of 1109:  0.7559450017444471 MAE: 0.6842780015871087\n",
      "MSE of 1110:  0.7062985260268773 MAE: 0.7438225962975795\n",
      "MSE of 1111:  0.9862848993998309 MAE: 0.7623282737618641\n",
      "MSE of 1112:  0.6485960835445244 MAE: 0.6457051804813633\n",
      "MSE of 1113:  0.5922365976215411 MAE: 0.608731439412134\n",
      "MSE of 1114:  0.8798130667097112 MAE: 0.7572217599602408\n",
      "MSE of 1115:  0.8484457347587017 MAE: 0.721811972727308\n",
      "MSE of 1116:  4.3932537686479005 MAE: 1.8915566932141388\n",
      "MSE of 1117:  0.6039436624738161 MAE: 0.5609169096630288\n",
      "MSE of 1118:  0.34713182646379276 MAE: 0.2853617200048812\n",
      "MSE of 1119:  0.45382844428916497 MAE: 0.4538052867693723\n",
      "MSE of 1120:  1.1616525331831977 MAE: 0.8614148795195242\n",
      "MSE of 1121:  3.6660527953836555 MAE: 1.6531662671172829\n",
      "MSE of 1122:  0.7312066885397077 MAE: 0.6290962462206725\n",
      "MSE of 1123:  1.8246662863764593 MAE: 1.2863654244397023\n",
      "MSE of 1124:  1.0603781131266907 MAE: 0.9067914646360445\n",
      "MSE of 1125:  1.039511735064852 MAE: 0.6389374226501517\n",
      "MSE of 1126:  0.6934727353330136 MAE: 0.6161628260177227\n",
      "MSE of 1127:  2.7168997815217386 MAE: 1.1402297531863288\n",
      "MSE of 1128:  0.7880504148582926 MAE: 0.7118642973443787\n",
      "MSE of 1129:  0.6128216716293704 MAE: 0.6491565397631633\n",
      "MSE of 1130:  0.7012211014635307 MAE: 0.6125862506383232\n",
      "MSE of 1131:  1.7743560081021623 MAE: 1.2170254266304676\n",
      "MSE of 1132:  6.40192602293214 MAE: 2.410882135741555\n",
      "MSE of 1133:  0.37393987585774635 MAE: 0.46091550043045987\n",
      "MSE of 1134:  2.1475471776031028 MAE: 1.216018688589918\n",
      "MSE of 1135:  0.9071434696913947 MAE: 0.6897291167402081\n",
      "MSE of 1136:  0.9790631340339142 MAE: 0.5883286232259347\n",
      "MSE of 1137:  0.5299946916333953 MAE: 0.5775721386912537\n",
      "MSE of 1138:  1.7695140683027035 MAE: 1.1987499299661522\n",
      "MSE of 1139:  0.7171401501193394 MAE: 0.6691500368879407\n",
      "MSE of 1140:  1.3582880184431285 MAE: 0.9002517962467355\n",
      "MSE of 1141:  2.010214589879787 MAE: 1.016436033965506\n",
      "MSE of 1142:  4.447538856276735 MAE: 1.2940237484342636\n",
      "MSE of 1143:  0.7216914808130557 MAE: 0.6927117898006557\n",
      "MSE of 1144:  0.9684730432099973 MAE: 0.778877431553014\n",
      "MSE of 1145:  3.53893804702141 MAE: 1.5760120967039013\n",
      "MSE of 1146:  0.5792814917150619 MAE: 0.563662610504587\n",
      "MSE of 1147:  1.0693687742511209 MAE: 0.7698942725324547\n",
      "MSE of 1148:  0.5930484883253584 MAE: 0.5994558413442114\n",
      "MSE of 1149:  0.7889904201907313 MAE: 0.7499506740698288\n",
      "MSE of 1150:  1.9264922659601948 MAE: 1.3099473339066536\n",
      "MSE of 1151:  1.01225265116413 MAE: 0.7358887530245465\n",
      "MSE of 1152:  1.0761712866402235 MAE: 0.7325256172204886\n",
      "MSE of 1153:  1.7800817211122641 MAE: 1.0720552952090714\n",
      "MSE of 1154:  1.409114336319643 MAE: 0.923577205350611\n",
      "MSE of 1155:  0.5115153220304255 MAE: 0.6031007222743533\n",
      "MSE of 1156:  1.9440706648611263 MAE: 1.0456465599444593\n",
      "MSE of 1157:  0.8773353254443749 MAE: 0.7543519744649055\n",
      "MSE of 1158:  0.47652168512782667 MAE: 0.4285114652965511\n",
      "MSE of 1159:  3.2410902552351906 MAE: 1.739628289724386\n",
      "MSE of 1160:  0.9376397124132719 MAE: 0.5386610225024971\n",
      "MSE of 1161:  0.2346154316405947 MAE: 0.37522050022385334\n",
      "MSE of 1162:  0.3845744600383842 MAE: 0.4135550628973858\n",
      "MSE of 1163:  0.43577869640701256 MAE: 0.5211006413406042\n",
      "MSE of 1164:  0.01897045398539076 MAE: 0.10666320143565856\n",
      "MSE of 1165:  1.4795860584475178 MAE: 1.0373600554913882\n",
      "MSE of 1166:  1.179449892942576 MAE: 0.8880118978581183\n",
      "MSE of 1167:  1.8138285301136605 MAE: 1.0464620495225077\n",
      "MSE of 1168:  1.2946090737794753 MAE: 0.8924337928250704\n",
      "MSE of 1169:  1.0422459686971721 MAE: 0.8271669124253049\n",
      "MSE of 1170:  0.7760960755623759 MAE: 0.5907841480606666\n",
      "MSE of 1171:  4.675426989605373 MAE: 1.8869194066661763\n",
      "MSE of 1172:  4.992557897173224 MAE: 2.02681828952643\n",
      "MSE of 1173:  4.826533066347585 MAE: 1.9397348271451869\n",
      "MSE of 1174:  0.9029127693543032 MAE: 0.7770006809729689\n",
      "MSE of 1175:  1.7176190935435975 MAE: 0.9300452395555788\n",
      "MSE of 1176:  0.17468247877699797 MAE: 0.33682629344676834\n",
      "MSE of 1177:  1.9078501773481478 MAE: 1.0357582779216608\n",
      "MSE of 1178:  0.7824119199862528 MAE: 0.661122628186156\n",
      "MSE of 1179:  0.6855450814974343 MAE: 0.7126932989071233\n",
      "MSE of 1180:  1.8352255793831869 MAE: 1.0649512694247592\n",
      "MSE of 1181:  0.2856150946205099 MAE: 0.41980816038113006\n",
      "MSE of 1182:  0.5915005470154331 MAE: 0.5580679608630253\n",
      "MSE of 1183:  1.219201796897616 MAE: 0.833294749593188\n",
      "MSE of 1184:  2.5412230795705844 MAE: 1.1929664223932042\n",
      "MSE of 1185:  1.592207936826097 MAE: 0.9467065661494795\n",
      "MSE of 1186:  1.892643082516826 MAE: 1.0156950589549842\n",
      "MSE of 1187:  1.2937367548688887 MAE: 0.892105728408908\n",
      "MSE of 1188:  0.5672768031261589 MAE: 0.5792869743844508\n",
      "MSE of 1189:  1.4098604871343299 MAE: 0.8820726053900241\n",
      "MSE of 1190:  0.9121947337920437 MAE: 0.6802915482835019\n",
      "MSE of 1191:  3.230228199146268 MAE: 1.315252603071304\n",
      "MSE of 1192:  1.4487232586459085 MAE: 0.9695064438915316\n",
      "MSE of 1193:  1.13034374092477 MAE: 0.8791926009848553\n",
      "MSE of 1194:  3.1141739540248596 MAE: 1.2663970845425845\n",
      "MSE of 1195:  2.0355629102227972 MAE: 1.1549883895270119\n",
      "MSE of 1196:  0.770506097138902 MAE: 0.6526683864175136\n",
      "MSE of 1197:  0.6372575404069323 MAE: 0.5265612575028816\n",
      "MSE of 1198:  3.3490055826126155 MAE: 1.5255347917328435\n",
      "MSE of 1199:  8.722371804275133 MAE: 2.7825877460458597\n",
      "MSE of 1200:  0.4293465194478919 MAE: 0.5177476782151499\n",
      "MSE of 1201:  0.9610674213158722 MAE: 0.8420069325472367\n",
      "MSE of 1202:  0.6738713491183066 MAE: 0.6103032137440741\n",
      "MSE of 1203:  1.0107737749292882 MAE: 0.8021190120329071\n",
      "MSE of 1204:  1.6149036796849008 MAE: 1.0798396623485191\n",
      "MSE of 1205:  2.2952223035800423 MAE: 1.1979964514646992\n",
      "MSE of 1206:  0.827442608672952 MAE: 0.646086696182216\n",
      "MSE of 1207:  1.1644473051832869 MAE: 0.884857798501164\n",
      "MSE of 1208:  1.4988250642023173 MAE: 0.879609567118392\n",
      "MSE of 1209:  2.9685024640215447 MAE: 1.4734839492802991\n",
      "MSE of 1210:  0.6428502501711201 MAE: 0.6715083817921782\n",
      "MSE of 1211:  3.130311095717254 MAE: 1.4672840727882428\n",
      "MSE of 1212:  0.7797833081584626 MAE: 0.704196562376118\n",
      "MSE of 1213:  2.207019043143999 MAE: 1.2361418041161272\n",
      "MSE of 1214:  6.799949399595606 MAE: 2.3535952634572137\n",
      "MSE of 1215:  0.6334612410148387 MAE: 0.6265647413808783\n",
      "MSE of 1216:  1.2398414345210387 MAE: 0.7694671376615374\n",
      "MSE of 1217:  0.6919606485428076 MAE: 0.7178309126965605\n",
      "MSE of 1218:  4.0852404710960615 MAE: 1.6483733069762676\n",
      "MSE of 1219:  0.5504085485036263 MAE: 0.652433372429267\n",
      "MSE of 1220:  1.6901133347307364 MAE: 1.1656542178604274\n",
      "MSE of 1221:  0.7622824854561229 MAE: 0.713869103011064\n",
      "MSE of 1222:  3.084377081383089e-08 MAE: 0.0001677988707389777\n"
     ]
    }
   ],
   "source": [
    "# do training on 2000 time steps\n",
    "process_and_predict(electricity_dict, \"electricity\", \"full\")\n",
    "process_and_predict(bavaria_dict, \"bavaria\", \"full\")\n",
    "process_and_predict(gp_dict, \"genome_project\", \"full\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
