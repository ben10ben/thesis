{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pmdarima as Arima\n",
    "from utils import data_handling, helpers\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
    "import config\n",
    "import pickle\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do long and short predictions using ARIMA\n",
    "\n",
    "For every ID in all three datasets we fit an ARIMA model and do predictions over every 96 time step window of each datasets test set.\n",
    "\n",
    "We take the last 2000 datapoints of the train set for \"full\" model training for computational reasons. \n",
    "For the jumpstart evaluation we also train all ARIMA models on around 350 time steps which equals the 2 week fine-tuning horizon used in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "train_standardize_dict = None\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "\n",
    "# load bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_tensor(df, lag):\n",
    "    if lag > 0:\n",
    "        return torch.cat((torch.zeros(lag, df.size(1)), df[:-lag]), dim=0)\n",
    "    return df\n",
    "\n",
    "# Example tensor of shape [2929, 348]\n",
    "def create_lagged(df):\n",
    "\n",
    "    # Lag by 24, ...\n",
    "    lagged_1 = lag_tensor(df, 1)\n",
    "    lagged_24 = lag_tensor(df, 24)\n",
    "    lagged_48 = lag_tensor(df, 24*2)\n",
    "    lagged_72 = lag_tensor(df, 24*3)\n",
    "    lagged_96 = lag_tensor(df, 24*4)\n",
    "\n",
    "    length = df.size(0)\n",
    "    ids = df.size(1)\n",
    "\n",
    "    # create time of day index\n",
    "    hours = torch.arange(0, 24)\n",
    "\n",
    "    # implement sin/cosine encoding for 24h\n",
    "    sin_encodings = torch.sin(2 * torch.pi * hours / 24)\n",
    "    cos_encodings = torch.cos(2 * torch.pi * hours / 24)\n",
    "\n",
    "    time_of_day_sin = sin_encodings.repeat(ids, length//23).transpose(0,1)[:length,:]\n",
    "    time_of_day_cos = cos_encodings.repeat(ids, length//23).transpose(0,1)[:length,:]\n",
    "    \n",
    "   # return torch.stack((lagged_24, lagged_48, lagged_72, lagged_96, time_of_day_sin, time_of_day_cos), dim=2)\n",
    "    return torch.stack((lagged_1, lagged_24, lagged_48, lagged_72, lagged_96, time_of_day_sin, time_of_day_cos), dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_predict(df, dataset_name, data_split_description):\n",
    "    num_96_horizons = int(df[\"test\"][:,0].shape[0] / (96))\n",
    "    lagged_covariates_train = create_lagged(df[\"train\"])\n",
    "    lagged_covariates_test = create_lagged(df[\"test\"])\n",
    "\n",
    "    #filename = config.CONFIG_OUTPUT_PATH[\"arima\"] / f'arima_{key_}predictions.csv'\n",
    "    filename = config.CONFIG_OUTPUT_PATH[\"arima\"] / f'arima_{dataset_name}_predictions{data_split_description}_new.pkl'\n",
    "\n",
    "\n",
    "    # load predictions if available\n",
    "    try:\n",
    "        with open(filename, 'rb') as file:\n",
    "            prediction_list = pickle.load(file)\n",
    "    except: \n",
    "        print(\"no predictions available.\")\n",
    "        prediction_list = []\n",
    "\n",
    "\n",
    "    # fit a model for each id and iterate over the test split for inference\n",
    "    for id in range(len(prediction_list), df[\"train\"].size(1)):\n",
    "        model = Arima.auto_arima(df[\"train\"][-2000:,id], exogenous=lagged_covariates_train[-2000:,id,:], stepwise=True, seasonal=True, m=24, maxiter=3)\n",
    "\n",
    "        sum_mse = 0\n",
    "        sum_mae = 0\n",
    "        sum_mape = 0\n",
    "        for i in range(num_96_horizons):\n",
    "            time_step = i * 96\n",
    "            target = df[\"test\"][time_step : time_step+96, id]\n",
    "\n",
    "            lagged_window_test = lagged_covariates_test[time_step:time_step+96,id,:]\n",
    "            forecasts = model.predict(n_periods=96, return_conf_int=False, exogenous=lagged_window_test, alpha=0.1)\n",
    "\n",
    "            # evaluate forecasts\n",
    "            sum_mse += mean_squared_error(forecasts, target)\n",
    "            sum_mae += mean_absolute_error(forecasts, target)\n",
    "            sum_mape = mean_absolute_percentage_error(forecasts, target)\n",
    "            \n",
    "\n",
    "        prediction_list.append([sum_mse / num_96_horizons, sum_mae / num_96_horizons, sum_mape / num_96_horizons])\n",
    "        print(f\"MSE of {id}: \", sum_mse / num_96_horizons, \"MAE:\" ,sum_mae / num_96_horizons)\n",
    "\n",
    "\n",
    "        # save as pickle\n",
    "        with open(filename, 'wb') as file:\n",
    "            pickle.dump(prediction_list, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE of 218:  0.5380489125843554 MAE: 0.6035750179751525\n",
      "MSE of 219:  1.3305422254948234 MAE: 1.0315176433396702\n",
      "MSE of 220:  1.8045855588592516 MAE: 1.1858992365313161\n",
      "MSE of 221:  1.13624204678139 MAE: 0.7743463151881277\n",
      "MSE of 222:  0.6714064563497094 MAE: 0.664520181686349\n",
      "MSE of 223:  0.8253601534884129 MAE: 0.736307430948409\n",
      "MSE of 224:  0.7352786082149744 MAE: 0.6966865952603992\n",
      "MSE of 225:  2.612423179416696 MAE: 1.2862432818895386\n",
      "MSE of 226:  2.159703291542092 MAE: 1.2642889642420778\n",
      "MSE of 227:  2.207926537752326 MAE: 0.8793676958421377\n",
      "MSE of 228:  3.9563345205454814 MAE: 1.799681377153002\n",
      "MSE of 229:  0.4876142883779614 MAE: 0.5045205769928588\n",
      "MSE of 230:  0.6047152769158017 MAE: 0.5400341992133683\n",
      "MSE of 231:  2.0703610520354925 MAE: 1.1753403917847798\n",
      "MSE of 232:  1.234093606483357 MAE: 0.5986890869775394\n",
      "MSE of 233:  0.6650968901308735 MAE: 0.7197257265103973\n",
      "MSE of 234:  2.9054339073590176 MAE: 1.3125791783515894\n",
      "MSE of 235:  1.1474653631520444 MAE: 0.8256225264119943\n",
      "MSE of 236:  10.47056522125278 MAE: 3.1487843981122565\n",
      "MSE of 237:  1.0764634865294633 MAE: 0.6405663127709184\n",
      "MSE of 238:  0.9385302382179326 MAE: 0.7089232073422503\n",
      "MSE of 239:  5.156862432626449 MAE: 1.9901575546902437\n",
      "MSE of 240:  1.1986761592345003 MAE: 0.8137477443195614\n",
      "MSE of 241:  2.187000371346121 MAE: 1.1808477101026211\n",
      "MSE of 242:  0.6904499462051735 MAE: 0.6015797007334764\n",
      "MSE of 243:  0.23965938637449946 MAE: 0.3569031863260468\n",
      "MSE of 244:  1.6897018795034842 MAE: 1.0528337366076346\n",
      "MSE of 245:  1.8412074476144435 MAE: 0.9568205698539702\n",
      "MSE of 246:  0.8137820485401023 MAE: 0.7194676500140484\n",
      "MSE of 247:  3.96203174097874 MAE: 1.630162043081588\n",
      "MSE of 248:  1.5556466509729323 MAE: 0.9543227966454192\n",
      "MSE of 249:  0.6037535129443846 MAE: 0.6130832294537271\n",
      "MSE of 250:  0.39259200453252413 MAE: 0.4619815687174896\n",
      "MSE of 251:  0.91708345786841 MAE: 0.7768735673100454\n",
      "MSE of 252:  2.3228195633508437 MAE: 1.3488684692319304\n",
      "MSE of 253:  0.612421132687253 MAE: 0.6306001554592839\n"
     ]
    }
   ],
   "source": [
    "# do training on 2000 time steps\n",
    "#process_and_predict(electricity_dict, \"electricity\", \"full\")\n",
    "#process_and_predict(bavaria_dict, \"bavaria\", \"full\")\n",
    "process_and_predict(gp_dict, \"genome_project\", \"full\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
