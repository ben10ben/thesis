{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training using darts library\n",
    "\n",
    "TL using the same number of IDs is possible\n",
    "\n",
    "Reshaping does not seem possible.\n",
    "\n",
    "when the target dataset has more IDs than the source set, we use the same model to predict multiple ids \n",
    "\n",
    "the models are trained on the same amount of IDs as the target test set contains \n",
    "\n",
    "residuals of the target test set are not considered \n",
    "\n",
    "TODO: Fine tuning and saving outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/statsforecast/core.py:26: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.utils.losses import *\n",
    "from darts.models import *\n",
    "from darts.metrics.metrics import mse, mae, mape\n",
    "\n",
    "from utils import data_handling, helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns dropped:  9\n",
      "start rows removed:  7608\n",
      "end rows removed:  16704\n"
     ]
    }
   ],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT USED FOR EXPERIMENTS\n",
    "# euro dataset\n",
    "#data_tensor = data_handling.eu_electricity_to_tensor()\n",
    "#euro_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(source_data_train, source_data_val, epochs=1):\n",
    "    \"\"\"\n",
    "    -Convert train/val data into Darts TimeSeries format\n",
    "    -Instantiate different models\n",
    "    -Fit models to dataset\n",
    "\n",
    "    Return: fitted models\n",
    "    \"\"\"\n",
    "    ts_train_source = TimeSeries.from_values(source_data_train)\n",
    "    ts_val_source = TimeSeries.from_values(source_data_val)\n",
    "   \n",
    "   \n",
    "    # model specific parameters\n",
    "    # nhits\n",
    "    NUM_STACKS = 4\n",
    "    NUM_BLOCKS = 2\n",
    "    NUM_LAYERS = 2\n",
    "    LAYER_WIDTH = 128\n",
    "    COEFFS_DIM = 11\n",
    "\n",
    "    # Training settings:\n",
    "    LR = 1e-3\n",
    "    BATCH_SIZE = 64\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    # shared parameters\n",
    "    LAYER_NORM = 'LayerNorm'\n",
    "    USE_REVIN = True\n",
    "    LOSS_FN = torch.nn.MSELoss()\n",
    "    IN_LEN = 96\n",
    "    OUT_LEN = 96\n",
    "    DROPOUT = 0.2  # slightly higher than \"generic\" because we want more robustnes for TL\n",
    "    VERBOSE = False\n",
    "\n",
    "    # reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "        activation='ReLU',\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs={\n",
    "            \"enable_progress_bar\": True,\n",
    "            # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "            \"accelerator\": \"gpu\",},\n",
    "    )\n",
    "\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        output_chunk_shift=0, \n",
    "        d_model=64, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=512, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=None, \n",
    "        custom_encoder=None, \n",
    "        custom_decoder=None,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "    )\n",
    "\n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        output_chunk_shift=0,\n",
    "        hidden_size=64, \n",
    "        ff_size=64, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=LAYER_NORM, \n",
    "        normalize_before=False, \n",
    "        use_static_covariates=False,\n",
    "    )\n",
    "\n",
    "    nbeats_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    transformer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    return transformer_model, nbeats_model, tsmixer_model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(transformer, nhits, tsnmix, target_test_reshaped):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    \n",
    "\n",
    "    Input:  -trained models\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: [transformer, nhits, tsnmix]-Losses\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate multiple multivariate ID chunks\n",
    "    big_window = []\n",
    "    big_target = []\n",
    "\n",
    "    for element in target_test_reshaped:\n",
    "        element = TimeSeries.from_values(element)\n",
    "        forecasting_endpoint = int(len(element)) - 96*2\n",
    "\n",
    "        window = [element[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "        target = [element[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "        big_window.append(window)\n",
    "        big_target.append(target)\n",
    "\n",
    "    window = [item for sublist in big_window for item in sublist]\n",
    "    target = [item for sublist in big_target for item in sublist]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    preds_transformer = transformer.predict(n=96, series=window)\n",
    "    preds_nhits = nhits.predict(n=96, series=window)\n",
    "    preds_tsnmix = tsnmix.predict(n=96, series=window)\n",
    "\n",
    "\n",
    "    mse_transformer = mse(preds_transformer, target)\n",
    "    mse_nhits = mse(preds_nhits, target)\n",
    "    mse_tsmix = mse(preds_tsnmix, target)\n",
    "    length_loss = len(mse_transformer)\n",
    "\n",
    "    mae_transformer = mae(preds_transformer, target)\n",
    "    mae_nhits = mae(preds_nhits, target)\n",
    "    mae_tsmix = mae(preds_tsnmix, target)\n",
    "\n",
    "    mape_transformer = mape(preds_transformer, target)\n",
    "    mape_nhits = mape(preds_nhits, target)\n",
    "    mape_tsmix = mape(preds_tsnmix, target)\n",
    "\n",
    "\n",
    "    mse_mae_mape_transformer = sum(mse_transformer) / length_loss, sum(mae_transformer) / length_loss, sum(mape_transformer) / length_loss\n",
    "    mse_mae_mape_nhits = sum(mse_nhits) / length_loss, sum(mae_nhits) / length_loss, sum(mape_nhits) / length_loss\n",
    "    mse_mae_mape_tsmix = sum(mse_tsmix) / length_loss, sum(mae_tsmix) / length_loss, sum(mape_tsmix) / length_loss\n",
    "\n",
    "    return mse_mae_mape_transformer, mse_mae_mape_nhits, mse_mae_mape_tsmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_zero_shot(source_data, target_data):\n",
    "    # either reshape source or target dataset according to which has less IDs\n",
    "    source_ids = source_data[\"train\"].size(1)\n",
    "    target_ids = target_data[\"test\"].size(1)\n",
    "\n",
    "    fine_tune_horizon = -24*7*2\n",
    "\n",
    "    if target_ids < source_ids:\n",
    "        source_train = source_data[\"train\"][:,:target_ids]\n",
    "        source_val = source_data[\"validation\"][:,:target_ids]\n",
    "        \n",
    "        target_test = [target_data[\"test\"]]\n",
    "        target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,:]\n",
    "\n",
    "    else:\n",
    "        source_train = source_data[\"train\"]\n",
    "        source_val = source_data[\"validation\"]\n",
    "        \n",
    "        n_subset = int(target_ids / source_ids)\n",
    "        target_test = []\n",
    "        for i in range(n_subset):\n",
    "            target_test.append(target_data[\"test\"][:,(i*source_ids): (i*source_ids + source_ids)])\n",
    "            target_fine_tuning = target_data[\"train\"][fine_tune_horizon:,(i*source_ids): (i*source_ids + source_ids)]\n",
    "\n",
    "    transformer, nhits, tsmix = train_models(source_train, source_val, epochs=5)\n",
    "\n",
    "    #zero_shot_loss = evaluate(transformer, nhits, tsmix, target_test)\n",
    "    \n",
    "    return transformer, nhits, tsmix, target_test, target_fine_tuning\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fine_tune_models(model, target_fine_tuning, epochs=5):\n",
    "    \"\"\"\n",
    "    Fine tune models over specified epochs\n",
    "\n",
    "    Input:  -trained models\n",
    "            -fine tuning dataset\n",
    "            -epochs\n",
    "\n",
    "    Returns: fitted models\n",
    "    \"\"\"\n",
    "\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    model_list = []\n",
    "\n",
    "    for ts_set in target_fine_tuning:\n",
    "        tmp_model = model\n",
    "        tmp_model.fit(\n",
    "            ts_set,\n",
    "            num_loader_workers=4,\n",
    "            epochs=NUM_EPOCHS,\n",
    "            max_samples_per_ts=None,\n",
    "        )\n",
    "        model_list.append(tmp_model)\n",
    " \n",
    "    return model_list\n",
    "\n",
    "def evaluate_fine_tuned(model_list, target_test_reshaped):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    \n",
    "\n",
    "    Input:  -trained models\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: [transformer, nhits, tsnmix]-Losses\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluate multiple multivariate ID chunks\n",
    "    mse_sum = 0\n",
    "    mae_sum = 0\n",
    "    mape_sum = 0\n",
    "    for element in range(target_test_reshaped):\n",
    "        ts_split = TimeSeries.from_values(target_test_reshaped[element])\n",
    "        forecasting_endpoint = int(len(ts_split)) - 96*2\n",
    "\n",
    "        window = [ts_split[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "        target = [ts_split[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "\n",
    "        preds = model_list[element].predict(n=96, series=window)\n",
    "\n",
    "        mse_sum += mse(preds, target)\n",
    "        mae_sum += mae(preds, target)\n",
    "        mape_sum += mape(preds, target)\n",
    "\n",
    "    \n",
    "    mse = sum(mse_sum) / len(mse_sum)\n",
    "    mae = sum(mae_sum) / len(mae_sum)\n",
    "    mape = sum(mape_sum) / len(mape_sum)\n",
    "\n",
    "\n",
    "    return [mse, mae, mape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(target_fine_tuning, torch.tensor):\n",
    "    print(\"Hi\")\n",
    "    target_fine_tuning = [target_fine_tuning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_list\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_list' is not defined"
     ]
    }
   ],
   "source": [
    "model_list = fine_tune_models(transformer, target_fine_tuning, epochs=5)\n",
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 11\u001b[0m\n\u001b[1;32m      7\u001b[0m transformer, nhits, tsmix, target_test, target_fine_tuning \u001b[38;5;241m=\u001b[39m train_and_zero_shot(electricity_dict, bavaria_dict)\n\u001b[1;32m      8\u001b[0m loss_transformer[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melec_to_bavaria\u001b[39m\u001b[38;5;124m\"\u001b[39m], loss_nhits[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melec_to_bavaria\u001b[39m\u001b[38;5;124m\"\u001b[39m], loss_tsnmix[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124melec_to_bavaria\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;241m=\u001b[39m evaluate(transformer, nhits, tsmix, target_test)\n\u001b[0;32m---> 11\u001b[0m model_list \u001b[38;5;241m=\u001b[39m \u001b[43mfine_tune_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_fine_tuning\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 51\u001b[0m, in \u001b[0;36mfine_tune_models\u001b[0;34m(model, target_fine_tuning, epochs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ts_set \u001b[38;5;129;01min\u001b[39;00m target_fine_tuning:\n\u001b[1;32m     50\u001b[0m     tmp_model \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m---> 51\u001b[0m     \u001b[43mtmp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mts_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_loader_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     model_list\u001b[38;5;241m.\u001b[39mappend(tmp_model)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_list\n",
      "File \u001b[0;32m~/bene/MA/myenv/lib/python3.10/site-packages/darts/utils/torch.py:103\u001b[0m, in \u001b[0;36mrandom_method.<locals>.decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fork_rng():\n\u001b[1;32m    102\u001b[0m     manual_seed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_random_instance\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m0\u001b[39m, high\u001b[38;5;241m=\u001b[39mMAX_TORCH_SEED_VALUE))\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdecorated\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/bene/MA/myenv/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:732\u001b[0m, in \u001b[0;36mTorchForecastingModel.fit\u001b[0;34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, num_loader_workers)\u001b[0m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;129m@random_method\u001b[39m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    663\u001b[0m     num_loader_workers: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    664\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorchForecastingModel\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    665\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit/train the model on one or multiple series.\u001b[39;00m\n\u001b[1;32m    666\u001b[0m \n\u001b[1;32m    667\u001b[0m \u001b[38;5;124;03m    This method wraps around :func:`fit_from_dataset()`, constructing a default training\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;124;03m        Fitted model.\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    728\u001b[0m     (\n\u001b[1;32m    729\u001b[0m         series,\n\u001b[1;32m    730\u001b[0m         past_covariates,\n\u001b[1;32m    731\u001b[0m         future_covariates,\n\u001b[0;32m--> 732\u001b[0m     ), params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setup_for_fit_from_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfuture_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_series\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_series\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_past_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_past_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_future_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_future_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_samples_per_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_loader_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_loader_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;66;03m# call super fit only if user is actually fitting the model\u001b[39;00m\n\u001b[1;32m    746\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    747\u001b[0m         series\u001b[38;5;241m=\u001b[39mseq2series(series),\n\u001b[1;32m    748\u001b[0m         past_covariates\u001b[38;5;241m=\u001b[39mseq2series(past_covariates),\n\u001b[1;32m    749\u001b[0m         future_covariates\u001b[38;5;241m=\u001b[39mseq2series(future_covariates),\n\u001b[1;32m    750\u001b[0m     )\n",
      "File \u001b[0;32m~/bene/MA/myenv/lib/python3.10/site-packages/darts/models/forecasting/torch_forecasting_model.py:785\u001b[0m, in \u001b[0;36mTorchForecastingModel._setup_for_fit_from_dataset\u001b[0;34m(self, series, past_covariates, future_covariates, val_series, val_past_covariates, val_future_covariates, trainer, verbose, epochs, max_samples_per_ts, num_loader_workers)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This method acts on `TimeSeries` inputs. It performs sanity checks, and sets up / returns the datasets and\u001b[39;00m\n\u001b[1;32m    782\u001b[0m \u001b[38;5;124;03madditional inputs required for training the model with `fit_from_dataset()`.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;66;03m# guarantee that all inputs are either list of `TimeSeries` or `None`\u001b[39;00m\n\u001b[0;32m--> 785\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[43mseries2seq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m past_covariates \u001b[38;5;241m=\u001b[39m series2seq(past_covariates)\n\u001b[1;32m    787\u001b[0m future_covariates \u001b[38;5;241m=\u001b[39m series2seq(future_covariates)\n",
      "File \u001b[0;32m~/bene/MA/myenv/lib/python3.10/site-packages/darts/utils/ts_utils.py:102\u001b[0m, in \u001b[0;36mseries2seq\u001b[0;34m(ts, seq_type_out, nested)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(seq_type_out, SeriesType):\n\u001b[1;32m     95\u001b[0m     raise_log(\n\u001b[1;32m     96\u001b[0m         \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     97\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid parameter `seq_type_out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseq_type_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Must be one of `(0, 1, 2)`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m         ),\n\u001b[1;32m     99\u001b[0m         logger\u001b[38;5;241m=\u001b[39mlogger,\n\u001b[1;32m    100\u001b[0m     )\n\u001b[0;32m--> 102\u001b[0m seq_type_in \u001b[38;5;241m=\u001b[39m \u001b[43mget_series_seq_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seq_type_out \u001b[38;5;241m==\u001b[39m seq_type_in:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ts\n",
      "File \u001b[0;32m~/bene/MA/myenv/lib/python3.10/site-packages/darts/utils/ts_utils.py:221\u001b[0m, in \u001b[0;36mget_series_seq_type\u001b[0;34m(ts)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ts[\u001b[38;5;241m0\u001b[39m], TimeSeries):\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesType\u001b[38;5;241m.\u001b[39mSEQ\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[43mts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m, TimeSeries):\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesType\u001b[38;5;241m.\u001b[39mSEQ_SEQ\n\u001b[1;32m    223\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index of a 0-dim tensor. Use `tensor.item()` in Python or `tensor.item<T>()` in C++ to convert a 0-dim tensor to a number"
     ]
    }
   ],
   "source": [
    "loss_transformer = {}\n",
    "loss_nhits = {}\n",
    "loss_tsnmix = {}\n",
    "\n",
    "\n",
    "# electricity as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, bavaria_dict)\n",
    "loss_transformer[\"elec_to_bavaria\"], loss_nhits[\"elec_to_bavaria\"], loss_tsnmix[\"elec_to_bavaria\"]  = evaluate(transformer, nhits, tsmix, target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.54it/s, train_loss=0.277, val_loss=0.521]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.50it/s, train_loss=0.277, val_loss=0.521]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 19.16it/s, train_loss=0.302, val_loss=0.531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.56it/s, train_loss=0.159, val_loss=0.690]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 47.53it/s, train_loss=0.159, val_loss=0.690]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 35.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 10.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 30.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.80it/s, train_loss=0.364, val_loss=0.448]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 76/76 [00:02<00:00, 33.76it/s, train_loss=0.364, val_loss=0.448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:07<00:00, 20.05it/s, train_loss=0.219, val_loss=0.382]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.88it/s, train_loss=0.131, val_loss=0.550]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 151/151 [00:03<00:00, 45.84it/s, train_loss=0.131, val_loss=0.550]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 15.18it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 31.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.43it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:02<00:00, 46.40it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 20.02it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.24it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 48.21it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 30.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 23.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.12it/s, train_loss=0.000319, val_loss=0.000184]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 132/132 [00:03<00:00, 40.09it/s, train_loss=0.000319, val_loss=0.000184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:13<00:00, 19.93it/s, train_loss=0.000289, val_loss=0.000194]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.66it/s, train_loss=0.000779, val_loss=0.0982]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 264/264 [00:05<00:00, 51.64it/s, train_loss=0.000779, val_loss=0.0982]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 36.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 27/27 [00:01<00:00, 21.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 54/54 [00:01<00:00, 29.28it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 134   \n",
      "4 | stacks        | ModuleList       | 4.0 M \n",
      "---------------------------------------------------\n",
      "3.9 M     Trainable params\n",
      "78.6 K    Non-trainable params\n",
      "4.0 M     Total params\n",
      "15.955    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.28it/s, train_loss=0.302, val_loss=1.110]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 44.26it/s, train_loss=0.302, val_loss=1.110]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 134   \n",
      "4 | encoder             | Linear              | 4.4 K \n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 418 K \n",
      "------------------------------------------------------------\n",
      "971 K     Trainable params\n",
      "0         Non-trainable params\n",
      "971 K     Total params\n",
      "3.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:46<00:00, 20.54it/s, train_loss=0.353, val_loss=1.090]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 25.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 4.4 K \n",
      "---------------------------------------------------------\n",
      "123 K     Trainable params\n",
      "0         Non-trainable params\n",
      "123 K     Total params\n",
      "0.493     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.04it/s, train_loss=0.248, val_loss=2.050]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 59.03it/s, train_loss=0.248, val_loss=2.050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 40.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 8/8 [00:00<00:00, 23.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicting DataLoader 0: 100%|██████████| 15/15 [00:00<00:00, 38.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | criterion     | MSELoss          | 0     \n",
      "1 | train_metrics | MetricCollection | 0     \n",
      "2 | val_metrics   | MetricCollection | 0     \n",
      "3 | rin           | RINorm           | 416   \n",
      "4 | stacks        | ModuleList       | 12.2 M\n",
      "---------------------------------------------------\n",
      "12.0 M    Trainable params\n",
      "241 K     Non-trainable params\n",
      "12.2 M    Total params\n",
      "48.875    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.18it/s, train_loss=0.375, val_loss=0.767]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 474/474 [00:10<00:00, 46.17it/s, train_loss=0.375, val_loss=0.767]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type                | Params\n",
      "------------------------------------------------------------\n",
      "0 | criterion           | MSELoss             | 0     \n",
      "1 | train_metrics       | MetricCollection    | 0     \n",
      "2 | val_metrics         | MetricCollection    | 0     \n",
      "3 | rin                 | RINorm              | 416   \n",
      "4 | encoder             | Linear              | 13.4 K\n",
      "5 | positional_encoding | _PositionalEncoding | 0     \n",
      "6 | transformer         | Transformer         | 548 K \n",
      "7 | decoder             | Linear              | 1.3 M \n",
      "------------------------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.441     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.88it/s, train_loss=0.434, val_loss=0.728]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:43<00:00, 21.87it/s, train_loss=0.434, val_loss=0.728]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "\n",
      "  | Name                | Type             | Params\n",
      "---------------------------------------------------------\n",
      "0 | criterion           | MSELoss          | 0     \n",
      "1 | train_metrics       | MetricCollection | 0     \n",
      "2 | val_metrics         | MetricCollection | 0     \n",
      "3 | fc_hist             | Linear           | 9.3 K \n",
      "4 | feature_mixing_hist | _FeatureMixing   | 43.2 K\n",
      "5 | conditional_mixer   | ModuleList       | 84.4 K\n",
      "6 | fc_out              | Linear           | 13.5 K\n",
      "---------------------------------------------------------\n",
      "150 K     Trainable params\n",
      "0         Non-trainable params\n",
      "150 K     Total params\n",
      "0.602     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.16it/s, train_loss=0.211, val_loss=1.260]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 948/948 [00:16<00:00, 57.15it/s, train_loss=0.211, val_loss=1.260]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 31.85it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 9/9 [00:00<00:00, 16.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 33.11it/s]\n"
     ]
    }
   ],
   "source": [
    "loss_transformer = {}\n",
    "loss_nhits = {}\n",
    "loss_tsnmix = {}\n",
    "\n",
    "# electricity as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, bavaria_dict)\n",
    "loss_transformer[\"elec_to_bavaria\"], loss_nhits[\"elec_to_bavaria\"], loss_tsnmix[\"elec_to_bavaria\"]  = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(electricity_dict, gp_dict)\n",
    "loss_transformer[\"elec_to_gp\"], loss_nhits[\"elec_to_gp\"], loss_tsnmix[\"elec_to_gp\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "\n",
    "# bavaria as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(bavaria_dict, electricity_dict)\n",
    "loss_transformer[\"bavaria_to_elec\"], loss_nhits[\"bavaria_to_elec\"], loss_tsnmix[\"bavaria_to_elec\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(bavaria_dict, gp_dict)\n",
    "loss_transformer[\"bavaria_to_gp\"], loss_nhits[\"bavaria_to_gp\"], loss_tsnmix[\"bavaria_to_gp\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "\n",
    "# genome project as source\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(gp_dict, bavaria_dict)\n",
    "loss_transformer[\"gp_to_bavaria\"], loss_nhits[\"gp_to_bavaria\"], loss_tsnmix[\"gp_to_bavaria\"] = evaluate(transformer, nhits, tsmix, target_test)\n",
    "\n",
    "transformer, nhits, tsmix, target_test, target_fine_tuning = train_and_zero_shot(gp_dict, electricity_dict)\n",
    "loss_transformer[\"gp_to_elec\"], loss_nhits[\"gp_to_elec\"], loss_tsnmix[\"gp_to_elec\"] = evaluate(transformer, nhits, tsmix, target_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
