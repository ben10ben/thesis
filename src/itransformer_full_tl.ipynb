{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import succesfull\n"
     ]
    }
   ],
   "source": [
    "# TODO which one?\n",
    "#git clone https://github.com/lucidrains/iTransformer.git\n",
    "#import iTransformer\n",
    "import sys\n",
    "sys.path.append('/vol/fob-vol7/nebenf21/reinbene/bene/MA/iTransformer') \n",
    "from iTransformer import iTransformer\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data_handling, helpers, training_functions\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "window_size = 96\n",
    "pred_length = (96)\n",
    "\n",
    "four_weeks = -24*7*4\n",
    "print(\"Import succesfull\")\n",
    "\n",
    "#metrics_output_path = config.CONFIG_OUTPUT_PATH[\"itransformer\"] / \"itransformer_results_transfer_learning.csv\"\n",
    "\n",
    "metrics_output_path = config.CONFIG_OUTPUT_PATH[\"itransformer\"] / \"itransformer_results_transfer_learning_revin.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select dataset for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 348])\n",
      "Feature batch shape: torch.Size([32, 96, 59])\n",
      "Feature batch shape: torch.Size([32, 96, 1454])\n"
     ]
    }
   ],
   "source": [
    "# electricity dataset\n",
    "data_dict = data_handling.load_electricity()\n",
    "\n",
    "electricity_dict = {}\n",
    "electricity_dict[\"dataloader_train\"], electricity_dict[\"dataloader_validation\"], electricity_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# create a smaller subset of the train dataset\n",
    "electricity_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(electricity_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "electricity_dict[\"4_weeks_train\"] = data_handling.DataLoader(electricity_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "data_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# convert to datalaoder\n",
    "bavaria_dict = {}\n",
    "bavaria_dict[\"dataloader_train\"], bavaria_dict[\"dataloader_validation\"], bavaria_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# add fine-tuning datalaoders\n",
    "# create a smaller subset of the train dataset\n",
    "bavaria_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "bavaria_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(bavaria_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "bavaria_dict[\"4_weeks_train\"] = data_handling.DataLoader(bavaria_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "data_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "# convert to datalaoder\n",
    "gp_dict = {}\n",
    "gp_dict[\"dataloader_train\"], gp_dict[\"dataloader_validation\"], gp_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# add fine-tuning datalaoders\n",
    "# create a smaller subset of the train dataset\n",
    "gp_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "gp_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(gp_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "gp_dict[\"4_weeks_train\"] = data_handling.DataLoader(gp_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# merge in dataset dict\n",
    "datasets = {\"ELD\" : electricity_dict,\n",
    "            \"GP2\" : gp_dict,\n",
    "\t\t\t\"Bavaria\" : bavaria_dict\n",
    "            }\n",
    "\n",
    "\n",
    "# define parameters for all models\n",
    "best_parameters = {'depth': 2, 'dim': 256, 'dim_head': 56, 'heads': 4, 'attn_dropout': 0.2, 'ff_mult': 4, 'ff_dropout': 0.2, \n",
    "                        'num_mem_tokens': 4, 'learning_rate': 0.0005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_setups = {\n",
    "    \"ELD_to_Bavaria\" : [electricity_dict, bavaria_dict, \"ELD\", \"Bavaria\"], \n",
    "    \"ELD_to_GP2\" : [electricity_dict, gp_dict, \"ELD\", \"GP2\"],\n",
    "    \"Bavaria_to_ELD\" : [bavaria_dict, electricity_dict, \"Bavaria\", \"ELD\"], \n",
    "    \"Bavaria_to_GP2\" : [bavaria_dict, gp_dict, \"Bavaria\", \"GP2\"], \n",
    "    \"GP2_to_Bavaria\": [gp_dict, bavaria_dict, \"GP2\", \"Bavaria\"], \n",
    "    \"GP2_to_ELD\" : [gp_dict, electricity_dict, \"GP2\", \"ELD\"]\n",
    "     }\n",
    "\n",
    "\n",
    "try:\n",
    "    results_df = pd.read_csv(metrics_output_path, index_col=[0, 1, 2])\n",
    "except FileNotFoundError:\n",
    "    metrics = [\"MSE\", \"MAE\"]\n",
    "    learning_scenarios = [\"Zero-Shot\", \"four_weeks_tl\", \"full_tl\", \"full_training\", \"four_weeks_training\"]\n",
    "    index = pd.MultiIndex.from_product([tl_setups.keys(), learning_scenarios, metrics], names=[\"Setup\", \"Learning_scenario\", \"Metric\"])\n",
    "    results_df = pd.DataFrame(columns=[\"iTransformer\"], index=index)\n",
    "\n",
    "# Helper functions\n",
    "def update_metrics(setup_name, model_name, learning_scenario, mae, mse):\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot prediction on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n",
      "Non-A100 GPU detected, using math or mem efficient attention if input tensor is on cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 142.54it/s]\n",
      "/tmp/ipykernel_14814/2943203897.py:21: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_14814/2943203897.py:22: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:03<00:00, 23.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 113.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:03<00:00, 23.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 279.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 112.98it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tl_setups.items():\n",
    "    source_df = value[0]\n",
    "    target_df = value[1]\n",
    "    source_name = value[2]\n",
    "    target_name = value[3]\n",
    "\n",
    "    model_path = config.CONFIG_MODEL_LOCATION[\"itransformer\"] / source_name / f\"{source_name}_full_dataset_best_val_loss.pt\"\n",
    "\n",
    "    dataloader = target_df[\"dataloader_test\"]\n",
    "\n",
    "    inputs, _ = next(iter(dataloader))\n",
    "    num_variates = inputs.size(2)\n",
    "\n",
    "    model_config = {\n",
    "            'num_variates': num_variates,\n",
    "            'lookback_len': window_size,\n",
    "            'depth': best_parameters[\"depth\"],\n",
    "            'dim': best_parameters[\"dim\"],\n",
    "            'num_tokens_per_variate': 1,\n",
    "            'pred_length': pred_length,\n",
    "            'dim_head': best_parameters[\"dim_head\"],\n",
    "            'heads': best_parameters[\"heads\"],\n",
    "            'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "            'ff_mult': best_parameters[\"ff_mult\"],\n",
    "            'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "            'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "            'use_reversible_instance_norm': True,\n",
    "            'reversible_instance_norm_affine': True,\n",
    "            'flash_attn': True\n",
    "        }\n",
    "\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    metrics = helpers.full_eval(model, dataloader, device)\n",
    "    update_metrics(key, \"iTransformer\", \"Zero-Shot\", metrics[1], metrics[0])\n",
    "\n",
    "results_df.to_csv(metrics_output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning and predicitons on the test data\n",
    "\n",
    "We fine tune for 5 epochs on different target datasets training sets length. After every epoch the training and validation loss is logged. For the final evaluation the model with the best validation loss is selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ELD as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 32.71it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 61.56it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 61.06it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 61.69it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 61.35it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:00<00:00, 58.78it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:00<00:00, 59.88it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:00<00:00, 58.22it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:00<00:00, 61.21it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:00<00:00, 59.98it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 259.37it/s]\n",
      "/tmp/ipykernel_14814/2943203897.py:21: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_14814/2943203897.py:22: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "Epoch: 1: 100%|██████████| 304/304 [00:05<00:00, 59.78it/s]\n",
      "Epoch: 2: 100%|██████████| 304/304 [00:05<00:00, 59.71it/s]\n",
      "Epoch: 3: 100%|██████████| 304/304 [00:05<00:00, 59.38it/s]\n",
      "Epoch: 4: 100%|██████████| 304/304 [00:05<00:00, 59.13it/s]\n",
      "Epoch: 5: 100%|██████████| 304/304 [00:05<00:00, 59.61it/s]\n",
      "Epoch: 6: 100%|██████████| 304/304 [00:05<00:00, 59.77it/s]\n",
      "Epoch: 7: 100%|██████████| 304/304 [00:05<00:00, 59.16it/s]\n",
      "Epoch: 8: 100%|██████████| 304/304 [00:05<00:00, 59.62it/s]\n",
      "Epoch: 9: 100%|██████████| 304/304 [00:04<00:00, 62.50it/s]\n",
      "Epoch: 10: 100%|██████████| 304/304 [00:04<00:00, 61.51it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 248.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ELD as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:02<00:00,  5.44it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:02<00:00,  5.52it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:02<00:00,  5.47it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:02<00:00,  5.53it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.27it/s]\n",
      "Epoch: 1: 100%|██████████| 314/314 [00:57<00:00,  5.44it/s]\n",
      "Epoch: 2: 100%|██████████| 314/314 [00:57<00:00,  5.43it/s]\n",
      "Epoch: 3: 100%|██████████| 314/314 [00:57<00:00,  5.45it/s]\n",
      "Epoch: 4: 100%|██████████| 314/314 [00:57<00:00,  5.46it/s]\n",
      "Epoch: 5: 100%|██████████| 314/314 [00:57<00:00,  5.46it/s]\n",
      "Epoch: 6: 100%|██████████| 314/314 [00:57<00:00,  5.46it/s]\n",
      "Epoch: 7: 100%|██████████| 314/314 [00:57<00:00,  5.45it/s]\n",
      "Epoch: 8: 100%|██████████| 314/314 [00:57<00:00,  5.47it/s]\n",
      "Epoch: 9: 100%|██████████| 314/314 [00:57<00:00,  5.47it/s]\n",
      "Epoch: 10: 100%|██████████| 314/314 [00:57<00:00,  5.49it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bavaria as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 31.29it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 32.65it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 31.45it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 31.58it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 31.13it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:00<00:00, 31.39it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:00<00:00, 31.35it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:00<00:00, 31.50it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:00<00:00, 31.22it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:00<00:00, 31.76it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 101.11it/s]\n",
      "Epoch: 1: 100%|██████████| 151/151 [00:05<00:00, 29.68it/s]\n",
      "Epoch: 2: 100%|██████████| 151/151 [00:05<00:00, 29.90it/s]\n",
      "Epoch: 3: 100%|██████████| 151/151 [00:05<00:00, 29.78it/s]\n",
      "Epoch: 4: 100%|██████████| 151/151 [00:05<00:00, 30.09it/s]\n",
      "Epoch: 5: 100%|██████████| 151/151 [00:04<00:00, 30.52it/s]\n",
      "Epoch: 6: 100%|██████████| 151/151 [00:05<00:00, 29.78it/s]\n",
      "Epoch: 7: 100%|██████████| 151/151 [00:05<00:00, 30.05it/s]\n",
      "Epoch: 8: 100%|██████████| 151/151 [00:05<00:00, 30.13it/s]\n",
      "Epoch: 9: 100%|██████████| 151/151 [00:05<00:00, 29.83it/s]\n",
      "Epoch: 10: 100%|██████████| 151/151 [00:04<00:00, 30.26it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 99.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bavaria as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:02<00:00,  5.42it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:02<00:00,  5.44it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:02<00:00,  5.47it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:02<00:00,  5.49it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:02<00:00,  5.46it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:02<00:00,  5.48it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:02<00:00,  5.47it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.51it/s]\n",
      "Epoch: 1: 100%|██████████| 314/314 [00:57<00:00,  5.47it/s]\n",
      "Epoch: 2: 100%|██████████| 314/314 [00:57<00:00,  5.45it/s]\n",
      "Epoch: 3: 100%|██████████| 314/314 [00:57<00:00,  5.46it/s]\n",
      "Epoch: 4: 100%|██████████| 314/314 [00:57<00:00,  5.46it/s]\n",
      "Epoch: 5: 100%|██████████| 314/314 [00:57<00:00,  5.45it/s]\n",
      "Epoch: 6: 100%|██████████| 314/314 [00:57<00:00,  5.45it/s]\n",
      "Epoch: 7: 100%|██████████| 314/314 [00:58<00:00,  5.34it/s]\n",
      "Epoch: 8: 100%|██████████| 314/314 [00:58<00:00,  5.38it/s]\n",
      "Epoch: 9: 100%|██████████| 314/314 [00:56<00:00,  5.53it/s]\n",
      "Epoch: 10: 100%|██████████| 314/314 [00:57<00:00,  5.44it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GP2 as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 70.17it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 70.09it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 64.00it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 57.67it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 58.22it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:00<00:00, 59.68it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:00<00:00, 58.02it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:00<00:00, 66.85it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:00<00:00, 63.38it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:00<00:00, 59.08it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 250.79it/s]\n",
      "Epoch: 1: 100%|██████████| 304/304 [00:05<00:00, 54.05it/s]\n",
      "Epoch: 2: 100%|██████████| 304/304 [00:05<00:00, 54.05it/s]\n",
      "Epoch: 3: 100%|██████████| 304/304 [00:05<00:00, 56.41it/s]\n",
      "Epoch: 4: 100%|██████████| 304/304 [00:05<00:00, 56.72it/s]\n",
      "Epoch: 5: 100%|██████████| 304/304 [00:05<00:00, 57.14it/s]\n",
      "Epoch: 6: 100%|██████████| 304/304 [00:03<00:00, 97.99it/s] \n",
      "Epoch: 7: 100%|██████████| 304/304 [00:05<00:00, 53.02it/s]\n",
      "Epoch: 8: 100%|██████████| 304/304 [00:05<00:00, 54.68it/s]\n",
      "Epoch: 9: 100%|██████████| 304/304 [00:05<00:00, 53.90it/s]\n",
      "Epoch: 10: 100%|██████████| 304/304 [00:05<00:00, 58.90it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 278.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GP2 as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 31.51it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 31.70it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 30.96it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 31.46it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 31.97it/s]\n",
      "Epoch: 6: 100%|██████████| 15/15 [00:00<00:00, 32.01it/s]\n",
      "Epoch: 7: 100%|██████████| 15/15 [00:00<00:00, 30.48it/s]\n",
      "Epoch: 8: 100%|██████████| 15/15 [00:00<00:00, 30.90it/s]\n",
      "Epoch: 9: 100%|██████████| 15/15 [00:00<00:00, 33.49it/s]\n",
      "Epoch: 10: 100%|██████████| 15/15 [00:00<00:00, 32.68it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 98.46it/s] \n",
      "Epoch: 1: 100%|██████████| 151/151 [00:05<00:00, 29.25it/s]\n",
      "Epoch: 2: 100%|██████████| 151/151 [00:05<00:00, 29.61it/s]\n",
      "Epoch: 3: 100%|██████████| 151/151 [00:05<00:00, 28.46it/s]\n",
      "Epoch: 4: 100%|██████████| 151/151 [00:05<00:00, 29.42it/s]\n",
      "Epoch: 5: 100%|██████████| 151/151 [00:05<00:00, 29.62it/s]\n",
      "Epoch: 6: 100%|██████████| 151/151 [00:05<00:00, 26.69it/s]\n",
      "Epoch: 7: 100%|██████████| 151/151 [00:06<00:00, 24.41it/s]\n",
      "Epoch: 8: 100%|██████████| 151/151 [00:06<00:00, 24.55it/s]\n",
      "Epoch: 9: 100%|██████████| 151/151 [00:05<00:00, 26.63it/s]\n",
      "Epoch: 10: 100%|██████████| 151/151 [00:05<00:00, 26.69it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 98.56it/s] \n"
     ]
    }
   ],
   "source": [
    "def fine_tune(model, dataloader_train, dataloader_validation, device, epoch=1):\n",
    "\n",
    "    # defining all needed instances\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    writer = SummaryWriter(log_dir=config.CONFIG_LOGS_PATH[\"itransformer\"])\n",
    "\n",
    "    # run model training as mentioned in the original paper\n",
    "    _, model = training_functions.train_one_epoch(epoch, model, device, dataloader_train, dataloader_validation, optimizer, \\\n",
    "                                                        scheduler, writer, save_model=False, validate=False)\n",
    "    return model, device\n",
    "\n",
    "\n",
    "epoch=10\n",
    "\n",
    "for key, value in tl_setups.items():\n",
    "    source_df = value[0]\n",
    "    target_df = value[1]\n",
    "    source_name = value[2]\n",
    "    target_name = value[3]\n",
    "    print(f\"Using {source_name} as a source dataset.\")\n",
    "\n",
    "    model_path = config.CONFIG_MODEL_LOCATION[\"itransformer\"] / source_name / f\"{source_name}_full_dataset_best_val_loss.pt\"\n",
    "\n",
    "\n",
    "    # do test predictions for both target datasets\n",
    "    dataloader_test = target_df[\"dataloader_test\"]\n",
    "    datalaoder_val = target_df[\"dataloader_validation\"]\n",
    "    fine_tune_dataloader = target_df[\"4_weeks_train\"]  \n",
    "    full_fine_tune_dataloader = target_df[\"dataloader_train\"]        \n",
    "      \n",
    "\n",
    "    inputs, _ = next(iter(dataloader_test))\n",
    "    num_variates = inputs.size(2)\n",
    "\n",
    "    model_config = {\n",
    "        'num_variates': num_variates,\n",
    "        'lookback_len': window_size,\n",
    "        'depth': best_parameters[\"depth\"],\n",
    "        'dim': best_parameters[\"dim\"],\n",
    "        'num_tokens_per_variate': 1,\n",
    "        'pred_length': pred_length,\n",
    "        'dim_head': best_parameters[\"dim_head\"],\n",
    "        'heads': best_parameters[\"heads\"],\n",
    "        'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "        'ff_mult': best_parameters[\"ff_mult\"],\n",
    "        'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "        'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "        'use_reversible_instance_norm': True,\n",
    "        'reversible_instance_norm_affine': True,\n",
    "        'flash_attn': True\n",
    "    }\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    \n",
    "    # fne tuning on 4 weeks of target data\n",
    "    model, device = fine_tune(model, fine_tune_dataloader, datalaoder_val, device, epoch=epoch)\n",
    "    metrics_fine_tuned = helpers.full_eval(model, dataloader_test, device)\n",
    "    update_metrics(key, \"iTransformer\", \"four_weeks_tl\", metrics_fine_tuned[1], metrics_fine_tuned[0])\n",
    "\n",
    "    # train on full target dataset\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # fne tuning on 4 weeks of target data\n",
    "    model, device = fine_tune(model, full_fine_tune_dataloader, datalaoder_val, device, epoch=epoch)\n",
    "    metrics_fine_tuned = helpers.full_eval(model, dataloader_test, device)\n",
    "    update_metrics(key, \"iTransformer\", \"full_tl\", metrics_fine_tuned[1], metrics_fine_tuned[0])\n",
    "\n",
    "results_df.to_csv(metrics_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iTransformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setup</th>\n",
       "      <th>Learning_scenario</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.461933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.022352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.008560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.684155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.482013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.548209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.400982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.465823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.357243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.191598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.196772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.274203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.359050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.179394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.267813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.338648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.052081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.552085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.414422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.458592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.353943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.226545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.435768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.013904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.013972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.331429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.392488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.210335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.292538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.179914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.262523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           iTransformer\n",
       "Setup          Learning_scenario   Metric              \n",
       "ELD_to_Bavaria Zero-Shot           MSE         0.241426\n",
       "                                   MAE         0.461933\n",
       "               four_weeks_tl       MSE         0.000939\n",
       "                                   MAE         0.022352\n",
       "               full_tl             MSE         0.000253\n",
       "                                   MAE         0.008560\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN\n",
       "ELD_to_GP2     Zero-Shot           MSE         0.684155\n",
       "                                   MAE         0.482013\n",
       "               four_weeks_tl       MSE         0.548209\n",
       "                                   MAE         0.400982\n",
       "               full_tl             MSE         0.465823\n",
       "                                   MAE         0.357243\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN\n",
       "Bavaria_to_ELD Zero-Shot           MSE         2.191598\n",
       "                                   MAE         1.196772\n",
       "               four_weeks_tl       MSE         0.274203\n",
       "                                   MAE         0.359050\n",
       "               full_tl             MSE         0.179394\n",
       "                                   MAE         0.267813\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN\n",
       "Bavaria_to_GP2 Zero-Shot           MSE         2.338648\n",
       "                                   MAE         1.052081\n",
       "               four_weeks_tl       MSE         0.552085\n",
       "                                   MAE         0.414422\n",
       "               full_tl             MSE         0.458592\n",
       "                                   MAE         0.353943\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN\n",
       "GP2_to_Bavaria Zero-Shot           MSE         0.226545\n",
       "                                   MAE         0.435768\n",
       "               four_weeks_tl       MSE         0.000472\n",
       "                                   MAE         0.013904\n",
       "               full_tl             MSE         0.000425\n",
       "                                   MAE         0.013972\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN\n",
       "GP2_to_ELD     Zero-Shot           MSE         0.331429\n",
       "                                   MAE         0.392488\n",
       "               four_weeks_tl       MSE         0.210335\n",
       "                                   MAE         0.292538\n",
       "               full_tl             MSE         0.179914\n",
       "                                   MAE         0.262523\n",
       "               full_training       MSE              NaN\n",
       "                                   MAE              NaN\n",
       "               four_weeks_training MSE              NaN\n",
       "                                   MAE              NaN"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
