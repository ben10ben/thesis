{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import succesfull\n"
     ]
    }
   ],
   "source": [
    "# TODO which one?\n",
    "#git clone https://github.com/lucidrains/iTransformer.git\n",
    "#import iTransformer\n",
    "import sys\n",
    "sys.path.append('/vol/fob-vol7/nebenf21/reinbene/bene/MA/iTransformer') \n",
    "from iTransformer import iTransformer\n",
    "import torch\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from utils import data_handling, helpers, training_functions\n",
    "import config\n",
    "import pandas as pd\n",
    "\n",
    "window_size = 96\n",
    "pred_length = (96)\n",
    "\n",
    "four_weeks = -24*7*4\n",
    "print(\"Import succesfull\")\n",
    "\n",
    "#metrics_output_path = config.CONFIG_OUTPUT_PATH[\"itransformer\"] / \"itransformer_results_transfer_learning.csv\"\n",
    "\n",
    "metrics_output_path = config.CONFIG_OUTPUT_PATH[\"itransformer\"] / \"itransformer_results_transfer_learning_revin.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select dataset for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature batch shape: torch.Size([32, 96, 348])\n",
      "Feature batch shape: torch.Size([32, 96, 59])\n",
      "Feature batch shape: torch.Size([32, 96, 1454])\n"
     ]
    }
   ],
   "source": [
    "# electricity dataset\n",
    "data_dict = data_handling.load_electricity()\n",
    "\n",
    "electricity_dict = {}\n",
    "electricity_dict[\"dataloader_train\"], electricity_dict[\"dataloader_validation\"], electricity_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# create a smaller subset of the train dataset\n",
    "electricity_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(electricity_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "electricity_dict[\"4_weeks_train\"] = data_handling.DataLoader(electricity_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "data_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "\n",
    "# convert to datalaoder\n",
    "bavaria_dict = {}\n",
    "bavaria_dict[\"dataloader_train\"], bavaria_dict[\"dataloader_validation\"], bavaria_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# add fine-tuning datalaoders\n",
    "# create a smaller subset of the train dataset\n",
    "bavaria_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "bavaria_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(bavaria_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "bavaria_dict[\"4_weeks_train\"] = data_handling.DataLoader(bavaria_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "data_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "# convert to datalaoder\n",
    "gp_dict = {}\n",
    "gp_dict[\"dataloader_train\"], gp_dict[\"dataloader_validation\"], gp_dict[\"dataloader_test\"] = data_handling.convert_data(data_dict, window_size, pred_length)\n",
    "\n",
    "# add fine-tuning datalaoders\n",
    "# create a smaller subset of the train dataset\n",
    "gp_dict[\"4_weeks_train\"] = data_dict[\"train\"][four_weeks:,:]\n",
    "gp_dict[\"4_weeks_train\"] = data_handling.SlidingWindowTimeSeriesDataset(gp_dict[\"4_weeks_train\"] , window_size, pred_length)\n",
    "gp_dict[\"4_weeks_train\"] = data_handling.DataLoader(gp_dict[\"4_weeks_train\"] , batch_size=32, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# merge in dataset dict\n",
    "datasets = {\"ELD\" : electricity_dict,\n",
    "            \"GP2\" : gp_dict,\n",
    "\t\t\t\"Bavaria\" : bavaria_dict\n",
    "            }\n",
    "\n",
    "\n",
    "# define parameters for all models\n",
    "best_parameters = {'depth': 2, 'dim': 256, 'dim_head': 56, 'heads': 4, 'attn_dropout': 0.2, 'ff_mult': 4, 'ff_dropout': 0.2, \n",
    "                        'num_mem_tokens': 4, 'learning_rate': 0.0005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl_setups = {\n",
    "    \"ELD_to_Bavaria\" : [electricity_dict, bavaria_dict, \"ELD\", \"Bavaria\"], \n",
    "    \"ELD_to_GP2\" : [electricity_dict, gp_dict, \"ELD\", \"GP2\"],\n",
    "    \"Bavaria_to_ELD\" : [bavaria_dict, electricity_dict, \"Bavaria\", \"ELD\"], \n",
    "    \"Bavaria_to_GP2\" : [bavaria_dict, gp_dict, \"Bavaria\", \"GP2\"], \n",
    "    \"GP2_to_Bavaria\": [gp_dict, bavaria_dict, \"GP2\", \"Bavaria\"], \n",
    "    \"GP2_to_ELD\" : [gp_dict, electricity_dict, \"GP2\", \"ELD\"]\n",
    "     }\n",
    "\n",
    "\n",
    "try:\n",
    "    results_df = pd.read_csv(metrics_output_path, index_col=[0, 1, 2])\n",
    "except FileNotFoundError:\n",
    "    metrics = [\"MSE\", \"MAE\"]\n",
    "    learning_scenarios = [\"Zero-Shot\", \"four_weeks_tl\", \"full_tl\", \"full_training\", \"four_weeks_training\"]\n",
    "    index = pd.MultiIndex.from_product([tl_setups.keys(), learning_scenarios, metrics], names=[\"Setup\", \"Learning_scenario\", \"Metric\"])\n",
    "    results_df = pd.DataFrame(columns=[\"iTransformer\"], index=index)\n",
    "\n",
    "# Helper functions\n",
    "def update_metrics(setup_name, model_name, learning_scenario, mae, mse):\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
    "    results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero-shot prediction on the test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 271.90it/s]\n",
      "/tmp/ipykernel_35715/2943203897.py:21: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_35715/2943203897.py:22: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:03<00:00, 22.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 112.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:03<00:00, 23.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 279.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 111.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tl_setups.items():\n",
    "    source_df = value[0]\n",
    "    target_df = value[1]\n",
    "    source_name = value[2]\n",
    "    target_name = value[3]\n",
    "\n",
    "    model_path = config.CONFIG_MODEL_LOCATION[\"itransformer\"] / source_name / f\"{source_name}_full_dataset_best_val_loss.pt\"\n",
    "\n",
    "    dataloader = target_df[\"dataloader_test\"]\n",
    "\n",
    "    inputs, _ = next(iter(dataloader))\n",
    "    num_variates = inputs.size(2)\n",
    "\n",
    "    model_config = {\n",
    "            'num_variates': num_variates,\n",
    "            'lookback_len': window_size,\n",
    "            'depth': best_parameters[\"depth\"],\n",
    "            'dim': best_parameters[\"dim\"],\n",
    "            'num_tokens_per_variate': 1,\n",
    "            'pred_length': pred_length,\n",
    "            'dim_head': best_parameters[\"dim_head\"],\n",
    "            'heads': best_parameters[\"heads\"],\n",
    "            'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "            'ff_mult': best_parameters[\"ff_mult\"],\n",
    "            'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "            'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "            'use_reversible_instance_norm': True,\n",
    "            'reversible_instance_norm_affine': True,\n",
    "            'flash_attn': True\n",
    "        }\n",
    "\n",
    "    device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    metrics = helpers.full_eval(model, dataloader, device)\n",
    "    update_metrics(key, \"iTransformer\", \"Zero-Shot\", metrics[1], metrics[0])\n",
    "\n",
    "results_df.to_csv(metrics_output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning and predicitons on the test data\n",
    "\n",
    "We fine tune for 5 epochs on different target datasets training sets length. After every epoch the training and validation loss is logged. For the final evaluation the model with the best validation loss is selected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ELD as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 64.63it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 61.46it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 61.73it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 61.61it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 66.31it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 244.75it/s]\n",
      "/tmp/ipykernel_35715/2943203897.py:21: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MAE\"), model_name] = mae\n",
      "/tmp/ipykernel_35715/2943203897.py:22: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  results_df.loc[(setup_name, learning_scenario, \"MSE\"), model_name] = mse\n",
      "Epoch: 1: 100%|██████████| 304/304 [00:05<00:00, 59.35it/s]\n",
      "Epoch: 2: 100%|██████████| 304/304 [00:05<00:00, 59.42it/s]\n",
      "Epoch: 3: 100%|██████████| 304/304 [00:05<00:00, 58.89it/s]\n",
      "Epoch: 4: 100%|██████████| 304/304 [00:05<00:00, 59.78it/s]\n",
      "Epoch: 5: 100%|██████████| 304/304 [00:04<00:00, 63.85it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 263.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ELD as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:02<00:00,  5.48it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:02<00:00,  5.48it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:02<00:00,  5.50it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:02<00:00,  5.56it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:02<00:00,  5.56it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.62it/s]\n",
      "Epoch: 1: 100%|██████████| 314/314 [00:56<00:00,  5.53it/s]\n",
      "Epoch: 2: 100%|██████████| 314/314 [00:56<00:00,  5.53it/s]\n",
      "Epoch: 3: 100%|██████████| 314/314 [00:56<00:00,  5.58it/s]\n",
      "Epoch: 4: 100%|██████████| 314/314 [00:57<00:00,  5.49it/s]\n",
      "Epoch: 5: 100%|██████████| 314/314 [00:57<00:00,  5.50it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 21.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bavaria as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 31.16it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 28.80it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 28.39it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 32.41it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 30.10it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 96.07it/s] \n",
      "Epoch: 1: 100%|██████████| 151/151 [00:04<00:00, 30.83it/s]\n",
      "Epoch: 2: 100%|██████████| 151/151 [00:05<00:00, 28.16it/s]\n",
      "Epoch: 3: 100%|██████████| 151/151 [00:05<00:00, 28.59it/s]\n",
      "Epoch: 4: 100%|██████████| 151/151 [00:05<00:00, 28.90it/s]\n",
      "Epoch: 5: 100%|██████████| 151/151 [00:05<00:00, 27.75it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 87.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Bavaria as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:02<00:00,  5.22it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:02<00:00,  5.48it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:02<00:00,  5.51it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:02<00:00,  5.46it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:02<00:00,  5.30it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 20.32it/s]\n",
      "Epoch: 1: 100%|██████████| 314/314 [00:58<00:00,  5.40it/s]\n",
      "Epoch: 2: 100%|██████████| 314/314 [00:57<00:00,  5.43it/s]\n",
      "Epoch: 3: 100%|██████████| 314/314 [00:57<00:00,  5.49it/s]\n",
      "Epoch: 4: 100%|██████████| 314/314 [00:58<00:00,  5.41it/s]\n",
      "Epoch: 5: 100%|██████████| 314/314 [00:57<00:00,  5.43it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:04<00:00, 21.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GP2 as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 67.52it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 65.96it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 68.60it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 99.71it/s] \n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 80.81it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 264.41it/s]\n",
      "Epoch: 1: 100%|██████████| 304/304 [00:03<00:00, 79.26it/s]\n",
      "Epoch: 2: 100%|██████████| 304/304 [00:03<00:00, 78.79it/s]\n",
      "Epoch: 3: 100%|██████████| 304/304 [00:03<00:00, 77.05it/s]\n",
      "Epoch: 4: 100%|██████████| 304/304 [00:04<00:00, 68.96it/s]\n",
      "Epoch: 5: 100%|██████████| 304/304 [00:04<00:00, 74.64it/s]\n",
      "Epoch: Validating: 100%|██████████| 83/83 [00:00<00:00, 260.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GP2 as a source dataset.\n",
      "Using device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|██████████| 15/15 [00:00<00:00, 32.25it/s]\n",
      "Epoch: 2: 100%|██████████| 15/15 [00:00<00:00, 32.93it/s]\n",
      "Epoch: 3: 100%|██████████| 15/15 [00:00<00:00, 32.39it/s]\n",
      "Epoch: 4: 100%|██████████| 15/15 [00:00<00:00, 32.56it/s]\n",
      "Epoch: 5: 100%|██████████| 15/15 [00:00<00:00, 32.99it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:00<00:00, 96.03it/s] \n",
      "Epoch: 1: 100%|██████████| 151/151 [00:04<00:00, 31.38it/s]\n",
      "Epoch: 2: 100%|██████████| 151/151 [00:04<00:00, 30.83it/s]\n",
      "Epoch: 3: 100%|██████████| 151/151 [00:04<00:00, 31.22it/s]\n",
      "Epoch: 4: 100%|██████████| 151/151 [00:04<00:00, 30.94it/s]\n",
      "Epoch: 5: 100%|██████████| 151/151 [00:04<00:00, 30.89it/s]\n",
      "Epoch: Validating: 100%|██████████| 86/86 [00:01<00:00, 85.16it/s] \n"
     ]
    }
   ],
   "source": [
    "def fine_tune(model, dataloader_train, dataloader_validation, device, epoch=1):\n",
    "\n",
    "    # defining all needed instances\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "    writer = SummaryWriter(log_dir=config.CONFIG_LOGS_PATH[\"itransformer\"])\n",
    "\n",
    "    # run model training as mentioned in the original paper\n",
    "    _, model = training_functions.train_one_epoch(epoch, model, device, dataloader_train, dataloader_validation, optimizer, \\\n",
    "                                                        scheduler, writer, save_model=False, validate=False)\n",
    "    return model, device\n",
    "\n",
    "\n",
    "epoch=5\n",
    "\n",
    "for key, value in tl_setups.items():\n",
    "    source_df = value[0]\n",
    "    target_df = value[1]\n",
    "    source_name = value[2]\n",
    "    target_name = value[3]\n",
    "    print(f\"Using {source_name} as a source dataset.\")\n",
    "\n",
    "    model_path = config.CONFIG_MODEL_LOCATION[\"itransformer\"] / source_name / f\"{source_name}_full_dataset_best_val_loss.pt\"\n",
    "\n",
    "\n",
    "    # do test predictions for both target datasets\n",
    "    dataloader_test = target_df[\"dataloader_test\"]\n",
    "    datalaoder_val = target_df[\"dataloader_validation\"]\n",
    "    fine_tune_dataloader = target_df[\"4_weeks_train\"]  \n",
    "    full_fine_tune_dataloader = target_df[\"dataloader_train\"]        \n",
    "      \n",
    "\n",
    "    inputs, _ = next(iter(dataloader_test))\n",
    "    num_variates = inputs.size(2)\n",
    "\n",
    "    model_config = {\n",
    "        'num_variates': num_variates,\n",
    "        'lookback_len': window_size,\n",
    "        'depth': best_parameters[\"depth\"],\n",
    "        'dim': best_parameters[\"dim\"],\n",
    "        'num_tokens_per_variate': 1,\n",
    "        'pred_length': pred_length,\n",
    "        'dim_head': best_parameters[\"dim_head\"],\n",
    "        'heads': best_parameters[\"heads\"],\n",
    "        'attn_dropout': best_parameters[\"attn_dropout\"],\n",
    "        'ff_mult': best_parameters[\"ff_mult\"],\n",
    "        'ff_dropout': best_parameters[\"ff_dropout\"],\n",
    "        'num_mem_tokens': best_parameters[\"num_mem_tokens\"],\n",
    "        'use_reversible_instance_norm': True,\n",
    "        'reversible_instance_norm_affine': True,\n",
    "        'flash_attn': True\n",
    "    }\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    \n",
    "    # fne tuning on 4 weeks of target data\n",
    "    model, device = fine_tune(model, fine_tune_dataloader, datalaoder_val, device, epoch=epoch)\n",
    "    metrics_fine_tuned = helpers.full_eval(model, dataloader_test, device)\n",
    "    update_metrics(key, \"iTransformer\", \"four_weeks_tl\", metrics_fine_tuned[1], metrics_fine_tuned[0])\n",
    "\n",
    "    # train on full target dataset\n",
    "    checkpoint = torch.load(model_path,map_location='cpu')\n",
    "\n",
    "    # values are all set to zero (beta) and one (gamma), array needs to be adapted to num_variates\n",
    "    # learned affine parameters are series specific and need to be relearned for new series\n",
    "    # value are kept at 1 and 0 for stationary normalization\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.beta\"] = torch.zeros(num_variates, 1, dtype=torch.float)\n",
    "    checkpoint[\"model_state_dict\"][\"reversible_instance_norm.gamma\"] = torch.ones(num_variates, 1, dtype=torch.float)\n",
    "\n",
    "    model = iTransformer(**model_config).to(device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    # fne tuning on 4 weeks of target data\n",
    "    model, device = fine_tune(model, full_fine_tune_dataloader, datalaoder_val, device, epoch=epoch)\n",
    "    metrics_fine_tuned = helpers.full_eval(model, dataloader_test, device)\n",
    "    update_metrics(key, \"iTransformer\", \"full_tl\", metrics_fine_tuned[1], metrics_fine_tuned[0])\n",
    "\n",
    "results_df.to_csv(metrics_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>iTransformer</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Setup</th>\n",
       "      <th>Learning_scenario</th>\n",
       "      <th>Metric</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.461933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.022971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.008841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">ELD_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.684155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.482013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.509668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.380965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.465909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.361734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.191598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.196772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.316252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.389833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.185281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.274371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">Bavaria_to_GP2</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>2.338648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>1.052081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.594544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.454166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.458327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.356787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_Bavaria</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.226545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.435768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.0146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.000459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.014203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">GP2_to_ELD</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">Zero-Shot</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.331429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.392488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.218327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.297379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_tl</th>\n",
       "      <th>MSE</th>\n",
       "      <td>0.179492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>0.262639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">full_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">four_weeks_training</th>\n",
       "      <th>MSE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          iTransformer\n",
       "Setup          Learning_scenario   Metric             \n",
       "ELD_to_Bavaria Zero-Shot           MSE        0.241426\n",
       "                                   MAE        0.461933\n",
       "               four_weeks_tl       MSE        0.000976\n",
       "                                   MAE        0.022971\n",
       "               full_tl             MSE        0.000257\n",
       "                                   MAE        0.008841\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN\n",
       "ELD_to_GP2     Zero-Shot           MSE        0.684155\n",
       "                                   MAE        0.482013\n",
       "               four_weeks_tl       MSE        0.509668\n",
       "                                   MAE        0.380965\n",
       "               full_tl             MSE        0.465909\n",
       "                                   MAE        0.361734\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN\n",
       "Bavaria_to_ELD Zero-Shot           MSE        2.191598\n",
       "                                   MAE        1.196772\n",
       "               four_weeks_tl       MSE        0.316252\n",
       "                                   MAE        0.389833\n",
       "               full_tl             MSE        0.185281\n",
       "                                   MAE        0.274371\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN\n",
       "Bavaria_to_GP2 Zero-Shot           MSE        2.338648\n",
       "                                   MAE        1.052081\n",
       "               four_weeks_tl       MSE        0.594544\n",
       "                                   MAE        0.454166\n",
       "               full_tl             MSE        0.458327\n",
       "                                   MAE        0.356787\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN\n",
       "GP2_to_Bavaria Zero-Shot           MSE        0.226545\n",
       "                                   MAE        0.435768\n",
       "               four_weeks_tl       MSE        0.000523\n",
       "                                   MAE          0.0146\n",
       "               full_tl             MSE        0.000459\n",
       "                                   MAE        0.014203\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN\n",
       "GP2_to_ELD     Zero-Shot           MSE        0.331429\n",
       "                                   MAE        0.392488\n",
       "               four_weeks_tl       MSE        0.218327\n",
       "                                   MAE        0.297379\n",
       "               full_tl             MSE        0.179492\n",
       "                                   MAE        0.262639\n",
       "               full_training       MSE             NaN\n",
       "                                   MAE             NaN\n",
       "               four_weeks_training MSE             NaN\n",
       "                                   MAE             NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
