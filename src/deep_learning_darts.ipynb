{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training using darts library\n",
    "\n",
    "TL using the same number of IDs is possible\n",
    "\n",
    "Reshaping does not seem possible.\n",
    "\n",
    "when the target dataset has more IDs than the source set, we use the same model to predict multiple ids \n",
    "\n",
    "the models are trained on the same amount of IDs as the target test set contains \n",
    "\n",
    "residuals of the target test set are not considered \n",
    "\n",
    "TODO: Fine tuning and saving outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.utils.losses import *\n",
    "from darts.models import *\n",
    "from darts.metrics.metrics import mse, mae, mape\n",
    "\n",
    "from utils import data_handling, helpers\n",
    "import config\n",
    "import torch\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "four_weeks = -24*7*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set: 209 days, 0:00:00\n",
      "Length validation set: 34 days, 0:00:00\n",
      "Saving train, validation and test df for faster loading\n"
     ]
    }
   ],
   "source": [
    "# use electricity dataset\n",
    "electricity_dict = data_handling.format_electricity()\n",
    "\n",
    "for key, value in electricity_dict.items():\n",
    "\t\t\telectricity_dict[key]= data_handling.df_to_tensor(value)\n",
    "\n",
    "# normalize train and use matrics for val and test\n",
    "electricity_dict[\"4_weeks_train\"] = electricity_dict[\"train\"][four_weeks:,:]\n",
    "electricity_dict[\"train\"], train_standardize_dict = helpers.custom_standardizer(electricity_dict[\"train\"])\n",
    "electricity_dict[\"validation\"], _ = helpers.custom_standardizer(electricity_dict[\"validation\"], train_standardize_dict)\n",
    "electricity_dict[\"test\"], _ = helpers.custom_standardizer(electricity_dict[\"test\"], train_standardize_dict)\n",
    "electricity_dict[\"4_weeks_train\"], _ = helpers.custom_standardizer(electricity_dict[\"4_weeks_train\"], train_standardize_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bavaria dataset\n",
    "data_tensor = data_handling.load_bavaria_electricity()\n",
    "bavaria_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "bavaria_dict[\"4_weeks_train\"] = bavaria_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building genome project dataset\n",
    "data_tensor = data_handling.load_genome_project_data()\n",
    "gp_dict, standadizer = data_handling.train_test_split_eu_elec(data_tensor, standardize=True)\n",
    "gp_dict[\"4_weeks_train\"] = gp_dict[\"train\"][four_weeks:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define and train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(source_data_train, source_data_val, epochs=1):\n",
    "    \"\"\"\n",
    "    -Convert train/val data into Darts TimeSeries format\n",
    "    -Instantiate different models\n",
    "    -Fit models to dataset\n",
    "\n",
    "    Return: fitted models\n",
    "    \"\"\"\n",
    "    ts_train_source = TimeSeries.from_values(source_data_train)\n",
    "    ts_val_source = TimeSeries.from_values(source_data_val)\n",
    "   \n",
    "   \n",
    "    # model specific parameters\n",
    "    # nhits/nbeats\n",
    "    NUM_STACKS = 4\n",
    "    NUM_BLOCKS = 2\n",
    "    NUM_LAYERS = 2\n",
    "    LAYER_WIDTH = 256\n",
    "    COEFFS_DIM = 5\n",
    "\n",
    "    # Training settings:\n",
    "    LR = 0.0005\n",
    "    BATCH_SIZE = 32\n",
    "    NUM_EPOCHS = epochs\n",
    "\n",
    "    # shared parameters\n",
    "    LAYER_NORM = 'LayerNorm'\n",
    "    USE_REVIN = True\n",
    "    LOSS_FN = torch.nn.MSELoss()\n",
    "    IN_LEN = 96\n",
    "    OUT_LEN = 96\n",
    "    DROPOUT = 0.2  # slightly higher than \"generic\" because we want more robustnes for TL\n",
    "    VERBOSE = False\n",
    "\n",
    "    # reproducibility\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "    nhits_model = NHiTSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        activation='ReLU',\n",
    "        num_stacks=NUM_STACKS, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        num_layers=NUM_LAYERS, \n",
    "        layer_widths=LAYER_WIDTH, \n",
    "   #     expansion_coefficient_dim=COEFFS_DIM, \n",
    "    #    trend_polynomial_degree=2, \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "        pl_trainer_kwargs={\n",
    "                \"enable_progress_bar\": True,\n",
    "                # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "                \"accelerator\": \"gpu\",},\n",
    ")\n",
    "\n",
    "    nbeats_model = NBEATSModel(\n",
    "        input_chunk_length=IN_LEN,\n",
    "        output_chunk_length=OUT_LEN,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_stacks=NUM_STACKS,\n",
    "        num_blocks=NUM_BLOCKS,\n",
    "        num_layers=NUM_LAYERS,\n",
    "        layer_widths=LAYER_WIDTH,\n",
    "        expansion_coefficient_dim=COEFFS_DIM,\n",
    "        loss_fn=LOSS_FN,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "        activation='ReLU',\n",
    "        optimizer_kwargs={\"lr\": LR},\n",
    "        pl_trainer_kwargs={\n",
    "            \"enable_progress_bar\": True,\n",
    "            # change this one to \"gpu\" if your notebook does run in a GPU environment:\n",
    "            \"accelerator\": \"gpu\",},\n",
    "    )\n",
    "\n",
    "\n",
    "    transformer_model = TransformerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN,\n",
    "        output_chunk_shift=0, \n",
    "        d_model=LAYER_WIDTH, \n",
    "        nhead=4, \n",
    "        num_encoder_layers=3, \n",
    "        num_decoder_layers=3, \n",
    "        dim_feedforward=LAYER_WIDTH, \n",
    "        dropout=DROPOUT, \n",
    "        activation='relu', \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=None, \n",
    "        custom_encoder=None, \n",
    "        custom_decoder=None,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "    )\n",
    "\n",
    "    tsmixer_model = TSMixerModel(\n",
    "        input_chunk_length=IN_LEN, \n",
    "        output_chunk_length=OUT_LEN, \n",
    "        output_chunk_shift=0,\n",
    "        hidden_size=LAYER_WIDTH, \n",
    "        ff_size=LAYER_WIDTH, \n",
    "        num_blocks=NUM_BLOCKS, \n",
    "        activation='ReLU', \n",
    "        dropout=DROPOUT, \n",
    "        loss_fn=LOSS_FN,\n",
    "        norm_type=LAYER_NORM, \n",
    "        normalize_before=False, \n",
    "        use_static_covariates=False,\n",
    "        use_reversible_instance_norm=USE_REVIN,\n",
    "\n",
    "    )\n",
    "\n",
    "    nhits_model.fit(        \n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,)\n",
    "\n",
    "    nbeats_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    transformer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "    tsmixer_model.fit(\n",
    "        ts_train_source,\n",
    "        val_series=ts_val_source,\n",
    "        num_loader_workers=4,\n",
    "        epochs=NUM_EPOCHS,\n",
    "        max_samples_per_ts=None,\n",
    "        verbose = VERBOSE,\n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "    return transformer_model, nbeats_model, tsmixer_model, nhits_model\n",
    "\n",
    "\n",
    "\n",
    "def evaluate(transformer, nbeats, nhits, tsnmix, target_test):\n",
    "    \"\"\"\n",
    "    Evaluates models on target test set\n",
    "    \n",
    "\n",
    "    Input:  -trained models\n",
    "            -List of target test sets shaped according to models\n",
    "\n",
    "    Output: [transformer, nhits, tsnmix]-Losses\n",
    "    \"\"\"\n",
    "\n",
    "    forecasting_endpoint = int(len(target_test)) - 96*2\n",
    "    target_test = TimeSeries.from_values(target_test)\n",
    "    window = [target_test[i:i+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "    target = [target_test[i+96:i+96+96] for i in range(0, forecasting_endpoint, 5)]\n",
    "\n",
    "    # predict over dataloader with slidingwindow implementation and 5 time step shifts for each input\n",
    "    preds_transformer = transformer.predict(n=96, series=window)\n",
    "    preds_nhits = nhits.predict(n=96, series=window)\n",
    "    preds_tsnmix = tsnmix.predict(n=96, series=window)\n",
    "    preds_nbeats = nbeats.predict(n=96, series=window)\n",
    "\n",
    "\n",
    "    mse_transformer = mse(preds_transformer, target)\n",
    "    mse_nhits = mse(preds_nhits, target)\n",
    "    mse_tsmix = mse(preds_tsnmix, target)\n",
    "    mse_nbeats = mse(preds_nbeats, target)\n",
    "\n",
    "    length_loss = len(mse_transformer)\n",
    "\n",
    "    mae_transformer = mae(preds_transformer, target)\n",
    "    mae_nhits = mae(preds_nhits, target)\n",
    "    mae_tsmix = mae(preds_tsnmix, target)\n",
    "    mae_nbeats = mae(preds_nbeats, target)\n",
    "\n",
    "\n",
    "#    mape_transformer = mape(preds_transformer, target)\n",
    " #   mape_nhits = mape(preds_nhits, target)\n",
    "  #  mape_tsmix = mape(preds_tsnmix, target)\n",
    "   # mape_nbeats = mape(preds_nbeats, target)\n",
    "\n",
    "\n",
    "\n",
    "    mse_mae_mape_transformer = sum(mse_transformer) / length_loss, sum(mae_transformer) / length_loss#, sum(mape_transformer) / length_loss\n",
    "    mse_mae_mape_nhits = sum(mse_nhits) / length_loss, sum(mae_nhits) / length_loss#, sum(mape_nhits) / length_loss\n",
    "    mse_mae_mape_tsmix = sum(mse_tsmix) / length_loss, sum(mae_tsmix) / length_loss#, sum(mape_tsmix) / length_loss\n",
    "    mse_mae_mape_nbeats = sum(mse_nbeats) / length_loss, sum(mae_nbeats) / length_loss#, sum(mape_nbeats) / length_loss\n",
    "\n",
    "    return mse_mae_mape_transformer, mse_mae_mape_nhits, mse_mae_mape_nbeats, mse_mae_mape_tsmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/torch/random.py:107: UserWarning: CUDA reports that you have 3 available devices, and you have used fork_rng without explicitly specifying which devices are being used. For safety, we initialize *every* CUDA device by default, which can be quite slow if you have a lot of GPUs.  If you know that you are only making use of a few CUDA devices, set the environment variable CUDA_VISIBLE_DEVICES or the 'devices' keyword argument of fork_rng with the set of devices you are actually using.  For example, if you are using CPU only, set CUDA_VISIBLE_DEVICES= or devices=[]; if you are using GPU 0 only, set CUDA_VISIBLE_DEVICES=0 or devices=[0].  To initialize all devices and suppress this warning, set the 'devices' keyword argument to `range(torch.cuda.device_count())`.\n",
      "  warnings.warn(\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 16.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 21.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 18.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 17.31it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 19.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 16.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 19.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:00<00:00, 18.53it/s]\n"
     ]
    }
   ],
   "source": [
    "output_path_full = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"electricity_metrics_full.csv\"\n",
    "output_path_short = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"electricity_metrics_short.csv\"\n",
    "\n",
    "# train on 4 weeks and predict on electricity dataset\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(electricity_dict[\"4_weeks_train\"], electricity_dict[\"validation\"], 10)\n",
    "electricity_metrics_short = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, electricity_dict[\"test\"])\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_short, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(electricity_metrics_short)\n",
    "\n",
    "# full training and evaluation\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(electricity_dict[\"train\"], electricity_dict[\"validation\"], 10)\n",
    "electricity_metrics_full = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, electricity_dict[\"test\"])\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_full, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(electricity_metrics_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:01<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 20.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 23.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 20.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 24.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 21.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:01<00:00, 16.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 17/17 [00:00<00:00, 24.06it/s]\n"
     ]
    }
   ],
   "source": [
    "output_path_full = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"bavaria_metrics_full.csv\"\n",
    "output_path_short = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"bavaria_metrics_short.csv\"\n",
    "\n",
    "# train on 4 weeks dataset and evaluate\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(bavaria_dict[\"4_weeks_train\"], bavaria_dict[\"validation\"], 10)\n",
    "bavaria_metrics_short = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, bavaria_dict[\"test\"])\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_short, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(bavaria_metrics_short)\n",
    "\n",
    "\n",
    "# train and predict on bavaria dataset\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(bavaria_dict[\"train\"], bavaria_dict[\"validation\"], 10)\n",
    "bavaria_metrics_long = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, bavaria_dict[\"test\"])\n",
    "\n",
    "\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_full, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(bavaria_metrics_long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n",
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n",
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "/vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /vol/fob-vol7/nebenf21/reinbene/bene/MA/myenv/lib/py ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:37<00:00,  0.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 3 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=3)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 18/18 [00:01<00:00, 13.30it/s]\n"
     ]
    }
   ],
   "source": [
    "output_path_full = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"gp_metrics_full.csv\"\n",
    "output_path_short = config.CONFIG_OUTPUT_PATH[\"darts\"] / \"gp_metrics_short.csv\"\n",
    "\n",
    "\n",
    "# train and predict on genome project 2 dataset\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(gp_dict[\"4_weeks_train\"], gp_dict[\"validation\"], 10)\n",
    "gp_metrics_short = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, gp_dict[\"test\"])\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_short, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(gp_metrics_short)\n",
    "\n",
    "    \n",
    "# train and predict on genome project 2 dataset\n",
    "transformer_model, nbeats_model, tsmixer_model, nhits_model = train_models(gp_dict[\"train\"], gp_dict[\"validation\"], 10)\n",
    "gp_metrics_long = evaluate(transformer_model, nbeats_model, nhits_model, tsmixer_model, gp_dict[\"test\"])\n",
    "\n",
    "# Open the file in write mode\n",
    "with open(output_path_full, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "\n",
    "    # Optionally write headers, if you want to label the columns\n",
    "    writer.writerow([\"mse\", \"mae\"])\n",
    "\n",
    "    # Write the data\n",
    "    writer.writerows(gp_metrics_long)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
