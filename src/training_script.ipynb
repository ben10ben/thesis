{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git clone https://github.com/lucidrains/iTransformer.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben_ten/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/ben_ten/.local/lib/python3.8/site-packages/pandas/core/computation/expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ModelConfig' from 'utils.helpers' (/home/ben_ten/ben/MA/src/utils/helpers.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/home/ben_ten/ben/MA/src/training_script.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mhelpers\u001b[39;00m \u001b[39mimport\u001b[39;00m SlidingWindowTimeSeriesDataset, ModelConfig, create_checkpoint, calc_percentiles\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'ModelConfig' from 'utils.helpers' (/home/ben_ten/ben/MA/src/utils/helpers.py)"
     ]
    }
   ],
   "source": [
    "#%pip install iTransformer\n",
    "#!python3 -m pip install torch==2.0.0+cu117 torchvision==0.15.1+cu117 torchaudio==2.0.1 --index-url https://download.pytorch.org/whl/cu117\n",
    "#!pip install holidays\n",
    "\n",
    "from iTransformer import iTransformer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import holidays\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from beartype.typing import Union, Tuple\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.helpers import SlidingWindowTimeSeriesDataset, ModelConfig, create_checkpoint, calc_percentiles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iTransformer from paper, difficult to use // dataprep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use of paper iTransformer\n",
    "\n",
    "from model.iTransformer import Model \n",
    "\n",
    "from types import SimpleNamespace\n",
    "\n",
    "configs = SimpleNamespace(\n",
    "    seq_len=100,\n",
    "    pred_len=10,\n",
    "    output_attention=True,\n",
    "    d_model=512,\n",
    "    embed='some_embedding_config',\n",
    "    freq='H',  # e.g., hourly frequency\n",
    "    dropout=0.1,\n",
    "    class_strategy='some_strategy',\n",
    "    factor=5,\n",
    "    e_layers=6,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    activation='relu'  # e.g., relu activation\n",
    ")\n",
    "\n",
    "model = Model(configs)\n",
    "\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "#class ModelConfig:\n",
    "\tseq_len: int = 96\n",
    "\tpred_len: int = 24\n",
    "\toutput_attention: int =  \n",
    "\td_model\n",
    "\tembed\n",
    "\tfreq\n",
    "\tdropout\n",
    "\tclass_strategy\n",
    "\tfactor\n",
    "\tn_heads\n",
    "\td_ff\n",
    "\tactivation\n",
    "\te_layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>power_usage</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>days_from_start</th>\n",
       "      <th>id</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26304.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26305.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26306.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.855330</td>\n",
       "      <td>26307.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.538071</td>\n",
       "      <td>26308.0</td>\n",
       "      <td>1096</td>\n",
       "      <td>MT_001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198067</th>\n",
       "      <td>20824.324324</td>\n",
       "      <td>32299.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>19</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198068</th>\n",
       "      <td>19527.027027</td>\n",
       "      <td>32300.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198069</th>\n",
       "      <td>20202.702703</td>\n",
       "      <td>32301.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198070</th>\n",
       "      <td>19851.351351</td>\n",
       "      <td>32302.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2198071</th>\n",
       "      <td>20135.135135</td>\n",
       "      <td>32303.0</td>\n",
       "      <td>1345</td>\n",
       "      <td>MT_370</td>\n",
       "      <td>23</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2100000 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          power_usage  time_idx  days_from_start      id  hour  day  \\\n",
       "0            2.538071   26304.0             1096  MT_001     0    1   \n",
       "1            2.855330   26305.0             1096  MT_001     1    1   \n",
       "2            2.855330   26306.0             1096  MT_001     2    1   \n",
       "3            2.855330   26307.0             1096  MT_001     3    1   \n",
       "4            2.538071   26308.0             1096  MT_001     4    1   \n",
       "...               ...       ...              ...     ...   ...  ...   \n",
       "2198067  20824.324324   32299.0             1345  MT_370    19    7   \n",
       "2198068  19527.027027   32300.0             1345  MT_370    20    7   \n",
       "2198069  20202.702703   32301.0             1345  MT_370    21    7   \n",
       "2198070  19851.351351   32302.0             1345  MT_370    22    7   \n",
       "2198071  20135.135135   32303.0             1345  MT_370    23    7   \n",
       "\n",
       "         day_of_week  month  \n",
       "0                  2      1  \n",
       "1                  2      1  \n",
       "2                  2      1  \n",
       "3                  2      1  \n",
       "4                  2      1  \n",
       "...              ...    ...  \n",
       "2198067            6      9  \n",
       "2198068            6      9  \n",
       "2198069            6      9  \n",
       "2198070            6      9  \n",
       "2198071            6      9  \n",
       "\n",
       "[2100000 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#passenger_df = pd.read_csv(Path(\"/home/ben_ten/ben/MA/air_passenger/AirPassengers.csv\"), delimiter=\",\")\n",
    "\n",
    "electricity = pd.read_csv(Path(\"/home/ben_ten/ben/MA/LD2011_2014.csv\"), delimiter=\",\")\n",
    "electricity.drop(['categorical_hour', 'categorical_day_of_week', 'hours_from_start', 'Unnamed: 0', 'categorical_id', 'date'], axis=1, inplace=True)\n",
    "for i in electricity[\"id\"].unique():\n",
    "\tif electricity[electricity[\"id\"]==i][\"days_from_start\"].min() != 1096:\n",
    "\t\telectricity.drop(electricity[electricity[\"id\"] == i].index, inplace=True)\n",
    "electricity.to_csv(\"electricity_small.csv\", index=False)\n",
    "electricity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataprep pessenger\n",
    "\n",
    "# Sample pandas series\n",
    "passenger = passenger_df['#Passengers']\n",
    "\n",
    "# Convert the pandas series to a NumPy array\n",
    "numpy_arr = passenger.to_numpy()\n",
    "\n",
    "# Reshape the NumPy array to have shape (1, Series, 1)\n",
    "reshaped_array = numpy_arr.reshape(1, -1, 1)\n",
    "\n",
    "# Convert the reshaped NumPy array to a PyTorch tensor\n",
    "torch_tensor = torch.Tensor(reshaped_array)\n",
    "\n",
    "# Check the shape of the PyTorch tensor\n",
    "print(torch_tensor.shape)\n",
    "\n",
    "def min_max_scaling(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    return normalized_tensor\n",
    "\n",
    "def standard_scaling(tensor):\n",
    "    mean = tensor.mean(dim=(0, 1), keepdim=True)\n",
    "    std = tensor.std(dim=(0, 1), unbiased=False, keepdim=True)  # using unbiased=False for sample standard deviation\n",
    "    scaled_tensor = (tensor - mean) / (std + 1e-7) \n",
    "    return scaled_tensor\n",
    "\n",
    "#uncommend for normalized/standardized tensors\n",
    "#torch_tensor = min_max_scaling(torch_tensor)\n",
    "torch_tensor = standard_scaling(torch_tensor)\n",
    "\n",
    "tensor_x = torch_tensor[:, :132, :]\n",
    "tensor_y = torch_tensor[:, 132:, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for electricity and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datalaoder n_batches:\n",
      "Train: 80\n",
      "Valid: 376\n",
      "Test: 2111\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# small multi batch dataset for trial\n",
    "train_tensor_small = train_tensor[:1, 0:, :] # 10 ids and 1000 timesteps -> 10 * (1000/144) = 60 timeseries\n",
    "valid_tensor_small = valid_tensor[:20, 0:, :]\n",
    "test_tensor_small = test_tensor[:, 0:, :]\n",
    "\n",
    "\n",
    "valid_tensor_id_1 = valid_tensor[:1, 0:, :]\n",
    "valid_tensor_id_2 =valid_tensor[2:3, 0:, :]\n",
    "\n",
    "# define input and output size for dataset creation and model config\n",
    "window_size = 132\n",
    "pred_length = 12\n",
    "\n",
    "# create dataset with mutiple input timeseries per id accodring to window_length/pred_length\n",
    "train_sliding_window = SlidingWindowTimeSeriesDataset(train_tensor_small, window_size, pred_length)\n",
    "valid_sliding_window = SlidingWindowTimeSeriesDataset(valid_tensor_small, window_size, pred_length)\n",
    "test_sliding_window = SlidingWindowTimeSeriesDataset(test_tensor_small, window_size, pred_length)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_sliding_window, batch_size=64, shuffle=True, num_workers=5)\n",
    "valid_dataloader = DataLoader(valid_sliding_window, batch_size=32, shuffle=False)\n",
    "test_datalaoder = DataLoader(test_sliding_window, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Datalaoder n_batches:\\nTrain: {len(train_dataloader)}\\nValid: {len(valid_dataloader)}\\nTest: {len(test_datalaoder)}\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# defining all needed instances\n",
    "config = ModelConfig(lookback_len=window_size, pred_length=pred_length)\n",
    "model = iTransformer(config).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "writer = SummaryWriter(log_dir='logs')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = dict()\n",
    "dict[\"test\"] = load_data(\"blabla\")\n",
    "dict[\"valid\"] = load_data(\"blabla\")\n",
    "\n",
    "transformed = transform(cases)\n",
    "\n",
    "\n",
    "def transorm(data):\n",
    "\ttransormed = dict()\n",
    "\tfor key, value in cases.items():\n",
    "\t\ttransformed[key] = transoform(cases)\n",
    "\treturn transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:19<00:00,  4.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.17024583357851952\n",
      "Checkpointing succesfull after epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:19<00:00,  4.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Loss: 0.03198554607806727\n",
      "Checkpointing succesfull after epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:19<00:00,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Loss: 0.0240678658883553\n",
      "Checkpointing succesfull after epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch = 3\n",
    "\n",
    "def train_one_epoch(epoch, model, device, train_dataloader, optimizer, scheduler, writer):\n",
    "\tglobal_step = 0\n",
    "\tmodel.train()\n",
    "\ttotal_loss = 0\n",
    "\tfor input, target_covariates in tqdm(train_dataloader, desc=f\"Epoch: {epoch}\"):\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tinput = input.to(device)\n",
    "\t\toutput_covariates = model(input)\n",
    "\n",
    "\t\t# this can be used for target specific fine-tuning\n",
    "\t\toutput = output_covariates[12][:,:,0]\n",
    "\t\ttarget = target_covariates[:,:,0]\n",
    "\n",
    "\t\tloss = torch.nn.MSELoss()\n",
    "\t\tloss = loss(output_covariates[12], target_covariates)  # compute loss on all variates\n",
    "\t\t#computed_loss = loss(output, target)  # compute loss on target variate\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\ttotal_loss += loss.item()\n",
    "\n",
    "\t\twriter.add_scalar('Loss/train', loss, global_step)\n",
    "\t\twriter.add_scalar('LR/train', optimizer.param_groups[0]['lr'], global_step)\n",
    "\n",
    "\t\tglobal_step+=1\n",
    "\n",
    "\tprint(f'Epoch {epoch}, Loss: {total_loss / len(train_dataloader)}')\n",
    "\n",
    "\tscheduler.step()\n",
    "\n",
    "\twriter.close()\n",
    "\tcreate_checkpoint(model, optimizer, scheduler, epoch, loss, global_step, \"first_20_ids_full\")\n",
    "\n",
    "for epoch in range(1, epoch + 1):\n",
    "\ttrain_one_epoch(epoch, model, device, train_dataloader, optimizer, scheduler, writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calc_percentiles(predictions, actuals, percentile):\n",
    "\t# take predictions, actuals in correct order and return percentiles\n",
    "\t# return p10, p50, p90\n",
    "\t\n",
    "\terrors = np.abs(predictions - actuals)\n",
    "\n",
    "\t# Sort the errors\n",
    "\tsorted_errors = np.sort(errors)\n",
    "\n",
    "# Calculate p10, P50 and P90\n",
    "\tp_percentile = np.percentile(sorted_errors, percentile)\n",
    "\treturn p_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ben_ten/ben/MA/src/training_script.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m valid_tensor_id_1 \u001b[39m=\u001b[39m valid_tensor[:\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m:, :]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m valid_tensor_id_2 \u001b[39m=\u001b[39mvalid_tensor[\u001b[39m2\u001b[39m:\u001b[39m3\u001b[39m, \u001b[39m0\u001b[39m:, :]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/ben_ten/ben/MA/src/training_script.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m window_size \u001b[39m=\u001b[39m \u001b[39m132\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "valid_tensor_id_1 = valid_tensor[:1, 0:, :]\n",
    "valid_tensor_id_2 =valid_tensor[2:3, 0:, :]\n",
    "\n",
    "\n",
    "\n",
    "window_size = 132\n",
    "pred_length = 12\n",
    "\n",
    "# create dataset with mutiple input timeseries per id accodring to window_length/pred_length\n",
    "valid_sliding_window_id1 = SlidingWindowTimeSeriesDataset(valid_tensor_id_1, window_size, pred_length)\n",
    "valid_sliding_window_id2 = SlidingWindowTimeSeriesDataset(valid_tensor_id_2, window_size, pred_length)\n",
    "\n",
    "valid_dataloader_id1 = DataLoader(valid_sliding_window_id1, batch_size=32, shuffle=False)\n",
    "valid_dataloader_id2 = DataLoader(valid_sliding_window_id2, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating:  21%|â–ˆâ–ˆ        | 4/19 [00:00<00:00, 17.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:00<00:00, 21.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.04394805421562571\n",
      "P10: 0.0032778435558276746\n",
      "\tP50: 0.026434942344693763\n",
      "P90: 0.4216238235172473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_function(valid_dataloader_id1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating:  11%|â–ˆ         | 2/19 [00:00<00:01, 13.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19/19 [00:01<00:00, 15.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Loss: 0.043910691220509376\n",
      "P10: 0.0032440845952614364\n",
      "\tP50: 0.02638869992408313\n",
      "P90: 0.42143149250432066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_function(valid_dataloader_id2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_function(valid_dataloader):\n",
    "\t# loading saved model\n",
    "#\tmodel = iTransformer(config)\n",
    "\n",
    "\tcheckpoint = torch.load(\"model_name_first_20_ids_full_epoch_3.pt\")\n",
    "\tmodel.load_state_dict(checkpoint['model_state_dict'])\n",
    "\toptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\tstart_epoch = checkpoint['epoch'] + 1  # Start training from \n",
    "\tscheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\tscheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\twriter = SummaryWriter(log_dir='logs')\n",
    "\tglobal_step = checkpoint['global_step_writer']\n",
    "\n",
    "\tdevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\tmodel.to(device)\n",
    "\tmodel.eval()\n",
    "\tglobal_step_eval = 1\n",
    "\ttotal_p10_eval = 0\n",
    "\ttotal_p50_eval = 0\n",
    "\ttotal_p90_eval = 0\n",
    "\n",
    "\t# Example inference code\n",
    "\twith torch.no_grad():\n",
    "\t\ttotal_loss_eval = 0\n",
    "\t\tfor input, target_covariates in tqdm(valid_dataloader, desc=f\"Epoch: Validating\"):\n",
    "\t\t\tinput = input.to(device)\n",
    "\t\t\toutput_covariates = model(input)\n",
    "\n",
    "\t\t\t# this can be used for target specific fine-tuning\n",
    "\t\t\t#output = output_covariates[12][:,:,0]\n",
    "\t\t\t#target = target_covariates[:,:,0]\n",
    "\n",
    "\t\t\tloss = torch.nn.MSELoss()\n",
    "\t\t\tloss = loss(output_covariates[12], target_covariates)  # compute loss on all variates\n",
    "\t\t\t#computed_loss = loss(output, target)  # compute loss on target variate\n",
    "\n",
    "\t\t\ttotal_loss_eval += loss.item()\n",
    "\t\t\ttotal_p10_eval += calc_percentiles(output_covariates[12], target_covariates, 10)\n",
    "\t\t\ttotal_p50_eval += calc_percentiles(output_covariates[12], target_covariates, 50)\n",
    "\t\t\ttotal_p90_eval += calc_percentiles(output_covariates[12], target_covariates, 90)\n",
    "\n",
    "\n",
    "\tprint(f'MSE Loss: {total_loss_eval / len(valid_dataloader)}\\nP10: { total_p10_eval/ len(valid_dataloader)}\\n\\\n",
    "\tP50: {total_p50_eval/ len(valid_dataloader)}\\nP90: { total_p90_eval/ len(valid_dataloader)}')\n",
    "\n",
    "\twriter.add_scalar('MSE/valid', total_loss_eval/ len(valid_dataloader), global_step_eval)\n",
    "\twriter.add_scalar('P10/valid', total_p10_eval/ len(valid_dataloader), global_step_eval)\n",
    "\twriter.add_scalar('P50/valid', total_p50_eval/ len(valid_dataloader), global_step_eval)\n",
    "\twriter.add_scalar('P90/valid', total_p90_eval/ len(valid_dataloader), global_step_eval)\n",
    "\n",
    "\twriter.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
